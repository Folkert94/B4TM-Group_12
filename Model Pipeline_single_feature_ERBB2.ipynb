{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0    1    2    3    4    5    6    7    8    9     ... 2824 2825  \\\n",
      "Array.129    0    0    0    0    0    0    0    0    0    0  ...    2    2   \n",
      "Array.34     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.67     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.24     0    0    0    0    0    0    0   -1    0    0  ...    0    0   \n",
      "Array.22     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.36     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.49     0    0    0    0    0    0    0    0    0    0  ...    2    1   \n",
      "Array.16     0    0    0    0   -1    0    0    0    0    0  ...    1    1   \n",
      "Array.146    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.143    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.65     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.62     1    1    1    1    1    1    1    1    1    1  ...    1    1   \n",
      "Array.4     -1   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    1    1   \n",
      "Array.76     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.118    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.154    1    1    0    0    0    0    0    0   -1   -1  ...    0    0   \n",
      "Array.48     1    0    0    0    0    0    1    0    0    0  ...    1    1   \n",
      "Array.6      0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.39    -1   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    1    1   \n",
      "Array.86     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.112    0    0    0    0    0    0    0    0    0    0  ...    2    2   \n",
      "Array.79     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.124    0    0    0    0    0    0    0    0    2    0  ...    2    1   \n",
      "Array.19     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.27     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.106    0    0    0    0    0    0    0    0   -1   -1  ...    2    2   \n",
      "Array.110    0    0    0    0    0    0    0    0    0    0  ...    2    2   \n",
      "Array.69     1    0    0    0    0    0    0    1    0    0  ...    1    1   \n",
      "Array.73     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.95     1    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.98     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.17     0    0    0    0    1    1    1   -1    1    1  ...    1    1   \n",
      "Array.33     0    0    0    0    0    0    0    0    0    0  ...    1    2   \n",
      "Array.138    0    0    0    0    0    0    0   -1   -1   -1  ...    1    1   \n",
      "Array.149    0    0    0    0    0    0    0   -1   -1   -1  ...    1    1   \n",
      "Array.101    0    0    1    1    1    1    1    1    1    1  ...    1    1   \n",
      "Array.90    -1   -1   -1    1   -1   -1   -1   -1   -1   -1  ...    2    2   \n",
      "Array.99    -1   -1    0    0    0    0    0    0    0    0  ...    2    2   \n",
      "Array.57    -1   -1   -1    1    1   -1   -1    1   -1   -1  ...    1    1   \n",
      "Array.105    0    0    0    0    0    0    0    0   -1   -1  ...    2    1   \n",
      "Array.85     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.114   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    2    1   \n",
      "Array.56     0   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    1    1   \n",
      "Array.5      0    0    1    1    1    1    1    1    1    1  ...    1    1   \n",
      "Array.8      0    0    0    0   -1   -1   -1   -1   -1   -1  ...    1    1   \n",
      "Array.113   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    2    2   \n",
      "Array.148    0    0    0    0    0    0   -1   -1   -1    0  ...    1    1   \n",
      "Array.42     0    0    0    0    0    0    0    1    0    0  ...    2    2   \n",
      "Array.25     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.102    0    0    0    0   -1   -1   -1    0   -1   -1  ...    1    1   \n",
      "Array.55     1    1    1    1    1    1    1    1    1    1  ...    1    1   \n",
      "Array.141    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.43     0    0    0    0    0    0    0   -1    0    0  ...    1    1   \n",
      "Array.159    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.52     0    0    0   -1   -1    0    0    0    0    0  ...    1    1   \n",
      "Array.88     0    0    0    0    0    0    0    0    0    0  ...    0    2   \n",
      "Array.125    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.152    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.50     0    0    0    0    0    0    0    0    0    0  ...    2    2   \n",
      "Array.23     1    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.68     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.94     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.153    0   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    0    0   \n",
      "Array.51     1    1    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "Array.142    0    0    0    0    0    0    0    0    0    0  ...    2    2   \n",
      "Array.144    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.37     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.78     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.18     0   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    1    1   \n",
      "Array.82     0    0    0    0    0    0    0    0    0    0  ...    2    2   \n",
      "Array.75     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.139    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.2      1    1    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.117    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.60     0    0    0    0    0    0    0   -1    0    0  ...    1    1   \n",
      "Array.38     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.72     1    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.104    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.137    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.145   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    1    1   \n",
      "Array.31     1    1    1    1    1    1    1    1    1    1  ...    2    2   \n",
      "Array.135    0    0    0    0    0    0    0    0    0    0  ...    2    2   \n",
      "Array.111    1    1    1    1    1    1    1    0    1    1  ...    1    1   \n",
      "Array.7      0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.21     0    0    0    0    0    0    0   -1    0    0  ...    2    2   \n",
      "Array.53     0    0    0    0    0    0    0    0    0    0  ...    2    2   \n",
      "Array.59    -1   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    0    0   \n",
      "Array.71     0    0    1    1    1    1    1    0    1    1  ...    1    1   \n",
      "Array.47     0    0    0    0    0    0    0    0   -1    0  ...    2    2   \n",
      "Array.107    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.64     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.89     0    0    0    1    1    0    0    0    0    0  ...    1    1   \n",
      "Array.30     1    1    1    1    1    1    1    1    1    1  ...    1    1   \n",
      "Array.35     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.93     0    0    1    1    1    1    1    1    0    0  ...    1    1   \n",
      "Array.10     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.123    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.100    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.134   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    1    1   \n",
      "Array.130    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "\n",
      "          2826 2827 2828 2829 2830 2831 2832 2833  \n",
      "Array.129    2    2    0    1    1    1    1    1  \n",
      "Array.34     1    1    1    1    1    1    1    1  \n",
      "Array.67     1    1    1    1    1    1    1    1  \n",
      "Array.24     0    0    0    0    0    0    0    0  \n",
      "Array.22     1    1    1    1    1    1    1    1  \n",
      "Array.36     0    1    1    1    1    1    1    1  \n",
      "Array.49     1    1    1    1    1    1    1    1  \n",
      "Array.16     1    1    1    1    1    1    1    1  \n",
      "Array.146    1    1    1    1    1    1    1    1  \n",
      "Array.143    1    1    1    1    1    1    1    1  \n",
      "Array.65     1    1    1    1    2    2    2    2  \n",
      "Array.62     1    1    1    1    1    1    0    1  \n",
      "Array.4      1    1    1    1    1    1    1    1  \n",
      "Array.76     1    1    1    1    1    1    1    1  \n",
      "Array.118    1    1    1    1    1    1    1    1  \n",
      "Array.154    0    0    0    0    0    0    0    0  \n",
      "Array.48     1    1    0    1    1    1    1    1  \n",
      "Array.6      0    1    1    1    1    1    1    1  \n",
      "Array.39     0    1    1    1    1    1    1    1  \n",
      "Array.86     1    1    1    1    1    1    1    1  \n",
      "Array.112    2    2    2    2    2    2    2    2  \n",
      "Array.79     1    1    1    1    1    1    1    1  \n",
      "Array.124    1    1    1    1    1    2    2    2  \n",
      "Array.19     1    1    2    1    1    1    2    1  \n",
      "Array.27     0    1    1    1    1    1    1    1  \n",
      "Array.106    2    2    2    2    2    2    2    1  \n",
      "Array.110    2    2    2    2    2    2    2    2  \n",
      "Array.69     1    1    1    1    1    1    1    1  \n",
      "Array.73     1    1    1    1    1    1    1    1  \n",
      "Array.95     1    1    1    1    1    1    1    1  \n",
      "Array.98     1    1    1    1    1    1    1    1  \n",
      "Array.17     0    1    1    1    1    1    1    1  \n",
      "Array.33     2    2    0    2    2    2    2    1  \n",
      "Array.138    1    1    1    1    1    1    1    1  \n",
      "Array.149    1    1    1    1    1    1    1    1  \n",
      "Array.101    1    1    1    1    1    1    1    1  \n",
      "Array.90     2    2    2    2    2    2    0    2  \n",
      "Array.99     2    2    2    2    2    2    2    2  \n",
      "Array.57     1    1    1    1    1    1    1    1  \n",
      "Array.105    1    1    1    1    1    2    2    2  \n",
      "Array.85     1    1    1    1    1    1    1    1  \n",
      "Array.114    1    1    1    1    2    2    2    2  \n",
      "Array.56     1    1    1    1    1    1    1    1  \n",
      "Array.5      1    1    1    1    1    1    1    1  \n",
      "Array.8      1    1    1    1    1    1    1    1  \n",
      "Array.113    2    2    2    2    2    2    2    2  \n",
      "Array.148    1    1    1    1    1    1    1    1  \n",
      "Array.42     2    2    2    2    2    2    2    2  \n",
      "Array.25     1    1    1    1    1    1    1    1  \n",
      "Array.102    1    1    1    1    1    1    1    1  \n",
      "Array.55     1    1    0    1    1    1    1    1  \n",
      "Array.141    1    1    1    1    1    1    1    1  \n",
      "Array.43     1    1    1    1    1    1    1    1  \n",
      "Array.159    1    1    1    1    1    1    1    1  \n",
      "Array.52     1    1    1    1    1    1    1    1  \n",
      "Array.88     1    2    2    2    0    0    0    0  \n",
      "Array.125    1    1    1    1    1    1    1    1  \n",
      "Array.152    1    1    1    1    1    1    1    1  \n",
      "Array.50     2    2    2    2    2    2    2    2  \n",
      "Array.23     1    1    1    1    1    1    1    1  \n",
      "Array.68     0    1    1    1    1    1    1    1  \n",
      "Array.94     1    1    1    1    1    1    1    1  \n",
      "Array.153    0    0    0    0    0    0    0    0  \n",
      "Array.51     0    0    0    0    0    0    0    0  \n",
      "Array.142    2    2    2    2    2    2    2    2  \n",
      "Array.144    1    1    1    1    1    1    1    1  \n",
      "Array.37     1    1    1    1    1    1    1    1  \n",
      "Array.78     1    1    1    1    1    1    1    1  \n",
      "Array.18     1    1    1    1    1    1    1    1  \n",
      "Array.82     2    2    2    2    2    2    2    2  \n",
      "Array.75     1    1    1    1    1    1    1    1  \n",
      "Array.139    1    1    2    1    1    1    1    1  \n",
      "Array.2      1    1    1    1    1    1    1    1  \n",
      "Array.117    1    1    1    1    1    1    1    1  \n",
      "Array.60     1    1    1    1    1    1    1    1  \n",
      "Array.38     1    1    1    1    1    1    1    1  \n",
      "Array.72     1    1    1    1    1    1    1    1  \n",
      "Array.104    1    1    1    1    1    1    1    1  \n",
      "Array.137    1    1    1    1    1    1    1    1  \n",
      "Array.145    1    1    1    1    1    1    1    0  \n",
      "Array.31     2    2    2    2    2    2    2    2  \n",
      "Array.135    2    2    2    2    2    2    2    2  \n",
      "Array.111    1    1    1    1    1    1    1    1  \n",
      "Array.7      1    1    1    1    1    1    1    1  \n",
      "Array.21     2    2    2    2    2    2    2    2  \n",
      "Array.53     2    2    2    2    2    2    2    2  \n",
      "Array.59     0    0    0    0    0    0    0    0  \n",
      "Array.71     1    1    1    1    1    1    1    1  \n",
      "Array.47     1    2    2    2    2    2    2    2  \n",
      "Array.107    1    1    1    1    1    1    1    1  \n",
      "Array.64     1    1    1    1    2    2    2    2  \n",
      "Array.89     1    1    1    1    1    1    1    1  \n",
      "Array.30     1    1    1    1    1    1    1    1  \n",
      "Array.35     1    1    1    1    1    1    1    1  \n",
      "Array.93     1    1    1    1    1    1    1    1  \n",
      "Array.10     0    1    1    1    1    1    1    1  \n",
      "Array.123    1    1    1    1    1    1    1    1  \n",
      "Array.100    1    1    1    1    1    1    1    1  \n",
      "Array.134    1    1    1    1    1    1    1    1  \n",
      "Array.130    1    1    1    1    1    1    1    1  \n",
      "\n",
      "[100 rows x 2834 columns]\n",
      "[1, 2, 2, 3, 3, 2, 1, 1, 3, 1, 2, 3, 1, 1, 3, 3, 2, 1, 2, 2, 3, 1, 2, 1, 2, 1, 1, 3, 1, 2, 2, 1, 2, 1, 2, 2, 3, 3, 3, 1, 2, 3, 2, 3, 2, 3, 1, 1, 3, 3, 1, 2, 2, 3, 2, 3, 1, 1, 3, 2, 1, 2, 3, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 3, 1, 3, 2, 3, 3, 3, 3, 2, 1, 1, 2, 3, 3, 3, 3, 2, 3, 2, 3, 1, 2, 2, 2, 1]\n",
      "The regions found in the literature were:  [111, 157, 249, 65, 361, 360, 479, 576, 583, 688, 664, 625, 670, 772, 876, 877, 878, 937, 991, 992, 993, 966, 1136, 1137, 1092, 1207, 1234, 1370, 1371, 1387, 1296, 1310, 1583, 1407, 1575, 1513, 1589, 1611, 1697, 1645, 1657, 1725, 1734, 1735, 1865, 1904, 1911, 2017, 1965, 2015, 2016, 2207, 2074, 2075, 2306, 2184, 2135, 2136, 2200, 2201, 2071, 2160, 2161, 2446, 2681, 2682, 2683, 2684, 2685, 2732, 2744, 2794, 2822]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "with open(\"train_call.txt\", 'r') as temp:\n",
    "    for line in temp:\n",
    "        temp_list.append(line.split())\n",
    "\n",
    "columns_temp = temp_list[0]\n",
    "columns_temp = [x.replace(\"\\\"\", \"\") for x in columns_temp]\n",
    "\n",
    "df_train = pd.DataFrame(temp_list[1:], columns=columns_temp)\n",
    "X = df_train.drop(['Chromosome', 'Start','End', 'Nclone'], axis=1)\n",
    "X = X.transpose()\n",
    "\n",
    "labels = []\n",
    "\n",
    "# X for features Y for breast cancer subtype where 1 = HER2+, 2 = HR+, 3 = Triple Neg\n",
    "with open(\"Train_clinical.txt\", 'r') as temp_labels:\n",
    "    next(temp_labels)\n",
    "    for line in temp_labels:\n",
    "        temp = line.strip()\n",
    "        temp = temp.split()\n",
    "        if temp[1].strip(\"\\\"\") == \"HER2+\":\n",
    "            labels.append(1)\n",
    "        if temp[1].strip(\"\\\"\") == \"HR+\":\n",
    "            labels.append(2)\n",
    "        if temp[1].strip(\"\\\"\") == \"Triple\":\n",
    "            labels.append(3)\n",
    "\n",
    "Y = labels\n",
    "            \n",
    "important_genes = []\n",
    "\n",
    "with open(\"important_genes_2.csv\", 'r') as imp_genes:\n",
    "    for line in imp_genes:\n",
    "        temp = line.strip()\n",
    "        important_genes.append(temp.split(\",\"))\n",
    "        \n",
    "imp_genes = []\n",
    "\n",
    "for gene in important_genes[1:]:\n",
    "    imp_genes.append([gene[0], gene[1], gene[2], gene[3]])\n",
    "    \n",
    "important_genes = []\n",
    "\n",
    "for x in imp_genes:\n",
    "    for i, y in enumerate(df_train.values.tolist()):\n",
    "        if x[1] == y[0] and x[2] == y[1] and x[3] == y[2]:\n",
    "            important_genes.append(i)\n",
    "            \n",
    "print(X)\n",
    "print(Y)\n",
    "print(\"The regions found in the literature were: \", important_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Gene  Region number       P-value Yes/No\n",
      "0              DIRAS3            111  6.897062e-01     No\n",
      "1              PTPN22            157  7.287985e-01     No\n",
      "2                 AGT            249  9.791761e-01     No\n",
      "3               CLSPN             65  5.039604e-01     No\n",
      "4   BARD1/CASP8/CTLA4            361  8.022867e-01     No\n",
      "5               SF3B1            360  8.717109e-01     No\n",
      "6              PIK3CA            479  4.007464e-01     No\n",
      "7               NFKB1            576  8.076397e-01     No\n",
      "8                FGF2            583  8.076397e-01     No\n",
      "9               RAD50            688  1.138701e-01     No\n",
      "10             MAP3K1            664  1.569463e-01     No\n",
      "11               TERT            625  9.757757e-01     No\n",
      "12             PIK3R1            670  4.250528e-02    Yes\n",
      "13              CCND3            772  1.568220e-01     No\n",
      "14               ESR1            876  4.297669e-01     No\n",
      "15               ESR1            877  3.435048e-01     No\n",
      "16               ESR1            878  3.384654e-01     No\n",
      "17               EGFR            937  9.492498e-01     No\n",
      "18       KMT2C (MLL3)            991  8.738841e-01     No\n",
      "19       KMT2C (MLL3)            992  8.280285e-01     No\n",
      "20       KMT2C (MLL3)            993  8.014328e-01     No\n",
      "21          CAV1/CAV2            966  8.425206e-01     No\n",
      "22                NBN           1136  7.630498e-01     No\n",
      "23                NBN           1137  7.911207e-01     No\n",
      "24              IKBKB           1092  7.408158e-02     No\n",
      "25              PTPRD           1207  5.060686e-01     No\n",
      "26               MELK           1234  6.914782e-01     No\n",
      "27               PTEN           1370  9.529703e-01     No\n",
      "28               PTEN           1371  7.162040e-01     No\n",
      "29              FGFR2           1387  9.025203e-01     No\n",
      "30              GATA3           1296  6.855018e-01     No\n",
      "31              MASTL           1310  4.611954e-01     No\n",
      "32                ATM           1583  2.250590e-01     No\n",
      "33           H19/LSP1           1407  5.048502e-01     No\n",
      "34           MRE11(A)           1575  2.436539e-01     No\n",
      "35              CCND1           1513  6.078381e-01     No\n",
      "36              TIRAP           1589  1.729887e-01     No\n",
      "37             CDKN1B           1611  7.665508e-01     No\n",
      "38               TBX3           1697  7.967035e-01     No\n",
      "39               KRT5           1645  1.479597e-01     No\n",
      "40               IL22           1657  5.859564e-02     No\n",
      "41              BRCA2           1725  6.931973e-01     No\n",
      "42                RB1           1734  3.485173e-01     No\n",
      "43                RB1           1735  4.047287e-01     No\n",
      "44               AKT1           1865  3.883914e-01     No\n",
      "45              RAD51           1904  2.001524e-01     No\n",
      "46            CYP19A1           1911  2.163115e-01     No\n",
      "47               CDH1           2017  4.623894e-02    Yes\n",
      "48              PALB2           1965  5.683650e-01     No\n",
      "49               CBFB           2015  1.517658e-01     No\n",
      "50               CDH3           2016  1.160794e-01     No\n",
      "51              BRCA1           2207  3.346706e-03    Yes\n",
      "52               TP53           2074  3.249625e-02    Yes\n",
      "53               TP53           2075  3.249625e-02    Yes\n",
      "54              BRIP1           2306  6.918517e-01     No\n",
      "55       ERBB2 (HER2)           2184  8.326227e-14    Yes\n",
      "56                NF1           2135  2.972004e-01     No\n",
      "57                NF1           2136  6.509545e-01     No\n",
      "58              KRT14           2200  4.172152e-01     No\n",
      "59              KRT17           2201  6.104122e-01     No\n",
      "60             ALOX15           2071  9.275122e-02     No\n",
      "61               CCL5           2160  5.475658e-01     No\n",
      "62               CCL4           2161  6.103237e-01     No\n",
      "63         STK11/LKB1           2446  9.669922e-01     No\n",
      "64              RUNX1           2681  5.234851e-01     No\n",
      "65              RUNX1           2682  4.492747e-01     No\n",
      "66              RUNX1           2683  5.987332e-01     No\n",
      "67              RUNX1           2684  6.175287e-01     No\n",
      "68              RUNX1           2685  5.718320e-01     No\n",
      "69              CHEK2           2732  4.082143e-02    Yes\n",
      "70              PDGFB           2744  9.509540e-02     No\n",
      "71                 AR           2794  7.771286e-01     No\n",
      "72               AFF2           2822  9.299035e-01     No\n",
      "    Chromosome      Start        End Nclone\n",
      "0            1   35903416   37578554    144\n",
      "1            1   67574404   69349603    118\n",
      "2            1  113508337  114220736     71\n",
      "3            1  225926558  231061656    435\n",
      "4            2  196090504  198648767    257\n",
      "5            2  198658046  216382286   1522\n",
      "6            3  177004388  181135381    268\n",
      "7            4  102672728  104401802    147\n",
      "8            4  120650347  124374816    281\n",
      "9            5    1007442    2438174    145\n",
      "10           5   55148225   57204282    139\n",
      "11           5   60285997   62401952    135\n",
      "12           5   62457701   65999278    299\n",
      "13           5   66011537   68773114    198\n",
      "14           5   70752359   71062539     40\n",
      "15           5   71077546   89933522   1459\n",
      "16           5   93328253   96508341    310\n",
      "17           5  131845023  140196482    920\n",
      "18           5  140433878  142819410    270\n",
      "19           5  142831583  149027600    525\n",
      "20           5  149050787  150137980    144\n",
      "21           5  150224239  152555267    187\n",
      "22           5  152572508  153979903    115\n",
      "23           5  154006451  157875296    310\n",
      "24           6   40747924   42826227    225\n",
      "25           6   80170446   80661257     33\n",
      "26           6   89106148   90015649     77\n",
      "27           6   90034143   91964331    149\n",
      "28           6  110490286  110621141     12\n",
      "29           6  111038086  111980766    105\n",
      "30           6  111990899  112201862     24\n",
      "31           6  113313043  113625048     12\n",
      "32           6  113685697  115481584     86\n",
      "33           6  115539064  119256600    285\n",
      "34           6  119263604  122326220    164\n",
      "35           6  122710361  123097090     43\n",
      "36           6  123114345  125128655    184\n",
      "37           6  125139481  126167412     78\n",
      "38           6  126241146  127397419     84\n",
      "39           6  127419048  128608361    120\n",
      "40           6  128614174  131296266    224\n",
      "41           6  131304839  132036965     59\n",
      "42           6  132048194  133414796    125\n",
      "43           6  133447975  135173194    145\n",
      "44           6  135286400  135498058     20\n",
      "45           6  135520431  136095714     50\n",
      "46           6  136159988  136555576     40\n",
      "47           6  136561135  136680507     15\n",
      "48           6  136687816  137521284     86\n",
      "49           6  137534872  137928470     23\n",
      "50           6  137982450  139107896     94\n",
      "51           6  139119957  139765820     62\n",
      "52           6  139797732  140252392     25\n",
      "53           6  140293024  140905063     22\n",
      "54           6  140939171  142310445     62\n",
      "55           6  151923886  152073221     15\n",
      "56           6  152086678  152409827     33\n",
      "57           6  152417607  153905878    133\n",
      "58           7   54100285   55448490     97\n",
      "59           7  112637687  118300098    386\n",
      "60           7  151340103  151554620     20\n",
      "61           7  151573687  153083628     75\n",
      "62           8     184617     808139     63\n",
      "63           8     822927    1136619     36\n",
      "64           8    1152551    2563316    132\n",
      "65           8    2586264    3627077    113\n",
      "66           8    3635646    4294791     74\n",
      "67           8    4299996    4692082     48\n",
      "68           8    4708444    5657660     43\n",
      "69           8    5952862    6907624     98\n",
      "70           8   12623479   14185328    128\n",
      "71           8   14193778   14291793     13\n",
      "72           8   16373516   16668380     15\n",
      "73           8   19181564   21447923    139\n",
      "74           8   22663858   23132039     58\n",
      "75           8   23137151   25096564    149\n",
      "76           8   25114132   25774629     65\n",
      "77           8   25782621   26587838     77\n",
      "78           8   28883487   29205723     37\n",
      "79           8   34104577   34785140     34\n",
      "80           8   35875555   36133992     12\n",
      "81           8   41575958   42118548     55\n",
      "82           8   42191493   42325689     15\n",
      "83           8   88534367   91007791    133\n",
      "84           8   91015577   92330975    109\n",
      "85           9    7751878   10013842    181\n",
      "86           9   36418729   37260341     73\n",
      "87          10    7653937    9348858    103\n",
      "88          10   27375620   30712263    281\n",
      "89          10   89253592   89696646     47\n",
      "90          10  123051158  123681745     63\n",
      "91          11     297092    3320321    373\n",
      "92          11   68972488   69191919     16\n",
      "93          11   80263397   80790766     17\n",
      "94          11   82599955   82867442     25\n",
      "95          11   83733321   85064586    126\n",
      "96          11   89496302   95731868    491\n",
      "97          11  107409719  109050102    128\n",
      "98          11  124303180  130667119    520\n",
      "99          12   12157656   12837059     85\n",
      "100         12   49299695   51238169    253\n",
      "101         12   64727853   66012212     99\n",
      "102         12   66035532   66948440     56\n",
      "103         12   75396411   75693696     24\n",
      "104         12   77023447   82859962    422\n",
      "105         12  112932396  115188305    114\n",
      "106         13   31768319   33387727    173\n",
      "107         13   47691104   47937120     32\n",
      "108         13   47948924   51937853    440\n",
      "109         14  103664534  104533357    133\n",
      "110         15   32796260   39569934    687\n",
      "111         15   48406757   51888263    353\n",
      "112         16   23257230   25462573    235\n",
      "113         16   63246412   66317225    283\n",
      "114         16   66324844   67303969    127\n",
      "115         16   67314736   68371045    124\n",
      "116         16   68880321   69381055     61\n",
      "117         16   69763173   70593293    100\n",
      "118         16   70601469   71161060     43\n",
      "119         16   86985669   88124384    145\n",
      "120         16   88130840   88690571     90\n",
      "121         17     465054     974692     73\n",
      "122         17    1302415    1427745     18\n",
      "123         17    1456417    1524691     12\n",
      "124         17    1542118    1560766     11\n",
      "125         17    1562322    1703117     23\n",
      "126         17    1718892    1845756     16\n",
      "127         17    1912424    2133315     24\n",
      "128         17    2145322    2286311     23\n",
      "129         17    2361350    2900841     61\n",
      "130         17    3393853    4388997    123\n",
      "131         17    4393276    4966472     93\n",
      "132         17    5343504    7517491    247\n",
      "133         17    7522884    8559106    145\n",
      "134         17    8567837    9872633    143\n",
      "135         17    9943837   11456680    128\n",
      "136         17   11469879   12854787    119\n",
      "137         17   13035306   15423538    134\n",
      "138         17   25179301   25520058     42\n",
      "139         17   26424460   26602264     18\n",
      "140         17   26617118   26763588     21\n",
      "141         17   31182810   31330891     23\n",
      "142         17   31334408   31456645     22\n",
      "143         17   35076296   35282086     29\n",
      "144         17   36861607   37014754     31\n",
      "145         17   37416931   38029088     90\n",
      "146         17   38077519   38710043     88\n",
      "147         17   38784700   39114890     35\n",
      "148         17   39139634   39275931     20\n",
      "149         17   39280577   40847517    203\n",
      "150         17   41062669   41447005     37\n",
      "151         17   42161364   42296514     18\n",
      "152         17   42301553   42639030     37\n",
      "153         17   42648686   42873571     24\n",
      "154         17   57117999   57372913     30\n",
      "155         19     763067    2336468    217\n",
      "156         21   34810804   35118077     40\n",
      "157         21   35162506   35255874     14\n",
      "158         21   35266227   36466945    115\n",
      "159         22   26999547   27819338     82\n",
      "160         22   37803663   38961219    155\n",
      "161         22   41307174   41912419     90\n",
      "162         23   66527817   67559319     90\n",
      "163         23  145164724  149589730    314\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# #Loading data\n",
    "patients = X.values.tolist()\n",
    "\n",
    "## FEATURE SELECTION\n",
    "\n",
    "# we need to shift the features by 1 since the chi2 function does not take non-negative values\n",
    "patients_shift = []\n",
    "\n",
    "for patient in patients:\n",
    "    x = []\n",
    "    for feature in patient:\n",
    "        x.append(int(feature) + 1)\n",
    "    patients_shift.append(x)\n",
    "\n",
    "chi, p_val = chi2(patients_shift, Y)\n",
    "\n",
    "imp_genes_p_values = []\n",
    "\n",
    "for i, j in enumerate(important_genes):\n",
    "    if p_val[j] >= 0.05:\n",
    "        imp_genes_p_values.append([imp_genes[i][0], j, p_val[j], \"No\"])\n",
    "    else:\n",
    "        imp_genes_p_values.append([imp_genes[i][0], j, p_val[j], \"Yes\"])\n",
    "    \n",
    "\n",
    "important_genes_scores = pd.DataFrame(imp_genes_p_values, columns=[\"Gene\", \"Region number\", \"P-value\", \"Yes/No\"])\n",
    "pd.set_option('display.max_rows', 75)\n",
    "print(important_genes_scores)\n",
    "\n",
    "X_feature_selected = X\n",
    "\n",
    "significant_features = []\n",
    "\n",
    "threshold = 0.05\n",
    "for i, val in enumerate(p_val):\n",
    "    # this drops the p_values higher than 0.05 that are not in the significant genes list\n",
    "    gene_temp = df_train.iloc[i].values.tolist()\n",
    "    \n",
    "    if val >= threshold and i not in important_genes or int(gene_temp[3]) < 10:\n",
    "        X_feature_selected = X_feature_selected.drop([i], axis=1)\n",
    "    else:\n",
    "        significant_features.append([gene_temp[0], gene_temp[1], gene_temp[2], gene_temp[3]])\n",
    "        \n",
    "sig_features_df = pd.DataFrame(significant_features, columns=[\"Chromosome\", \"Start\", \"End\", \"Nclone\"])\n",
    "pd.set_option('display.max_rows', 204)\n",
    "print(sig_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 164\n"
     ]
    }
   ],
   "source": [
    "X = X_feature_selected\n",
    "number_of_features = len(X.values.tolist()[0])\n",
    "print(\"Number of features = {}\".format(number_of_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[2184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = X\n",
    "X = []\n",
    "for val in new_X:\n",
    "    X.append(int(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    \"Scorer for the cross validation function\"\n",
    "    originalclass.extend(y_true)\n",
    "    predictedclass.extend(y_pred)\n",
    "    return accuracy_score(y_true, y_pred) \n",
    "\n",
    "def evaluate_model(model, features, labels):\n",
    "    \"Gets the cross validation score using a 5-fold (cv=5) cross validation\"\n",
    "    scores = cross_val_score(model, features, labels, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cross_validation(MODEL, PARAMS, X, Y, NUM_TRIALS):\n",
    "    model_scores = np.zeros(NUM_TRIALS)\n",
    "    model_params = {}\n",
    "    nested_scores = []\n",
    "    \n",
    "    for i in range(NUM_TRIALS):\n",
    "        print(\"Running Trial {}...\".format(i + 1))\n",
    "        inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "        outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "        \n",
    "        model = GridSearchCV(estimator=MODEL, param_grid=PARAMS, cv=inner_cv, n_jobs=2)\n",
    "        model.fit(X, Y)\n",
    "        print(model.score(X, Y), model.best_params_)\n",
    "        model_scores[i] = model.score(X, Y)\n",
    "        model_params[i] = model.best_params_\n",
    "        \n",
    "        nested_score = cross_val_score(model, X=X, y=Y, cv=outer_cv)\n",
    "        nested_scores.append([nested_score.mean(), nested_score.std()])\n",
    "        print(nested_score.mean(), nested_score.std())\n",
    "        \n",
    "    return model_scores, model_params, nested_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Trial 1...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.63 0.06557438524302002\n",
      "Running Trial 2...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.5 0.14\n",
      "Running Trial 3...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.69 0.01732050807568874\n",
      "Running Trial 4...\n",
      "0.69 {'hidden_layer_sizes': 1, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.66 0.044721359549995794\n",
      "Running Trial 5...\n",
      "0.68 {'hidden_layer_sizes': 4, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.58 0.14\n",
      "Running Trial 6...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.55 0.11445523142259598\n",
      "Running Trial 7...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.47 0.1109053650640942\n",
      "Running Trial 8...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.66 0.020000000000000018\n",
      "Running Trial 9...\n",
      "0.69 {'hidden_layer_sizes': 4, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.6699999999999999 0.04358898943540674\n",
      "Running Trial 10...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.55 0.1307669683062202\n",
      "Running Trial 11...\n",
      "0.68 {'hidden_layer_sizes': 1, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 12...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.5900000000000001 0.1452583904633395\n",
      "Running Trial 13...\n",
      "0.36 {'hidden_layer_sizes': 2, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.59 0.13379088160259656\n",
      "Running Trial 14...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.68 0.028284271247461888\n",
      "Running Trial 15...\n",
      "0.69 {'hidden_layer_sizes': 4, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.6900000000000001 0.03316624790355398\n",
      "Running Trial 16...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.6 0.1385640646055102\n",
      "Running Trial 17...\n",
      "0.69 {'hidden_layer_sizes': 4, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.61 0.15066519173319365\n",
      "Running Trial 18...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.64 0.04898979485566356\n",
      "Running Trial 19...\n",
      "0.69 {'hidden_layer_sizes': 4, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 20...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.64 0.04898979485566356\n",
      "Running Trial 21...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.5700000000000001 0.13076696830622023\n",
      "Running Trial 22...\n",
      "0.68 {'hidden_layer_sizes': 1, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.6900000000000001 0.017320508075688742\n",
      "Running Trial 23...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.55 0.11789826122551599\n",
      "Running Trial 24...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.62 0.150996688705415\n",
      "Running Trial 25...\n",
      "0.69 {'hidden_layer_sizes': 8, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.4600000000000001 0.15362291495737218\n",
      "Running Trial 26...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.63 0.06557438524302002\n",
      "Running Trial 27...\n",
      "0.36 {'hidden_layer_sizes': 1, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.52 0.16000000000000003\n",
      "Running Trial 28...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 29...\n",
      "0.69 {'hidden_layer_sizes': 1, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.6100000000000001 0.04358898943540674\n",
      "Running Trial 30...\n",
      "0.36 {'hidden_layer_sizes': 1, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.68 0.05656854249492382\n",
      "Running Trial 31...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.58 0.13114877048604004\n",
      "Running Trial 32...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.6300000000000001 0.043588989435406726\n",
      "Running Trial 33...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.63 0.051961524227066326\n",
      "Running Trial 34...\n",
      "0.68 {'hidden_layer_sizes': 1, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.5900000000000001 0.05916079783099616\n",
      "Running Trial 35...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.68 0.028284271247461888\n",
      "Running Trial 36...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.58 0.128062484748657\n",
      "Running Trial 37...\n",
      "0.36 {'hidden_layer_sizes': 2, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.64 0.06324555320336757\n",
      "Running Trial 38...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.68 0.05656854249492382\n",
      "Running Trial 39...\n",
      "0.69 {'hidden_layer_sizes': 4, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.59 0.1396424004376894\n",
      "Running Trial 40...\n",
      "0.69 {'hidden_layer_sizes': 4, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.68 0.0\n",
      "Running Trial 41...\n",
      "0.69 {'hidden_layer_sizes': 6, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.6 0.1385640646055102\n",
      "Running Trial 42...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.47 0.11789826122551597\n",
      "Running Trial 43...\n",
      "0.68 {'hidden_layer_sizes': 1, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.67 0.07141428428542848\n",
      "Running Trial 44...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.66 0.05999999999999998\n",
      "Running Trial 45...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.48 0.14696938456699069\n",
      "Running Trial 46...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.53 0.12124355652982143\n",
      "Running Trial 47...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.6000000000000001 0.1414213562373095\n",
      "Running Trial 48...\n",
      "0.69 {'hidden_layer_sizes': 4, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.63 0.051961524227066326\n",
      "Running Trial 49...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.6100000000000001 0.1452583904633395\n",
      "Running Trial 50...\n",
      "0.68 {'hidden_layer_sizes': 5, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.64 0.0692820323027551\n",
      "Running Trial 51...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.66 0.020000000000000018\n",
      "Running Trial 52...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.6000000000000001 0.1385640646055102\n",
      "Running Trial 53...\n",
      "0.36 {'hidden_layer_sizes': 3, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.68 0.028284271247461888\n",
      "Running Trial 54...\n",
      "0.68 {'hidden_layer_sizes': 3, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.6300000000000001 0.043588989435406726\n",
      "Running Trial 55...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.61 0.033166247903553984\n",
      "Running Trial 56...\n",
      "0.69 {'hidden_layer_sizes': 4, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 57...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.51 0.099498743710662\n",
      "Running Trial 58...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.63 0.059160797830996134\n",
      "Running Trial 59...\n",
      "0.69 {'hidden_layer_sizes': 4, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.63 0.033166247903554026\n",
      "Running Trial 60...\n",
      "0.68 {'hidden_layer_sizes': 1, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.56 0.0894427190999916\n",
      "Running Trial 61...\n",
      "0.68 {'hidden_layer_sizes': 1, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 62...\n",
      "0.68 {'hidden_layer_sizes': 3, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.5800000000000001 0.13114877048604004\n",
      "Running Trial 63...\n",
      "0.36 {'hidden_layer_sizes': 1, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.68 0.0\n",
      "Running Trial 64...\n",
      "0.69 {'hidden_layer_sizes': 1, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.6 0.14142135623730953\n",
      "Running Trial 65...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.6000000000000001 0.1385640646055102\n",
      "Running Trial 66...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.6 0.14142135623730953\n",
      "Running Trial 67...\n",
      "0.69 {'hidden_layer_sizes': 7, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.5700000000000001 0.13076696830622023\n",
      "Running Trial 68...\n",
      "0.68 {'hidden_layer_sizes': 4, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.5700000000000001 0.13076696830622023\n",
      "Running Trial 69...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.6900000000000001 0.017320508075688742\n",
      "Running Trial 70...\n",
      "0.69 {'hidden_layer_sizes': 5, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.5800000000000001 0.09165151389911681\n",
      "Running Trial 71...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.6 0.14142135623730953\n",
      "Running Trial 72...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69 {'hidden_layer_sizes': 1, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.67 0.04358898943540674\n",
      "Running Trial 73...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.6500000000000001 0.05196152422706632\n",
      "Running Trial 74...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 75...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.5900000000000001 0.1396424004376894\n",
      "Running Trial 76...\n",
      "0.68 {'hidden_layer_sizes': 1, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.5900000000000001 0.13379088160259656\n",
      "Running Trial 77...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.67 0.033166247903553984\n",
      "Running Trial 78...\n",
      "0.69 {'hidden_layer_sizes': 4, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.44999999999999996 0.09110433579144302\n",
      "Running Trial 79...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.5700000000000001 0.12449899597988735\n",
      "Running Trial 80...\n",
      "0.68 {'hidden_layer_sizes': 1, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.6900000000000001 0.06557438524302002\n",
      "Running Trial 81...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 82...\n",
      "0.68 {'hidden_layer_sizes': 1, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.65 0.07681145747868608\n",
      "Running Trial 83...\n",
      "0.68 {'hidden_layer_sizes': 1, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.5700000000000001 0.08660254037844388\n",
      "Running Trial 84...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.6399999999999999 0.04898979485566356\n",
      "Running Trial 85...\n",
      "0.69 {'hidden_layer_sizes': 7, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.65 0.05196152422706632\n",
      "Running Trial 86...\n",
      "0.69 {'hidden_layer_sizes': 5, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.66 0.0447213595499958\n",
      "Running Trial 87...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.6100000000000001 0.05916079783099617\n",
      "Running Trial 88...\n",
      "0.36 {'hidden_layer_sizes': 1, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.6500000000000001 0.07681145747868608\n",
      "Running Trial 89...\n",
      "0.69 {'hidden_layer_sizes': 7, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.51 0.08660254037844389\n",
      "Running Trial 90...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.5800000000000001 0.11489125293076058\n",
      "Running Trial 91...\n",
      "0.69 {'hidden_layer_sizes': 3, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.6200000000000001 0.06\n",
      "Running Trial 92...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.66 0.020000000000000018\n",
      "Running Trial 93...\n",
      "0.68 {'hidden_layer_sizes': 1, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.5900000000000001 0.07141428428542851\n",
      "Running Trial 94...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.6900000000000001 0.03316624790355398\n",
      "Running Trial 95...\n",
      "0.68 {'hidden_layer_sizes': 2, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.66 0.020000000000000018\n",
      "Running Trial 96...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.64 0.040000000000000036\n",
      "Running Trial 97...\n",
      "0.69 {'hidden_layer_sizes': 2, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 98...\n",
      "0.69 {'hidden_layer_sizes': 4, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.64 0.040000000000000036\n",
      "Running Trial 99...\n",
      "0.36 {'hidden_layer_sizes': 1, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.6000000000000001 0.1414213562373095\n",
      "Running Trial 100...\n",
      "0.68 {'hidden_layer_sizes': 1, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.5800000000000001 0.13114877048604004\n"
     ]
    }
   ],
   "source": [
    "parameters = {'solver': ['lbfgs'], \n",
    "              'max_iter': [500, 1000, 1500, 2000], \n",
    "              'hidden_layer_sizes':np.linspace(1, 10, 10, dtype=int)\n",
    "             }\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "mlp_scores, mlp_params, mlp_nested = nested_cross_validation(mlp, parameters, X, Y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Trial 1...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 22}\n",
      "0.62 0.060000000000000005\n",
      "Running Trial 2...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 22}\n",
      "0.68 0.028284271247461888\n",
      "Running Trial 3...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 39}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 4...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 11}\n",
      "0.63 0.01732050807568879\n",
      "Running Trial 5...\n",
      "0.66 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.65 0.1244989959798873\n",
      "Running Trial 6...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 6}\n",
      "0.6300000000000001 0.043588989435406726\n",
      "Running Trial 7...\n",
      "0.66 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.64 0.040000000000000036\n",
      "Running Trial 8...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.6400000000000001 0.04898979485566356\n",
      "Running Trial 9...\n",
      "0.66 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.63 0.06557438524302002\n",
      "Running Trial 10...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 33}\n",
      "0.6300000000000001 0.06557438524302002\n",
      "Running Trial 11...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 6}\n",
      "0.6100000000000001 0.051961524227066305\n",
      "Running Trial 12...\n",
      "0.66 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.63 0.051961524227066326\n",
      "Running Trial 13...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 44}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 14...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 22}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 15...\n",
      "0.68 {'max_features': 'sqrt', 'n_estimators': 6}\n",
      "0.6900000000000001 0.03316624790355398\n",
      "Running Trial 16...\n",
      "0.66 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.66 0.020000000000000018\n",
      "Running Trial 17...\n",
      "0.66 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.6400000000000001 0.04898979485566356\n",
      "Running Trial 18...\n",
      "0.67 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.6000000000000001 0.03999999999999998\n",
      "Running Trial 19...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 6}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 20...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 11}\n",
      "0.5700000000000001 0.017320508075688742\n",
      "Running Trial 21...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.6500000000000001 0.05196152422706632\n",
      "Running Trial 22...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 6}\n",
      "0.67 0.033166247903553984\n",
      "Running Trial 23...\n",
      "0.67 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 24...\n",
      "0.68 {'max_features': 'auto', 'n_estimators': 39}\n",
      "0.6200000000000001 0.06633249580710801\n",
      "Running Trial 25...\n",
      "0.68 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.6300000000000001 0.051961524227066326\n",
      "Running Trial 26...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.62 0.060000000000000005\n",
      "Running Trial 27...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.6900000000000001 0.017320508075688742\n",
      "Running Trial 28...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 29...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.64 0.040000000000000036\n",
      "Running Trial 30...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 11}\n",
      "0.6000000000000001 0.04898979485566356\n",
      "Running Trial 31...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.63 0.051961524227066326\n",
      "Running Trial 32...\n",
      "0.68 {'max_features': 'auto', 'n_estimators': 11}\n",
      "0.64 0.028284271247461926\n",
      "Running Trial 33...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 11}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 34...\n",
      "0.67 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.6100000000000001 0.07141428428542851\n",
      "Running Trial 35...\n",
      "0.67 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.66 0.03464101615137758\n",
      "Running Trial 36...\n",
      "0.67 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.62 0.044721359549995794\n",
      "Running Trial 37...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 44}\n",
      "0.66 0.06633249580710801\n",
      "Running Trial 38...\n",
      "0.63 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.67 0.04358898943540674\n",
      "Running Trial 39...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.62 0.05999999999999998\n",
      "Running Trial 40...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 28}\n",
      "0.68 0.0\n",
      "Running Trial 41...\n",
      "0.66 {'max_features': 'auto', 'n_estimators': 22}\n",
      "0.67 0.033166247903553984\n",
      "Running Trial 42...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 22}\n",
      "0.5800000000000001 0.04472135954999579\n",
      "Running Trial 43...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 17}\n",
      "0.6300000000000001 0.051961524227066326\n",
      "Running Trial 44...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.6200000000000001 0.06\n",
      "Running Trial 45...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.65 0.099498743710662\n",
      "Running Trial 46...\n",
      "0.63 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.6 0.08485281374238571\n",
      "Running Trial 47...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 33}\n",
      "0.64 0.028284271247461926\n",
      "Running Trial 48...\n",
      "0.68 {'max_features': 'auto', 'n_estimators': 11}\n",
      "0.6000000000000001 0.04898979485566356\n",
      "Running Trial 49...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 28}\n",
      "0.66 0.03464101615137758\n",
      "Running Trial 50...\n",
      "0.66 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.63 0.07681145747868608\n",
      "Running Trial 51...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 33}\n",
      "0.64 0.028284271247461926\n",
      "Running Trial 52...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 50}\n",
      "0.68 0.028284271247461888\n",
      "Running Trial 53...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.6900000000000001 0.017320508075688742\n",
      "Running Trial 54...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 44}\n",
      "0.65 0.01732050807568879\n",
      "Running Trial 55...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.65 0.01732050807568879\n",
      "Running Trial 56...\n",
      "0.68 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.69 0.05916079783099616\n",
      "Running Trial 57...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.5800000000000001 0.04472135954999579\n",
      "Running Trial 58...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 17}\n",
      "0.6200000000000001 0.0447213595499958\n",
      "Running Trial 59...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.6200000000000001 0.044721359549995794\n",
      "Running Trial 60...\n",
      "0.67 {'max_features': 'auto', 'n_estimators': 11}\n",
      "0.59 0.091104335791443\n",
      "Running Trial 61...\n",
      "0.66 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.66 0.03464101615137758\n",
      "Running Trial 62...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.66 0.03464101615137758\n",
      "Running Trial 63...\n",
      "0.67 {'max_features': 'auto', 'n_estimators': 6}\n",
      "0.62 0.020000000000000018\n",
      "Running Trial 64...\n",
      "0.67 {'max_features': 'auto', 'n_estimators': 22}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 65...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 6}\n",
      "0.68 0.0\n",
      "Running Trial 66...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 39}\n",
      "0.67 0.033166247903553984\n",
      "Running Trial 67...\n",
      "0.67 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.68 0.04898979485566356\n",
      "Running Trial 68...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.6699999999999999 0.033166247903553984\n",
      "Running Trial 69...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 6}\n",
      "0.6699999999999999 0.04358898943540674\n",
      "Running Trial 70...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 11}\n",
      "0.5800000000000001 0.09165151389911681\n",
      "Running Trial 71...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 39}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 72...\n",
      "0.66 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.6300000000000001 0.051961524227066326\n",
      "Running Trial 73...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 11}\n",
      "0.6000000000000001 0.028284271247461888\n",
      "Running Trial 74...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.6399999999999999 0.04898979485566356\n",
      "Running Trial 75...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 11}\n",
      "0.71 0.017320508075688742\n",
      "Running Trial 76...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 6}\n",
      "0.6200000000000001 0.034641016151377525\n",
      "Running Trial 77...\n",
      "0.68 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.67 0.07681145747868606\n",
      "Running Trial 78...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 6}\n",
      "0.63 0.051961524227066326\n",
      "Running Trial 79...\n",
      "0.64 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.64 0.040000000000000036\n",
      "Running Trial 80...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 28}\n",
      "0.64 0.028284271247461926\n",
      "Running Trial 81...\n",
      "0.68 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.62 0.020000000000000018\n",
      "Running Trial 82...\n",
      "0.67 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.6100000000000001 0.07141428428542851\n",
      "Running Trial 83...\n",
      "0.67 {'max_features': 'sqrt', 'n_estimators': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63 0.051961524227066326\n",
      "Running Trial 84...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.65 0.07141428428542847\n",
      "Running Trial 85...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 28}\n",
      "0.69 0.043588989435406726\n",
      "Running Trial 86...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 6}\n",
      "0.68 0.028284271247461888\n",
      "Running Trial 87...\n",
      "0.68 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.5800000000000001 0.04472135954999579\n",
      "Running Trial 88...\n",
      "0.68 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.63 0.059160797830996134\n",
      "Running Trial 89...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 28}\n",
      "0.6500000000000001 0.05916079783099614\n",
      "Running Trial 90...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 33}\n",
      "0.62 0.08246211251235319\n",
      "Running Trial 91...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 11}\n",
      "0.5900000000000001 0.03316624790355398\n",
      "Running Trial 92...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 39}\n",
      "0.65 0.01732050807568879\n",
      "Running Trial 93...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 1}\n",
      "0.5900000000000001 0.07141428428542851\n",
      "Running Trial 94...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 39}\n",
      "0.7000000000000001 0.019999999999999962\n",
      "Running Trial 95...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.6200000000000001 0.060000000000000005\n",
      "Running Trial 96...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 97...\n",
      "0.68 {'max_features': 'auto', 'n_estimators': 33}\n",
      "0.6799999999999999 0.028284271247461888\n",
      "Running Trial 98...\n",
      "0.66 {'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 99...\n",
      "0.69 {'max_features': 'sqrt', 'n_estimators': 6}\n",
      "0.6400000000000001 0.04898979485566356\n",
      "Running Trial 100...\n",
      "0.69 {'max_features': 'auto', 'n_estimators': 33}\n",
      "0.64 0.040000000000000036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1, stop = 50, num = 10, dtype=int)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Create the random grid\n",
    "parameters = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_scores, rf_params, rf_nested = nested_cross_validation(rf, parameters, X, Y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Trial 1...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.63 0.06557438524302002\n",
      "Running Trial 2...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.66 0.0447213595499958\n",
      "Running Trial 3...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6799999999999999 0.028284271247461888\n",
      "Running Trial 4...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.67 0.033166247903553984\n",
      "Running Trial 5...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.5900000000000001 0.05916079783099616\n",
      "Running Trial 6...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6300000000000001 0.043588989435406726\n",
      "Running Trial 7...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.64 0.040000000000000036\n",
      "Running Trial 8...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6400000000000001 0.04898979485566356\n",
      "Running Trial 9...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6699999999999999 0.04358898943540674\n",
      "Running Trial 10...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.62 0.07211102550927977\n",
      "Running Trial 11...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 12...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.67 0.04358898943540674\n",
      "Running Trial 13...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.69 0.03316624790355398\n",
      "Running Trial 14...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.68 0.028284271247461888\n",
      "Running Trial 15...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.68 0.028284271247461888\n",
      "Running Trial 16...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 17...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6400000000000001 0.04898979485566356\n",
      "Running Trial 18...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6100000000000001 0.05196152422706631\n",
      "Running Trial 19...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.65 0.059160797830996134\n",
      "Running Trial 20...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6100000000000001 0.05196152422706631\n",
      "Running Trial 21...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6400000000000001 0.06324555320336757\n",
      "Running Trial 22...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6900000000000001 0.03316624790355398\n",
      "Running Trial 23...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.63 0.051961524227066326\n",
      "Running Trial 24...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.66 0.08246211251235319\n",
      "Running Trial 25...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6500000000000001 0.05916079783099614\n",
      "Running Trial 26...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.62 0.060000000000000005\n",
      "Running Trial 27...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.63 0.051961524227066326\n",
      "Running Trial 28...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.63 0.033166247903554026\n",
      "Running Trial 29...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.5900000000000001 0.01732050807568874\n",
      "Running Trial 30...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6100000000000001 0.04358898943540674\n",
      "Running Trial 31...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.67 0.04358898943540674\n",
      "Running Trial 32...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6300000000000001 0.043588989435406726\n",
      "Running Trial 33...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.64 0.06324555320336757\n",
      "Running Trial 34...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6100000000000001 0.07141428428542851\n",
      "Running Trial 35...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6900000000000001 0.017320508075688742\n",
      "Running Trial 36...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6 0.028284271247461888\n",
      "Running Trial 37...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.64 0.06324555320336757\n",
      "Running Trial 38...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.64 0.040000000000000036\n",
      "Running Trial 39...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 40...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6900000000000001 0.017320508075688742\n",
      "Running Trial 41...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 42...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.5800000000000001 0.04472135954999579\n",
      "Running Trial 43...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6000000000000001 0.04898979485566356\n",
      "Running Trial 44...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.63 0.07141428428542847\n",
      "Running Trial 45...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6 0.08485281374238571\n",
      "Running Trial 46...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6 0.07483314773547885\n",
      "Running Trial 47...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.68 0.028284271247461888\n",
      "Running Trial 48...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.61 0.04358898943540674\n",
      "Running Trial 49...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6500000000000001 0.05196152422706632\n",
      "Running Trial 50...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6599999999999999 0.08246211251235319\n",
      "Running Trial 51...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6900000000000001 0.03316624790355398\n",
      "Running Trial 52...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.69 0.03316624790355398\n",
      "Running Trial 53...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 54...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6300000000000001 0.043588989435406726\n",
      "Running Trial 55...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.63 0.043588989435406726\n",
      "Running Trial 56...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.63 0.051961524227066326\n",
      "Running Trial 57...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.56 0.028284271247461888\n",
      "Running Trial 58...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.63 0.059160797830996134\n",
      "Running Trial 59...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6200000000000001 0.044721359549995794\n",
      "Running Trial 60...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.59 0.091104335791443\n",
      "Running Trial 61...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.65 0.051961524227066326\n",
      "Running Trial 62...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.67 0.04358898943540674\n",
      "Running Trial 63...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 64...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.66 0.0447213595499958\n",
      "Running Trial 65...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6900000000000001 0.017320508075688742\n",
      "Running Trial 66...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.66 0.0447213595499958\n",
      "Running Trial 67...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6400000000000001 0.04898979485566356\n",
      "Running Trial 68...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6400000000000001 0.04898979485566356\n",
      "Running Trial 69...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.63 0.05196152422706632\n",
      "Running Trial 70...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6100000000000001 0.051961524227066305\n",
      "Running Trial 71...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.65 0.033166247903554026\n",
      "Running Trial 72...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6300000000000001 0.051961524227066326\n",
      "Running Trial 73...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6500000000000001 0.05196152422706632\n",
      "Running Trial 74...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.63 0.033166247903554026\n",
      "Running Trial 75...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6699999999999999 0.04358898943540674\n",
      "Running Trial 76...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6300000000000001 0.043588989435406726\n",
      "Running Trial 77...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.64 0.028284271247461926\n",
      "Running Trial 78...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.56 0.028284271247461888\n",
      "Running Trial 79...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.67 0.04358898943540674\n",
      "Running Trial 80...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.64 0.028284271247461926\n",
      "Running Trial 81...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 82...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6100000000000001 0.07141428428542851\n",
      "Running Trial 83...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6000000000000001 0.04898979485566356\n",
      "Running Trial 84...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6599999999999999 0.06\n",
      "Running Trial 85...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.64 0.04898979485566356\n",
      "Running Trial 86...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.63 0.059160797830996134\n",
      "Running Trial 87...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6100000000000001 0.05916079783099617\n",
      "Running Trial 88...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.64 0.06324555320336757\n",
      "Running Trial 89...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6300000000000001 0.07141428428542848\n",
      "Running Trial 90...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.66 0.05999999999999998\n",
      "Running Trial 91...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6200000000000001 0.06\n",
      "Running Trial 92...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 93...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.55 0.05196152422706632\n",
      "Running Trial 94...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.67 0.01732050807568879\n",
      "Running Trial 95...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.64 0.028284271247461926\n",
      "Running Trial 96...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.63 0.033166247903554026\n",
      "Running Trial 97...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.69 0.03316624790355398\n",
      "Running Trial 98...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.66 0.0447213595499958\n",
      "Running Trial 99...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.6400000000000001 0.056568542494923775\n",
      "Running Trial 100...\n",
      "0.69 {'var_smoothing': 1e-05}\n",
      "0.65 0.051961524227066326\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "          \"var_smoothing\" : [1e-5, 1e-9]\n",
    "}\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb_scores, nb_params, nb_nested = nested_cross_validation(nb, params, X, Y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "result_columns = [\"Model\", \"Trial\", \"Parameters\", \"Accuracy\", \"Std_dev\"]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    result_list.append([\"NB\", i, nb_params[i], nb_nested[i][0], nb_nested[i][1]])\n",
    "    \n",
    "nb_df = pd.DataFrame(result_list,columns=result_columns)\n",
    "\n",
    "nb_df.to_csv(\"NB_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "result_columns = [\"Model\", \"Trial\", \"Parameters\", \"Accuracy\", \"Std_dev\"]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    result_list.append([\"MLP\", i, mlp_params[i], mlp_nested[i][0], mlp_nested[i][1]])\n",
    "    \n",
    "mlp_df = pd.DataFrame(result_list,columns=result_columns)\n",
    "\n",
    "mlp_df.to_csv(\"MLP_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "result_columns = [\"Model\", \"Trial\", \"Parameters\", \"Accuracy\", \"Std_dev\"]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    result_list.append([\"RF\", i, rf_params[i], rf_nested[i][0], rf_nested[i][1]])\n",
    "    \n",
    "rf_df = pd.DataFrame(result_list,columns=result_columns)\n",
    "\n",
    "rf_df.to_csv(\"RF_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp1 = np.array(mlp_nested)[:,0] \n",
    "temp2 = np.array(rf_nested)[:,0]\n",
    "temp3 = np.array(nb_nested)[:,0]\n",
    "\n",
    "# print(temp1)\n",
    "\n",
    "plt.boxplot([temp1, temp2, temp3], vert=0, labels=['MLP', 'RF', \"NB\"])\n",
    "plt.savefig(\"boxplot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 170 (0.113050)\n",
      "2. feature 201 (0.016140)\n",
      "3. feature 181 (0.015683)\n",
      "4. feature 26 (0.014354)\n",
      "5. feature 55 (0.014103)\n",
      "6. feature 3 (0.013284)\n",
      "7. feature 187 (0.013182)\n",
      "8. feature 17 (0.013129)\n",
      "9. feature 198 (0.013081)\n",
      "10. feature 123 (0.013056)\n",
      "11. feature 185 (0.012242)\n",
      "12. feature 188 (0.011577)\n",
      "13. feature 113 (0.011234)\n",
      "14. feature 41 (0.010344)\n",
      "15. feature 179 (0.010288)\n",
      "16. feature 122 (0.010015)\n",
      "17. feature 121 (0.009961)\n",
      "18. feature 136 (0.009958)\n",
      "19. feature 29 (0.009850)\n",
      "20. feature 18 (0.009226)\n",
      "21. feature 4 (0.009071)\n",
      "22. feature 186 (0.008986)\n",
      "23. feature 129 (0.008790)\n",
      "24. feature 199 (0.008763)\n",
      "25. feature 31 (0.008748)\n",
      "26. feature 54 (0.008368)\n",
      "27. feature 115 (0.007871)\n",
      "28. feature 174 (0.007802)\n",
      "29. feature 197 (0.007720)\n",
      "30. feature 140 (0.007683)\n",
      "31. feature 19 (0.007662)\n",
      "32. feature 138 (0.007483)\n",
      "33. feature 114 (0.007390)\n",
      "34. feature 200 (0.007148)\n",
      "35. feature 139 (0.007107)\n",
      "36. feature 33 (0.006964)\n",
      "37. feature 47 (0.006854)\n",
      "38. feature 182 (0.006840)\n",
      "39. feature 53 (0.006718)\n",
      "40. feature 75 (0.006668)\n",
      "41. feature 124 (0.006539)\n",
      "42. feature 27 (0.006456)\n",
      "43. feature 61 (0.006436)\n",
      "44. feature 102 (0.006384)\n",
      "45. feature 180 (0.006336)\n",
      "46. feature 120 (0.006319)\n",
      "47. feature 175 (0.006269)\n",
      "48. feature 178 (0.006261)\n",
      "49. feature 7 (0.006091)\n",
      "50. feature 16 (0.006072)\n",
      "51. feature 130 (0.005820)\n",
      "52. feature 51 (0.005795)\n",
      "53. feature 135 (0.005723)\n",
      "54. feature 40 (0.005693)\n",
      "55. feature 1 (0.005679)\n",
      "56. feature 49 (0.005666)\n",
      "57. feature 25 (0.005570)\n",
      "58. feature 64 (0.005513)\n",
      "59. feature 97 (0.005436)\n",
      "60. feature 183 (0.005428)\n",
      "61. feature 42 (0.005262)\n",
      "62. feature 35 (0.005193)\n",
      "63. feature 36 (0.005151)\n",
      "64. feature 149 (0.005143)\n",
      "65. feature 32 (0.005106)\n",
      "66. feature 56 (0.005103)\n",
      "67. feature 189 (0.004962)\n",
      "68. feature 74 (0.004946)\n",
      "69. feature 165 (0.004943)\n",
      "70. feature 22 (0.004894)\n",
      "71. feature 24 (0.004871)\n",
      "72. feature 50 (0.004863)\n",
      "73. feature 30 (0.004833)\n",
      "74. feature 0 (0.004815)\n",
      "75. feature 133 (0.004739)\n",
      "76. feature 119 (0.004571)\n",
      "77. feature 23 (0.004499)\n",
      "78. feature 101 (0.004497)\n",
      "79. feature 15 (0.004493)\n",
      "80. feature 52 (0.004430)\n",
      "81. feature 12 (0.004428)\n",
      "82. feature 79 (0.004398)\n",
      "83. feature 37 (0.004394)\n",
      "84. feature 60 (0.004348)\n",
      "85. feature 116 (0.004327)\n",
      "86. feature 137 (0.004313)\n",
      "87. feature 8 (0.004298)\n",
      "88. feature 152 (0.004296)\n",
      "89. feature 100 (0.004280)\n",
      "90. feature 98 (0.004257)\n",
      "91. feature 132 (0.004163)\n",
      "92. feature 28 (0.004150)\n",
      "93. feature 117 (0.004111)\n",
      "94. feature 126 (0.003844)\n",
      "95. feature 131 (0.003778)\n",
      "96. feature 48 (0.003684)\n",
      "97. feature 58 (0.003669)\n",
      "98. feature 111 (0.003650)\n",
      "99. feature 203 (0.003633)\n",
      "100. feature 103 (0.003614)\n",
      "101. feature 145 (0.003524)\n",
      "102. feature 155 (0.003467)\n",
      "103. feature 202 (0.003454)\n",
      "104. feature 68 (0.003449)\n",
      "105. feature 110 (0.003430)\n",
      "106. feature 151 (0.003372)\n",
      "107. feature 96 (0.003354)\n",
      "108. feature 141 (0.003316)\n",
      "109. feature 142 (0.003314)\n",
      "110. feature 10 (0.003311)\n",
      "111. feature 44 (0.003268)\n",
      "112. feature 76 (0.003175)\n",
      "113. feature 184 (0.003130)\n",
      "114. feature 14 (0.003038)\n",
      "115. feature 9 (0.003030)\n",
      "116. feature 134 (0.003008)\n",
      "117. feature 150 (0.002996)\n",
      "118. feature 99 (0.002974)\n",
      "119. feature 92 (0.002960)\n",
      "120. feature 106 (0.002881)\n",
      "121. feature 39 (0.002777)\n",
      "122. feature 86 (0.002697)\n",
      "123. feature 20 (0.002681)\n",
      "124. feature 46 (0.002665)\n",
      "125. feature 80 (0.002625)\n",
      "126. feature 144 (0.002606)\n",
      "127. feature 77 (0.002577)\n",
      "128. feature 57 (0.002567)\n",
      "129. feature 81 (0.002548)\n",
      "130. feature 62 (0.002529)\n",
      "131. feature 5 (0.002528)\n",
      "132. feature 73 (0.002499)\n",
      "133. feature 72 (0.002445)\n",
      "134. feature 66 (0.002381)\n",
      "135. feature 156 (0.002304)\n",
      "136. feature 177 (0.002275)\n",
      "137. feature 147 (0.002263)\n",
      "138. feature 172 (0.002254)\n",
      "139. feature 13 (0.002247)\n",
      "140. feature 128 (0.002242)\n",
      "141. feature 95 (0.002233)\n",
      "142. feature 65 (0.002231)\n",
      "143. feature 21 (0.002179)\n",
      "144. feature 43 (0.002163)\n",
      "145. feature 2 (0.002107)\n",
      "146. feature 70 (0.002088)\n",
      "147. feature 78 (0.002072)\n",
      "148. feature 125 (0.002064)\n",
      "149. feature 127 (0.002015)\n",
      "150. feature 11 (0.002014)\n",
      "151. feature 107 (0.001996)\n",
      "152. feature 148 (0.001973)\n",
      "153. feature 158 (0.001952)\n",
      "154. feature 166 (0.001929)\n",
      "155. feature 153 (0.001929)\n",
      "156. feature 162 (0.001922)\n",
      "157. feature 91 (0.001921)\n",
      "158. feature 105 (0.001876)\n",
      "159. feature 45 (0.001867)\n",
      "160. feature 118 (0.001856)\n",
      "161. feature 59 (0.001820)\n",
      "162. feature 173 (0.001767)\n",
      "163. feature 193 (0.001746)\n",
      "164. feature 93 (0.001702)\n",
      "165. feature 194 (0.001654)\n",
      "166. feature 89 (0.001598)\n",
      "167. feature 104 (0.001551)\n",
      "168. feature 108 (0.001521)\n",
      "169. feature 146 (0.001517)\n",
      "170. feature 6 (0.001474)\n",
      "171. feature 154 (0.001459)\n",
      "172. feature 94 (0.001444)\n",
      "173. feature 69 (0.001431)\n",
      "174. feature 168 (0.001425)\n",
      "175. feature 161 (0.001330)\n",
      "176. feature 112 (0.001310)\n",
      "177. feature 190 (0.001303)\n",
      "178. feature 157 (0.001302)\n",
      "179. feature 169 (0.001273)\n",
      "180. feature 109 (0.001195)\n",
      "181. feature 167 (0.001136)\n",
      "182. feature 85 (0.001121)\n",
      "183. feature 176 (0.001102)\n",
      "184. feature 34 (0.001071)\n",
      "185. feature 196 (0.001063)\n",
      "186. feature 63 (0.001021)\n",
      "187. feature 160 (0.000927)\n",
      "188. feature 191 (0.000912)\n",
      "189. feature 171 (0.000896)\n",
      "190. feature 71 (0.000896)\n",
      "191. feature 67 (0.000892)\n",
      "192. feature 82 (0.000872)\n",
      "193. feature 83 (0.000750)\n",
      "194. feature 159 (0.000729)\n",
      "195. feature 195 (0.000698)\n",
      "196. feature 88 (0.000669)\n",
      "197. feature 90 (0.000659)\n",
      "198. feature 84 (0.000658)\n",
      "199. feature 143 (0.000613)\n",
      "200. feature 38 (0.000551)\n",
      "201. feature 163 (0.000494)\n",
      "202. feature 192 (0.000424)\n",
      "203. feature 164 (0.000397)\n",
      "204. feature 87 (0.000254)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5hdVZnn8e+bSggCJQRQLkm4KaKoNDYRfMYLGRsQb8D0Iy3eGqdpM/YM4+PYto3aAg9KD6L2006LSkS8jiLCjEaNjSgERxRNgHBJIJKESxUBcodc6/rOH2st966TdapO1dmnTlXl93me85yz91577bVv611r7XOqzN0RERGpNa3dBRARkYlJAUJERLIUIEREJEsBQkREshQgREQkSwFCRESyFCBEhmFmXzWzT7W7HCLtYPodhLSCmT0GHAYMlGa/xN3XNZHnfOC77j6nudJNTmb2TaDb3f+p3WWRvYN6ENJKb3f3A0qvMQeHKpjZ9HZuvxlm1tHuMsjeRwFCxp2ZvcbMfmtmW83svtgzSMv+s5k9ZGbbzGytmf2XOH9/4OfAkWa2Pb6ONLNvmtlnSuvPN7Pu0vRjZvaPZnY/sMPMpsf1bjazDWb2qJl9aJiy/in/lLeZfczM1pvZU2Z2npm9xcz+aGabzewTpXUvN7ObzOwHcX/uMbM/Ky1/mZkticdhhZmdU7Pdr5jZYjPbAVwEvAf4WNz3n8R0l5jZmpj/SjP7T6U83m9mvzGzz5vZlrivby4tP9jMvmFm6+LyH5WWvc3Mlsey/dbMTiot+0czezJuc5WZ/UUDp10mI3fXS6/KX8BjwBmZ+bOBTcBbCA2UM+P0C+LytwIvAgw4HdgJ/HlcNp8wxFLO75vAZ0rTQ9LEciwH5gLPi9u8G7gU2Ac4DlgLvKnOfvwp/5h3f1x3BvABYAPwPaATeDmwGzgupr8c6APeEdN/FHg0fp4BrAY+EcvxRmAbcEJpu88Cr41l3rd2X2O684EjY5p3AjuAI+Ky98ftfwDoAP4OWEcxtPwz4AfArFie0+P8PwfWA6fF9S6Mx3EmcALQBRwZ0x4DvKjd15terXmpByGt9KPYAt1aap2+F1js7ovdfdDdbwWWEQIG7v4zd1/jwR3AL4DXN1mO/+XuXe6+C3g1IRhd4e697r4W+BpwQYN59QFXunsfcANwKPBFd9/m7iuAFcBJpfR3u/tNMf2/ECr618TXAcBVsRy3AT8F3lVa98fufmc8TrtzhXH3H7r7upjmB8AjwKmlJI+7+9fcfQD4FnAEcJiZHQG8Gfigu29x9754vCEElGvd/ffuPuDu3wJ6YpkHCIHiRDOb4e6PufuaBo+dTDIKENJK57n7QfF1Xpx3NHB+KXBsBV5HqLgwszeb2V1xuGYrIXAc2mQ5ukqfjyYMU5W3/wnCA/VGbIqVLcCu+P5MafkuQsW/x7bdfRDoJrT4jwS64rzkcUIPK1fuLDP769JQ0FbgFQw9Xk+Xtr8zfjyA0KPa7O5bMtkeDfx9zTGaS+g1rAY+TOgdrTezG8zsyJHKKZOTAoSMty7gO6XAcZC77+/uV5nZTOBm4PPAYe5+ELCYMNwEkPvK3Q5gv9L04Zk05fW6gEdrtt/p7m9pes/y5qYPZjYNmEMY5lkHzI3zkqOAJ+uUe49pMzua0Pu5GDgkHq8HKY7XcLqAg83soDrLrqw5Rvu5+/cB3P177v46QiBx4LMNbE8mIQUIGW/fBd5uZm8ysw4z2zc+/J1DGIufSRjX748PVM8qrfsMcIiZHViatxx4S3zgejihdTucPwDPxQetz4tleIWZvbqyPRzqFDP7SwvfoPowYajmLuD3hOD2MTObER/Uv50wbFXPM4RnJsn+hAp6A4QH/IQexIjc/SnCQ/8vm9msWIY3xMVfAz5oZqdZsL+ZvdXMOs3sBDN7Ywzmuwk9poE6m5FJTgFCxpW7dwHnEoZ1NhBaq/8ATHP3bcCHgBuBLcC7gUWldR8Gvg+sjUMfRwLfAe4jPET9BeGh63DbHyBUxCcTHhhvBK4DDhxuvSb8mPDweAvwPuAv43h/L3AO4TnARuDLwF/Hfazn64Sx/61m9iN3Xwl8AfgdIXi8ErhzFGV7H+GZysOEh9IfBnD3ZYTnEF+K5V5NeOANIYBfFcv8NPBCwrmUKUg/lBNpETO7HHixu7+33WURGQv1IEREJEsBQkREsjTEJCIiWepBiIhI1qT842WHHnqoH3PMMe0uhojIpHL33XdvdPcXNJp+UgaIY445hmXLlrW7GCIik4qZPT6a9BpiEhGRLAUIERHJUoAQEZEsBQgREclSgBARkSwFCBERyVKAEBGRLAUIERHJmpQBYtWqVcyfP7/dxRARmdImZYAQEZHWU4AQEZEsBQgREclSgBARkSwFCBERyVKAEBGRrEoChJmdbWarzGy1mV2SWf4RM1tpZveb2a/M7OjSsgEzWx5fi6ooj4iINK/pfxhkZh3ANcCZQDew1MwWufvKUrJ7gXnuvtPM/g64GnhnXLbL3U9uthwiIlKtKnoQpwKr3X2tu/cCNwDnlhO4++3uvjNO3gXMqWC7IiLSQlUEiNlAV2m6O86r5yLg56Xpfc1smZndZWbnVVAeERGpQBX/k9oy8zyb0Oy9wDzg9NLso9x9nZkdB9xmZg+4+5rMuguABQAzZ85svtQiIjKsKnoQ3cDc0vQcYF1tIjM7A/gkcI6796T57r4uvq8FlgCvym3E3Re6+zx3nzdjxowKii0iIsOpIkAsBY43s2PNbB/gAmDIt5HM7FXAtYTgsL40f5aZzYyfDwVeC5QfbouISJs0PcTk7v1mdjFwC9ABXO/uK8zsCmCZuy8CPgccAPzQzACecPdzgJcB15rZICFYXVXz7ScREWmTKp5B4O6LgcU18y4tfT6jznq/BV5ZRRlERKRa+iW1iIhkKUCIiEiWAoSIiGQpQIiISJYChIiIZClAiIhIlgKEiIhkKUCIiEiWAoSIiGQpQIiISJYChIiIZClAiIhIlgKEiIhkKUCIiEiWAoSIiGQpQIiISJYChIiIZClAiIhIlgKEiIhkKUCIiEiWAoSIiGQpQIiISJYChIiIZClAiIhIViUBwszONrNVZrbazC7JLP+Ima00s/vN7FdmdnRp2YVm9kh8XVhFeUREpHlNBwgz6wCuAd4MnAi8y8xOrEl2LzDP3U8CbgKujuseDFwGnAacClxmZrOaLZOIiDSvih7EqcBqd1/r7r3ADcC55QTufru774yTdwFz4uc3Abe6+2Z33wLcCpxdQZlERKRJVQSI2UBXabo7zqvnIuDno13XzBaY2TIzW9bX19dEcUVEpBHTK8jDMvM8m9DsvcA84PTRruvuC4GFAJ2dndk0IiJSnSp6EN3A3NL0HGBdbSIzOwP4JHCOu/eMZl0RERl/VQSIpcDxZnasme0DXAAsKicws1cB1xKCw/rSoluAs8xsVnw4fVacJyIibdb0EJO795vZxYSKvQO43t1XmNkVwDJ3XwR8DjgA+KGZATzh7ue4+2Yz+zQhyABc4e6bmy2TiIg0z9wn33B+Z2enn3LKKSxZsqTdRRERmTTM7G53n9doev2SWkREshQgREQkSwFCRESyFCBERCRLAUJERLIUIEREJEsBQkREshQgREQkSwFCRESyFCBERCRLAUJERLIUIEREJEsBQkREshQgREQkSwFCRESyFCBERCRLAUJERLIUIEREJEsBQkREshQgREQkSwFCRESyFCBERCRLAUJERLIqCRBmdraZrTKz1WZ2SWb5G8zsHjPrN7N31CwbMLPl8bWoivKIiEjzpjebgZl1ANcAZwLdwFIzW+TuK0vJngDeD3w0k8Uudz+52XKIiEi1mg4QwKnAandfC2BmNwDnAn8KEO7+WFw2WMH2RERkHFQxxDQb6CpNd8d5jdrXzJaZ2V1mdl69RGa2IKZb1tfXN9ayiohIg6roQVhmno9i/aPcfZ2ZHQfcZmYPuPuaPTJ0XwgsBOjs7BxN/iIiMgZV9CC6gbml6TnAukZXdvd18X0tsAR4VQVlEhGRJlURIJYCx5vZsWa2D3AB0NC3kcxslpnNjJ8PBV5L6dmFiIi0T9MBwt37gYuBW4CHgBvdfYWZXWFm5wCY2avNrBs4H7jWzFbE1V8GLDOz+4Dbgatqvv0kIiJtUsUzCNx9MbC4Zt6lpc9LCUNPtev9FnhlFWUQEZFq6ZfUIiKSpQAhIiJZChAiIpKlACEiIlkKECIikqUAISIiWQoQIiKSpQAhIiJZChAiIpKlACEiIlkKECIikqUAISIiWQoQIiKSpQAhIiJZChAiIpKlACEiIlkKECIikqUAISIiWZM3QNxxR7tLICIypU3eACEiIi2lACEiIlkKECIikqUAISIiWZUECDM728xWmdlqM7sks/wNZnaPmfWb2Ttqll1oZo/E14VVlEdERJrXdIAwsw7gGuDNwInAu8zsxJpkTwDvB75Xs+7BwGXAacCpwGVmNqvZMomISPOq6EGcCqx297Xu3gvcAJxbTuDuj7n7/cBgzbpvAm51983uvgW4FTi7gjKJiEiTqggQs4Gu0nR3nNfqdUVEpIWmV5CHZeZ51eua2QJgAcDMmTMbzF5ERMaqih5ENzC3ND0HWFf1uu6+0N3nufu8GTNmjKmgIiLSuCoCxFLgeDM71sz2AS4AFjW47i3AWWY2Kz6cPivOExGRNms6QLh7P3AxoWJ/CLjR3VeY2RVmdg6Amb3azLqB84FrzWxFXHcz8GlCkFkKXBHniYhIm5l7o48LJo7Ozk4/Zft2lkzCsouItIuZ3e3u8xpNr19Si4hIlgKEiIhkKUCIiEiWAoSIiGQpQIiISJYChIiIZClAiIhIlgKEiIhkKUCIiEiWAoSIiGQpQIiISJYChIiIZClAiIhIlgKEiIhkKUCIiEiWAoSIiGQpQIiISJYChIiIZE2JADF//nzmz5/f7mKIiEwpUyJAiIhI9RQgREQkSwFCRESypre7AM3QcwcRkdZRD0JERLIqCRBmdraZrTKz1WZ2SWb5TDP7QVz+ezM7Js4/xsx2mdny+PpqFeUREZHmNT3EZGYdwDXAmUA3sNTMFrn7ylKyi4At7v5iM7sA+Czwzrhsjbuf3Gw5ctIQ1JIlS1qRvYjIlFZFD+JUYLW7r3X3XuAG4NyaNOcC34qfbwL+wsysgm2LiEiLVBEgZgNdpenuOC+bxt37gWeBQ+KyY83sXjO7w8xeX28jZrbAzJaZ2bK+vr6mCz1//nwOOuggPegWEamjim8x5XoC3mCap4Cj3H2TmZ0C/MjMXu7uz+2R2H0hsBCgs7PT6ekZsnz58uVDKvvaYSUNN4mIjE4VPYhuYG5peg6wrl4aM5sOHAhsdvced98E4O53A2uAl1RQJhERaVIVAWIpcLyZHWtm+wAXAItq0iwCLoyf3wHc5u5uZi+ID7kxs+OA44G1FZRJRESa1PQQk7v3m9nFwC1AB3C9u68wsyuAZe6+CPg68B0zWw1sJgQRgDcAV5hZPzAAfNDdNzdbpuFU/cxBQ1ciMlVV8ktqd18MLK6Zd2np827g/Mx6NwM3V1GGKsyfP5/ly5dz8sknV1rhK4iIyGSkX1IPo/bPiOvPiovI3mRKBojabzSlnkE9o6n4a/MWEZmqpmSAmAjU2xCRyU4Boo6Reh2tWne4PBVwRGQ8KUC0Sa7CL8+rKiAosIjIWClAVKjVlfFwzz9aEVxEZO82qf9h0HgZqbIdqeJOX50dLu/RfAV2vNYRkb2behBtkHtGUZ7XimcYjao39KU/bCiy91GAmMLqBaLhnn20qhwKLiKTj4aYxmiiVHi5yn64Ia3xKEs7hrE0hCZSPQWIcTSWoDLcOq0OBiOVd7T7U67E630eab3hpGdBChIi1dAQk2Q1+xyk2ecWjQ5LjWbIbLg8NQwmsif1IPZizfRo2t1KV2Uu0nrqQQhQ3d+YGimfRv5O1ki9lyp6N43ua0o7Hj0MfVtMJhr1IPZCVQSDVjz/aEXFWM6zivLW60HVlr0VPayRnuGUt111T2+i9BxlfKkHIZPGaFvxVfQ0xuP3KM30ThrpbalHImM1uXsQd9xRfD7wwPaVQ1qmld/UyrWKx9JSrlfGkVr5oy3bWNV+u2ukXlCj21SvYuqb3AGiVjlgiDQgN9w22ucoOeWgkQsgrQx8w5Upqd2HXCU/ljLWGwbLLR9unkwMUytAlNUGiwMPzM8TmcBqK+nRBqexbidnpL851ki6kfIeS89qpKAkYzd1A0SjykHj9NPbVw6RSajq/7BYbygut43RblfBY/QUIMruuGNoT6Ner0M9EZnCqn6oPZZeUG26Robo6s2D0X3rTIGkoABRleECiQKNyLiqN+Q13DOnckCoF8Tq9WiaHRqbqBQgJppy0Gg0qFQVnO64Q8NsstcaqVcz2h5NbbpGg1O9crQjkFQSIMzsbOCLQAdwnbtfVbN8JvBt4BRgE/BOd38sLvs4cBEwAHzI3W+pokwyRrVfHR5roMnlN9Z8xrrt2jKo1yYTVG2PJxdo6gWnpNmvLec0HSDMrAO4BjgT6AaWmtkid19ZSnYRsMXdX2xmFwCfBd5pZicCFwAvB44EfmlmL3H3gWbLJdKwqRDkRtq2TGn1eifNfo26ih7EqcBqd18LYGY3AOcC5QBxLnB5/HwT8CUzszj/BnfvAR41s9Uxv99VUC4RSaZCkJus+9BmzfQkqggQs4Gu0nQ3cFq9NO7eb2bPAofE+XfVrDs7txEzWwAsAJg5c+aeY+XLlxfzli+H2shZXt7ovLGsU1U+2ofq9iGVYW/eh3ZdA9oHJrMqAoRl5nmDaRpZN8x0XwgsBOjs7MymERGRodr6DILQ6p9bmp4DrKuTptvMpgMHApsbXFdEZK928sknD/ujwfLyKlURIJYCx5vZscCThIfO765Jswi4kPBs4R3Abe7uZrYI+J6Z/QvhIfXxwB8qKJOITHDDVXityjtVpCP9xiGXLlcJNzq+X85zuHmNGM+vuzYdIOIzhYuBWwhfc73e3VeY2RXAMndfBHwd+E58CL2ZEESI6W4kPNDuB/6bvsHUesPdJHubsRyL8Tx+7ThPo6m4GzkWY6kUG/nlc6Pzcnk0WsmOtpyjSTeRfyCXVPI7CHdfDCyumXdp6fNu4Pw6614JXFlFOcZTK1s/UmhlBTnSTTvSdoe7Bmr/cFyjFddI22m0Qh7tMWtknVwLuGr1Ks3csR7tPVhVUNib6JfU42giB5XRtorrpW2mdT3S8RlLhdDOVn65opkIlU4u0DSSPq3TaNqxpGt0qGWkoD4RjvNUogCxFxtLwGr2BqwNII0OFYxmeW3aZLTfBx9rS3y0hmsdN7LuaFv+I7XSG1VVZaxKfeKakgGikUpoNNrZ8m90GKMV252IPZ12GU1rezzkKvyRejEiozUlA8R4q2p4ZixqK4dW5j2WdatYf7jlrQ5i41nBNhuENNQiVVOAqKOZ4YXaoYJG8qmyxzPabTeT/1jTj6YyG275aMbVx7pMdHz2VntdgBhuvLedQ0jt3J5ufhHJ2esCxHhopOXeTKXcygq9FQFkPAKQgpxI9aZMgGjVT83LxjP/3LaG28eR1lUFKiKjNWUCxEgaqSBr00ykVr4qeBEZb3tNgNhbKbCIyFhNa3cBmrFkyRJVgCIiLTKlexAjfa2xqq+SVpFGRGSimdIBYiSquEVE6pvUQ0wiItI6ChAiIpI1JYaYNFQkIlI99SBERCRLAUJERLIUIEREJEsBQkREsiZlgDjhhBP0YFpEpMUmZYAQEZHWU4AQEZGspgKEmR1sZrea2SPxfVaddBfGNI+Y2YWl+UvMbJWZLY+vFzZTHhERqU6zPYhLgF+5+/HAr+L0EGZ2MHAZcBpwKnBZTSB5j7ufHF/rmyyPiIhUpNkAcS7wrfj5W8B5mTRvAm51983uvgW4FTi7ye2KiEiLNRsgDnP3pwDie26IaDbQVZrujvOSb8ThpU+ZmTVZHhERqciIf4vJzH4JHJ5Z9MkGt5Gr9D2+v8fdnzSzTuBm4H3At+uUYwGwAOCoo45qcNMiIjJWIwYIdz+j3jIze8bMjnD3p8zsCCD3DKEbmF+angMsiXk/Gd+3mdn3CM8osgHC3RcCCwHmzZvnuTQiIlKdZoeYFgHpW0kXAj/OpLkFOMvMZsWH02cBt5jZdDM7FMDMZgBvAx5ssjwiIlIRcx97Y9zMDgFuBI4CngDOd/fNZjYP+KC7/21M9zfAJ+JqV7r7N8xsf+DXwAygA/gl8BF3H2hguxuAHcBG4NDSO3U+NzOvnfloHyZGPtqHiZGP9qH5fI529xfQKHeflC9gWe17vc/NzGtnPtqHiZGP9mFi5KN9aD6f0b70S2oREclSgBARkazJ/C9HF9Z5r/e5mXntzKed29Y+TIxtax8mxranwj6MSlMPqUVEZOrSEJOIiGQpQIiISNaEfQZhZtcD5wD7Av3AAUAfsIrwu4njgZmlVQbjey7oDdaZ3wrOnn9eZLTbd4r96Whiuz3APpn5uXWJ2xxue/1AL7BfZt3R/B2tXFmd8Ev8w2rm74jvHYRroSx3XHN5t1Kj23NgK9DJ0PuuL07X5vEEcDDhui/bAVwN/EPNMo+vaQ3MG4jbHOux6qe6umMs109VthOO4QD1r/uqr6fd7Hkdj0Yvoay15XXCeTGGnpseYBfw/Lisj3ANPR+4xN0/P9zGJnIP4pvAu4GnCYFiPqG87wZ+TjjQiwkn+e647CPAN+L62wgHzAl/7uNpYC3wLOEA7YrLdsR0EH6454S/ONsbX2sIFxDA/RQXdB+wOi7bFfPtIZyEpXH5APBMzH+AotLfRfjl+GBM1xfX741pN8V0aVsDwFuBzXH6lzHt0xSVwNfiMdka0zwUP98M3FPah1/E90HCD2c+Dvwhrrsxptsay5GOy7XAlfHzCuC3hOPusdzfju+PUrg45vlTwo8pPR6fewjnZiC+bohlGQT2j+v+n5ifx2MxAOwEthCO+aqYfhvwr3GdO2P6jXGbA7Gs2+PnLTFdN/CFOG9NzMfj8lSJPxTLDuHcpH2HcO4G434sIpzvdG63Af8R2FA63puBFwD3Ec5Zuud64vvTcX8HKM4vhGDZRbgm+0tp1xL+JllvLO+jsazlRsVGwjl6FnggLtsdlz9GOOY3AQ8D6yiu4XQt/Sget6/GMu0EHonlWB/z2QH8M+FaHCR8534zxfX3JPBfY94PxPd0L6btpTL1xOM8GLeb7oF07rYRzs8zMe/euI9QXKe9wF/FeY/H/UzHMd1/j8R5m2NZ9imVazDuJ4TrJ6VL10c6PgOEf22wPS57snTMU5qNcX92lcp4bfw8Pc5fCXyOcPzT9T9AOPbE/J+O838Tp1OZIFwHqX5I1+oMwrW3Me7rnYTr7TpgLuGPpG4HDiRcvyOasAHC3X8N/BHYHT93Ey6k2YQ/M74vobLbCryUcCBXUvxF2XSDGuFi2UQ4ePsTLoxphAM8nXBxQTjoAC8jXCy9cbvpItlA0Zpw4J8IkXwz4WZMx3MD4QLpj+vOoGiJpG2+JE6nALVf3KYBz4vv6YbfTTip6UK4PuZxZynf6+KyB0pl+GPch5dSVEgpgDrhApxF+CX8prjddOP0UbRS5sUy7gROip+fiWn3J5yHAYoKHuC5mG42cEL8/BRwEKHntyOW7cFY/mnxOAH8T4rgd3Asx464z9cBR8Z02yluwjtjPqkCmhb3bb843Rnze5hQWW8h3DSpEfFoXP/xuB+phT2NEJSI+cyI6X4T10/HfxrhZqeUF0Cfu6cb9kCKgNIR3w8lVNZ9DG2p7iZU8sdR9KJmEILerHgcewjnO7UY0/l6OpYt9brTuuk6Oww4kVDRHRS3m+6B3ji9i3Bd70+4r46L+zeNImD9EHg1IaC+KKZPvfpB4HdxH2fG9954DHrj/qVrLDUG0v3RQajYu9MxJATLzji9nhDc03bSeUp/VLSTIoAcQtHTPDDOu4/iHKbWeF8sZw/h/u8ntLJT/h2lfB6m6EXviMs/Vtr3mYQeYOopWMwz7YsB9xLuxcNLx9uB5THdNIo65acUAW9WTJvqiH6K+oW4rJPQyzwxzrvV3dfF8nTEPG+nEWP5dd14vYBjgAfj59cRLqznE1oUD8aTkG5wBz5EuJgHS/McuDym/wpFa6G8PE2nlmAfReu1PP1XNeul108oWiKppZxaBFtLn8vbLfdwUv69Nfn210ynluLVNdtz4PR4cWyM09sJrbtPEyrr3rjO6zLlTy3CQUKQTK2h8nF5qDTdX/rcF7e1vibPXfE4bCulfba0vZ2ZfU7H6LrSMXmOIvg/x9BjOFDa34FS+o/VlHNbaZ2dcV96GXqMU97rS9sYjOmeYc9jtpGickivPvY8Z2kb/fF49JbSpuviekIA2V1aZ2VMv7U0bxtFrye1rGu3X7vt+0v7k1q96Zr+Wcw/9XbTPnfX7Mvu+HlHPE47YvpVNesOlM5x+bpK+9UX1380Lkv5/yt73pOpV1B7jzpFryedz7Q8HauNcd9y66b704EvD5NmsOa9p+YYpfdUsfeX5tWWvbzO7lJ+6XylHm45/VaKe7K2LOn8l9On6Sdq5m8B3k/Rm95MuMYvBz46JX5JbWYHECr3p939OUILdwvwPwit43SCLqIYl32KohfxcUIL5zVxegfFCemmOMlfistTC2caoWWafCGmg3CSvhvf3xbnPRTfFzC01ZJaZan16IRhmQ72HHYYILT+04WeWl5dhJZJahFOo+iiQxhK6idcCBC6vicRWqjPEVqZ6QIh7vNzcTu3U7TyUi9gMJZ3d3x/KcWw0M0UQwldcf8PIrR00vH597jNLQztOaWKamYs729K20tjqN8kVD5OOJ9pP18OfLG0z+sIDQYohv9mAB+N81Jlsomi1TuN0KvpYOi5JB6PFPBSxddF0ULvLaWdTrjRBkr5bAe+TxgmSPMgnMcOwnWbgkoaPplG+Edbh1O0HiH0AjYSWoNpGOMAwl9DtjjPKK7j8n7spugxziH0iqC4BlPv5JXxeNX+kc2PEILPV2KeMwnX9tOE62NfQqNo33gcdhCC6LOxvKsJgewncd19Yr7pb68dHsuXhv1OI25q9KQAAAT0SURBVBzbXRQ9wr5YLi9Np89OGMaFIkh2EXoGA4Rew1sYeg6gCCbpfD5bym+wlG6AojeXeo+pPgD4t/iexvTT59QYmkbRuKi1huI6Teum3nk/4RilMm2J+7WDoueRGjPlkYxyHbIvRQDqIfR0rgZeQejpHwR8JlOuvHb3EhrpQRD+Iuyn4+fp8UBuiwf5dopIe3npBKyguMkH47qp5dBHEWnLkX5rad6meCJ+H09SX1w/tRR6CBV5iupdhB+jDBDGrDeyZ68h16JIlc4gRWDoq0k3SKg00/S/MfQCKrdgBkrTu+J+bCvl/4H4eTehUu1nz9ZIuaXyeDz+20vLy+mfI9ys/Qxt7aYWcmo5Ly0dj9QC6qcIUuVW0QbCjZnWXwM8HK+JIyieC/URWtoe97OPMNZ7W2ndLkJFk66Fy+JxKz8XKj8rKvcAyi3vdM7LLbraVt9jhOvsvFKaPuDva9LVvsotyfK2U6+stkxp3L6Hob2OtP4uisqwNt/thGuufO0+V0qznnD9ro3HNs3vY+i98qrScd5ACCDl+yg1QFJA7CX0ctM9+DRF4E+VY7lXsYuit9TL0J5oD0Pv5R7Cvfe/KXqM3y+le5ai4ZU7XuVzXfu5ttcwQHjONMDQXsAmwvlP1/t6iiBVzift826K6yoN5z1HMQKyLub1AKFif5Ii8D9bsx/lVz+h0fsM4VpM99hJFNfEuniONgMXT/YexGzCxff1OH0GoXewi/Cwel/CQ1YI/940taBTa2ka4cAcQDEOO42iknmG4mJLD4fTU/59CN3h/QiB6QmKqL8zTqcT30v4ZpURLsQD4ued8fUHipugh3Bz9RMqr9SqWxvzW0txcaeH2P+B4gL4m1iGS2MZ002ZuvDEY/NULHtq2R9A6N2kyjmN+a+I856K+5FuqJ2EZwDLKVpjV8ZzkR6abSD0Uu4j/E/y1Cr7dekc3EwI9uni3RWP+2aKoa9ewpAYhBt9dlz3iTj/EDM7DfhbwrOV9Awpjc+nsfFOioeRm2K+byTcYE4IkBsILfqnYrp0/lMrMn0BoCceg7QNKFpy2wjPDspDKC8kBLaPU/RepwGfip8foXjwmAKjEwLwIKGCSWW4l/CQdx3hSxrEdVIFcRtFizIFjcUx3WpCAyUNu6QvBaRvtd1IOKfb4/6l3khfPH5bCa3wwymeFfx7qXyDhN7H6+PygwmBe2N83UO4hv8f4fpL5fjvpfIeTBGsthPux36Ka2AV4TwbxXO+dB7WM/Qh9SChF3ICRZCZG/f1TopnAespel2DFPfz+tKxhSLwDxK+sALFw+M+whcwtsVypZb8/nFbHXH7a4EXU0gN0gcJ138/4TlCauh0xmO1LeaZetjHA3dQjCB0xW3dS3HvpHKnIb3nEZ5VrKF4lvkd4P/GbZ9EGNb7Z3dPoyZZE/aX1Gb2feBMiodMEG62HkKl+meEC2Kq2kW4wMtfZ0stpn2ya+wpndxGvua6m3ABpko9Jw3vzaxJk7rVw+Vvw0wPN7/RfZjoUsDdn8a+muul+eVl2wgNg6sY+jXvXB6p8kkVZKo80/lKwe2IBspfzr/e+Rtp2USThjQb/Sp5K6TKvZGvoyejOf6pkZMe0G8gNFJuBZ4Z6WuuEzZAiIhIe02GISYREWkDBQgREclSgBARkSwFCBERyVKAEBGRLAUIERHJUoAQEZGs/w8giW1bc9T5bgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'pr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-9ca0e150b218>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginalclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0medictedclass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pr' is not defined"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "# temp = evaluate_model(random_forest, X, Y)\n",
    "\n",
    "forest.fit(X, Y)\n",
    "# print(random_forest.feature_importances_.max())\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n",
    "print(classification_report(originalclass, pr/edictedclass)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.88      0.86        32\n",
      "           2       0.70      0.72      0.71        36\n",
      "           3       0.70      0.66      0.68        32\n",
      "\n",
      "    accuracy                           0.75       100\n",
      "   macro avg       0.75      0.75      0.75       100\n",
      "weighted avg       0.75      0.75      0.75       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "temp = evaluate_model(forest, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GaussianNB' object has no attribute 'coefs_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-5c1f70b8fbb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mgnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# temp = evaluate_model(gnb, X, Y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GaussianNB' object has no attribute 'coefs_'"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X, Y)\n",
    "print(gnb.coefs_)\n",
    "\n",
    "# temp = evaluate_model(gnb, X, Y)\n",
    "# print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.91      0.95        32\n",
      "           2       0.71      0.83      0.77        36\n",
      "           3       0.76      0.69      0.72        32\n",
      "\n",
      "    accuracy                           0.81       100\n",
      "   macro avg       0.82      0.81      0.81       100\n",
      "weighted avg       0.82      0.81      0.81       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural network with 1 hidden layer (the hidden layer is as big as the number of features)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation=\"relu\", alpha=0.0001,\n",
    "                    hidden_layer_sizes=(142,), max_iter=1000)\n",
    "\n",
    "temp = evaluate_model(mlp, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network with 2 hidden layer (the hidden layer is as big as the number of features)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation=\"relu\", alpha=1e-5,\n",
    "                    hidden_layer_sizes=(number_of_features, number_of_features), max_iter=1000)\n",
    "\n",
    "temp = evaluate_model(mlp, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network with 3 hidden layer (the hidden layer is as big as the number of features)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation=\"relu\", alpha=1e-5,\n",
    "                    hidden_layer_sizes=(number_of_features, number_of_features, number_of_features,), max_iter=1000)\n",
    "\n",
    "temp = evaluate_model(mlp, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
