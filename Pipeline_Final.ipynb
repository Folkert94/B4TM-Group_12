{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline CATS 12\n",
    "\n",
    "### Lucas Jollie, Michelle Klein, Maaike Scholten, Folkert Stijnman\n",
    "\n",
    "1. Extract features based on Chi Squared test and literature\n",
    "\n",
    "(skip 2. and 3. if you just want the model) \n",
    "\n",
    "2. Validate Naive Bayes, Random Forest, MLP\n",
    "3. Visualise in boxplot\n",
    "\n",
    "\n",
    "4. Train model (parameters taken from validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0    1    2    3    4    5    6    7    8    9     ... 2824 2825  \\\n",
      "Array.129    0    0    0    0    0    0    0    0    0    0  ...    2    2   \n",
      "Array.34     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.67     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.24     0    0    0    0    0    0    0   -1    0    0  ...    0    0   \n",
      "Array.22     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "Array.10     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.123    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.100    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.134   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    1    1   \n",
      "Array.130    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "\n",
      "          2826 2827 2828 2829 2830 2831 2832 2833  \n",
      "Array.129    2    2    0    1    1    1    1    1  \n",
      "Array.34     1    1    1    1    1    1    1    1  \n",
      "Array.67     1    1    1    1    1    1    1    1  \n",
      "Array.24     0    0    0    0    0    0    0    0  \n",
      "Array.22     1    1    1    1    1    1    1    1  \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "Array.10     0    1    1    1    1    1    1    1  \n",
      "Array.123    1    1    1    1    1    1    1    1  \n",
      "Array.100    1    1    1    1    1    1    1    1  \n",
      "Array.134    1    1    1    1    1    1    1    1  \n",
      "Array.130    1    1    1    1    1    1    1    1  \n",
      "\n",
      "[100 rows x 2834 columns]\n",
      "[1, 2, 2, 3, 3, 2, 1, 1, 3, 1, 2, 3, 1, 1, 3, 3, 2, 1, 2, 2, 3, 1, 2, 1, 2, 1, 1, 3, 1, 2, 2, 1, 2, 1, 2, 2, 3, 3, 3, 1, 2, 3, 2, 3, 2, 3, 1, 1, 3, 3, 1, 2, 2, 3, 2, 3, 1, 1, 3, 2, 1, 2, 3, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 3, 1, 3, 2, 3, 3, 3, 3, 2, 1, 1, 2, 3, 3, 3, 3, 2, 3, 2, 3, 1, 2, 2, 2, 1]\n",
      "The regions found in the literature were:  [111, 157, 249, 65, 361, 360, 479, 576, 583, 688, 664, 625, 670, 772, 876, 877, 878, 937, 991, 992, 993, 966, 1136, 1137, 1092, 1207, 1234, 1370, 1371, 1387, 1296, 1310, 1583, 1407, 1575, 1513, 1589, 1611, 1697, 1645, 1657, 1725, 1734, 1735, 1865, 1904, 1911, 2017, 1965, 2015, 2016, 2207, 2074, 2075, 2306, 2184, 2135, 2136, 2200, 2201, 2071, 2160, 2161, 2446, 2681, 2682, 2683, 2684, 2685, 2732, 2744, 2794, 2822]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# 1 Load data and important genes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "with open(\"train_call.txt\", 'r') as temp:\n",
    "    for line in temp:\n",
    "        temp_list.append(line.split())\n",
    "\n",
    "columns_temp = temp_list[0]\n",
    "columns_temp = [x.replace(\"\\\"\", \"\") for x in columns_temp]\n",
    "\n",
    "df_train = pd.DataFrame(temp_list[1:], columns=columns_temp)\n",
    "X = df_train.drop(['Chromosome', 'Start','End', 'Nclone'], axis=1)\n",
    "X = X.transpose()\n",
    "\n",
    "labels = []\n",
    "\n",
    "with open(\"Train_clinical.txt\", 'r') as temp_labels:\n",
    "    next(temp_labels)\n",
    "    for line in temp_labels:\n",
    "        temp = line.strip()\n",
    "        temp = temp.split()\n",
    "        if temp[1].strip(\"\\\"\") == \"HER2+\":\n",
    "            labels.append(1)\n",
    "        if temp[1].strip(\"\\\"\") == \"HR+\":\n",
    "            labels.append(2)\n",
    "        if temp[1].strip(\"\\\"\") == \"Triple\":\n",
    "            labels.append(3)\n",
    "\n",
    "Y = labels\n",
    "\n",
    "# Find the important genes list here if needed (anyone at VU can view this link): https://docs.google.com/spreadsheets/d/18T0gJ6nX67aa7veYpRTn_0yymVCvFnnllGqiQyqsIcc/edit?usp=sharing\n",
    "important_genes = [111, 157, 249, 65, 361, 360, 479, 576, 583, 688, 664, 625, 670, 772, 876, 877, 878, 937, 991, 992, 993, 966, 1136, 1137, 1092, 1207, 1234, 1370, 1371, 1387, 1296, 1310, 1583, 1407, 1575, 1513, 1589, 1611, 1697, 1645, 1657, 1725, 1734, 1735, 1865, 1904, 1911, 2017, 1965, 2015, 2016, 2207, 2074, 2075, 2306, 2184, 2135, 2136, 2200, 2201, 2071, 2160, 2161, 2446, 2681, 2682, 2683, 2684, 2685, 2732, 2744, 2794, 2822]\n",
    "            \n",
    "print(X)\n",
    "print(Y)\n",
    "print(\"The regions found in the literature were: \", important_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Gene  Region number       P-value Yes/No\n",
      "0              DIRAS3            111  6.897062e-01     No\n",
      "1              PTPN22            157  7.287985e-01     No\n",
      "2                 AGT            249  9.791761e-01     No\n",
      "3               CLSPN             65  5.039604e-01     No\n",
      "4   BARD1/CASP8/CTLA4            361  8.022867e-01     No\n",
      "5               SF3B1            360  8.717109e-01     No\n",
      "6              PIK3CA            479  4.007464e-01     No\n",
      "7               NFKB1            576  8.076397e-01     No\n",
      "8                FGF2            583  8.076397e-01     No\n",
      "9               RAD50            688  1.138701e-01     No\n",
      "10             MAP3K1            664  1.569463e-01     No\n",
      "11               TERT            625  9.757757e-01     No\n",
      "12             PIK3R1            670  4.250528e-02    Yes\n",
      "13              CCND3            772  1.568220e-01     No\n",
      "14               ESR1            876  4.297669e-01     No\n",
      "15               ESR1            877  3.435048e-01     No\n",
      "16               ESR1            878  3.384654e-01     No\n",
      "17               EGFR            937  9.492498e-01     No\n",
      "18       KMT2C (MLL3)            991  8.738841e-01     No\n",
      "19       KMT2C (MLL3)            992  8.280285e-01     No\n",
      "20       KMT2C (MLL3)            993  8.014328e-01     No\n",
      "21          CAV1/CAV2            966  8.425206e-01     No\n",
      "22                NBN           1136  7.630498e-01     No\n",
      "23                NBN           1137  7.911207e-01     No\n",
      "24              IKBKB           1092  7.408158e-02     No\n",
      "25              PTPRD           1207  5.060686e-01     No\n",
      "26               MELK           1234  6.914782e-01     No\n",
      "27               PTEN           1370  9.529703e-01     No\n",
      "28               PTEN           1371  7.162040e-01     No\n",
      "29              FGFR2           1387  9.025203e-01     No\n",
      "30              GATA3           1296  6.855018e-01     No\n",
      "31              MASTL           1310  4.611954e-01     No\n",
      "32                ATM           1583  2.250590e-01     No\n",
      "33           H19/LSP1           1407  5.048502e-01     No\n",
      "34           MRE11(A)           1575  2.436539e-01     No\n",
      "35              CCND1           1513  6.078381e-01     No\n",
      "36              TIRAP           1589  1.729887e-01     No\n",
      "37             CDKN1B           1611  7.665508e-01     No\n",
      "38               TBX3           1697  7.967035e-01     No\n",
      "39               KRT5           1645  1.479597e-01     No\n",
      "40               IL22           1657  5.859564e-02     No\n",
      "41              BRCA2           1725  6.931973e-01     No\n",
      "42                RB1           1734  3.485173e-01     No\n",
      "43                RB1           1735  4.047287e-01     No\n",
      "44               AKT1           1865  3.883914e-01     No\n",
      "45              RAD51           1904  2.001524e-01     No\n",
      "46            CYP19A1           1911  2.163115e-01     No\n",
      "47               CDH1           2017  4.623894e-02    Yes\n",
      "48              PALB2           1965  5.683650e-01     No\n",
      "49               CBFB           2015  1.517658e-01     No\n",
      "50               CDH3           2016  1.160794e-01     No\n",
      "51              BRCA1           2207  3.346706e-03    Yes\n",
      "52               TP53           2074  3.249625e-02    Yes\n",
      "53               TP53           2075  3.249625e-02    Yes\n",
      "54              BRIP1           2306  6.918517e-01     No\n",
      "55       ERBB2 (HER2)           2184  8.326227e-14    Yes\n",
      "56                NF1           2135  2.972004e-01     No\n",
      "57                NF1           2136  6.509545e-01     No\n",
      "58              KRT14           2200  4.172152e-01     No\n",
      "59              KRT17           2201  6.104122e-01     No\n",
      "60             ALOX15           2071  9.275122e-02     No\n",
      "61               CCL5           2160  5.475658e-01     No\n",
      "62               CCL4           2161  6.103237e-01     No\n",
      "63         STK11/LKB1           2446  9.669922e-01     No\n",
      "64              RUNX1           2681  5.234851e-01     No\n",
      "65              RUNX1           2682  4.492747e-01     No\n",
      "66              RUNX1           2683  5.987332e-01     No\n",
      "67              RUNX1           2684  6.175287e-01     No\n",
      "68              RUNX1           2685  5.718320e-01     No\n",
      "69              CHEK2           2732  4.082143e-02    Yes\n",
      "70              PDGFB           2744  9.509540e-02     No\n",
      "71                 AR           2794  7.771286e-01     No\n",
      "72               AFF2           2822  9.299035e-01     No\n",
      "Number of features = 204\n"
     ]
    }
   ],
   "source": [
    "## FEATURE SELECTION\n",
    "\n",
    "#Loading data\n",
    "patients = X.values.tolist()\n",
    "\n",
    "# we need to shift the features by 1 since the chi2 function does not take non-negative values\n",
    "patients_shift = []\n",
    "\n",
    "for patient in patients:\n",
    "    x = []\n",
    "    for feature in patient:\n",
    "        x.append(int(feature) + 1)\n",
    "    patients_shift.append(x)\n",
    "\n",
    "chi, p_val = chi2(patients_shift, Y)\n",
    "\n",
    "imp_genes_p_values = []\n",
    "\n",
    "for i, j in enumerate(important_genes):\n",
    "    if p_val[j] >= 0.05:\n",
    "        imp_genes_p_values.append([imp_genes[i][0], j, p_val[j], \"No\"])\n",
    "    else:\n",
    "        imp_genes_p_values.append([imp_genes[i][0], j, p_val[j], \"Yes\"])\n",
    "    \n",
    "\n",
    "important_genes_scores = pd.DataFrame(imp_genes_p_values, columns=[\"Gene\", \"Region number\", \"P-value\", \"Yes/No\"])\n",
    "pd.set_option('display.max_rows', 75)\n",
    "print(important_genes_scores)\n",
    "\n",
    "X_feature_selected = X\n",
    "\n",
    "threshold = 0.05\n",
    "for i, val in enumerate(p_val):\n",
    "    if val >= threshold and i not in important_genes:\n",
    "        X_feature_selected = X_feature_selected.drop([i], axis=1)\n",
    "        \n",
    "X = X_feature_selected\n",
    "number_of_features = len(X.values.tolist()[0])\n",
    "print(\"Number of features = {}\".format(number_of_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation scheme\n",
    "\n",
    "def nested_cross_validation(MODEL, PARAMS, X, Y, NUM_TRIALS):\n",
    "    nested_scores = []\n",
    "    \n",
    "    for i in range(NUM_TRIALS):\n",
    "        print(\"Running Trial {}...\".format(i + 1))\n",
    "        # K Fold inner & outer loop\n",
    "        inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "        outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "        \n",
    "        # one vs. rest approach\n",
    "        model_to_set = OneVsRestClassifier(MODEL)\n",
    "        \n",
    "        model = GridSearchCV(estimator=model_to_set, param_grid=PARAMS, cv=inner_cv, n_jobs=2)\n",
    "        nested_score = cross_val_score(model, X=X, y=Y, cv=outer_cv)\n",
    "        nested_scores.append([nested_score.mean(), nested_score.std()])\n",
    "        print(nested_score.mean(), nested_score.std())\n",
    "        \n",
    "    return nested_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8200000000000001, 0.08246211251235322], [0.82, 0.1341640786499874], [0.79, 0.0768114574786861], [0.78, 0.044721359549995794], [0.77, 0.15066519173319362], [0.8, 0.04898979485566356], [0.77, 0.08660254037844387], [0.84, 0.12328828005937952], [0.78, 0.060000000000000005], [0.78, 0.1], [0.8299999999999998, 0.08660254037844385], [0.8399999999999999, 0.08944271909999159], [0.8400000000000001, 0.09380831519646858], [0.8200000000000001, 0.11489125293076059], [0.77, 0.06557438524302002], [0.85, 0.06557438524301998], [0.81, 0.05916079783099616], [0.81, 0.0768114574786861], [0.81, 0.05916079783099617], [0.76, 0.1264911064067352], [0.84, 0.0632455532033676], [0.8200000000000001, 0.07211102550927981], [0.76, 0.0848528137423857], [0.8, 0.08485281374238568], [0.79, 0.01732050807568879], [0.77, 0.12124355652982143], [0.86, 0.06633249580710801], [0.81, 0.09110433579144302], [0.76, 0.11313708498984763], [0.8, 0.06928203230275512], [0.78, 0.12806248474865695], [0.77, 0.06557438524302002], [0.8, 0.03999999999999998], [0.8200000000000001, 0.03464101615137753], [0.8300000000000001, 0.09110433579144298], [0.8, 0.0632455532033676], [0.8, 0.13564659966250536], [0.79, 0.099498743710662], [0.8, 0.08944271909999159], [0.8300000000000001, 0.05196152422706631], [0.8400000000000001, 0.028284271247461888], [0.8500000000000001, 0.033166247903553984], [0.76, 0.07999999999999996], [0.79, 0.05916079783099617], [0.79, 0.05916079783099617], [0.79, 0.10344080432788601], [0.8200000000000001, 0.06633249580710801], [0.8300000000000001, 0.05196152422706631], [0.78, 0.06633249580710796], [0.78, 0.060000000000000005], [0.77, 0.08660254037844387], [0.8, 0.03999999999999998], [0.81, 0.08185352771872448], [0.8200000000000001, 0.12806248474865697], [0.76, 0.06324555320336757], [0.85, 0.04358898943540674], [0.83, 0.10344080432788598], [0.8300000000000001, 0.08660254037844385], [0.8400000000000001, 0.08000000000000002], [0.76, 0.12328828005937953], [0.79, 0.1396424004376894], [0.8300000000000001, 0.05916079783099616], [0.78, 0.08246211251235319], [0.81, 0.09949874371066199], [0.84, 0.05656854249492382], [0.8, 0.06324555320336758], [0.8300000000000001, 0.07681145747868605], [0.83, 0.07141428428542852], [0.8200000000000001, 0.04472135954999579], [0.77, 0.09949874371066199], [0.8200000000000001, 0.06633249580710801], [0.8200000000000001, 0.034641016151377525], [0.8300000000000001, 0.07681145747868605], [0.8200000000000001, 0.04472135954999579], [0.8, 0.08944271909999159], [0.85, 0.0714142842854285], [0.8400000000000001, 0.04898979485566356], [0.8300000000000001, 0.07141428428542851], [0.76, 0.1296148139681572], [0.81, 0.05916079783099617], [0.81, 0.09110433579144298], [0.81, 0.09110433579144302], [0.7999999999999999, 0.09380831519646858], [0.76, 0.07999999999999996], [0.8, 0.1624807680927192], [0.7999999999999999, 0.09380831519646858], [0.81, 0.11445523142259595], [0.84, 0.05656854249492382], [0.81, 0.03316624790355398], [0.82, 0.09165151389911678], [0.8, 0.0], [0.8200000000000001, 0.08246211251235323], [0.7899999999999999, 0.11090536506409417], [0.8099999999999999, 0.10344080432788601], [0.83, 0.11789826122551594], [0.78, 0.07211102550927977], [0.77, 0.09110433579144296], [0.8, 0.05656854249492382], [0.8200000000000001, 0.08717797887081347], [0.78, 0.05999999999999998]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes doesn't need parametrization\n",
    "\n",
    "nb_nested = []\n",
    "\n",
    "for i in range(100):\n",
    "    cv_folds = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    nb = OneVsRestClassifier(GaussianNB())\n",
    "    nested_score = cross_val_score(nb, X=X, y=Y, cv=cv_folds)\n",
    "    nb_nested.append([nested_score.mean(), nested_score.std()])\n",
    "    \n",
    "print(nb_nested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Trial 1...\n",
      "0.7600000000000001 0.04898979485566356\n",
      "Running Trial 2...\n",
      "0.71 0.18841443681416772\n",
      "Running Trial 3...\n",
      "0.77 0.07141428428542847\n",
      "Running Trial 4...\n",
      "0.7200000000000001 0.0748331477354788\n",
      "Running Trial 5...\n",
      "0.74 0.1183215956619923\n",
      "Running Trial 6...\n",
      "0.8 0.06324555320336758\n",
      "Running Trial 7...\n",
      "0.75 0.09110433579144296\n",
      "Running Trial 8...\n",
      "0.7900000000000001 0.08660254037844387\n",
      "Running Trial 9...\n",
      "0.78 0.060000000000000005\n",
      "Running Trial 10...\n",
      "0.73 0.07141428428542851\n",
      "Running Trial 11...\n",
      "0.78 0.06\n",
      "Running Trial 12...\n",
      "0.77 0.07681145747868608\n",
      "Running Trial 13...\n",
      "0.75 0.08660254037844387\n",
      "Running Trial 14...\n",
      "0.8 0.16248076809271922\n",
      "Running Trial 15...\n",
      "0.76 0.07483314773547882\n",
      "Running Trial 16...\n",
      "0.77 0.08660254037844387\n",
      "Running Trial 17...\n",
      "0.7500000000000001 0.091104335791443\n",
      "Running Trial 18...\n",
      "0.78 0.060000000000000005\n",
      "Running Trial 19...\n",
      "0.76 0.15748015748023622\n",
      "Running Trial 20...\n",
      "0.73 0.08660254037844387\n",
      "Running Trial 21...\n",
      "0.77 0.051961524227066326\n",
      "Running Trial 22...\n",
      "0.73 0.07681145747868606\n",
      "Running Trial 23...\n",
      "0.79 0.01732050807568879\n",
      "Running Trial 24...\n",
      "0.77 0.033166247903554026\n",
      "Running Trial 25...\n",
      "0.77 0.043588989435406726\n",
      "Running Trial 26...\n",
      "0.75 0.09949874371066199\n",
      "Running Trial 27...\n",
      "0.81 0.07141428428542851\n",
      "Running Trial 28...\n",
      "0.8 0.06324555320336758\n",
      "Running Trial 29...\n",
      "0.77 0.1244989959798873\n",
      "Running Trial 30...\n",
      "0.78 0.08717797887081347\n",
      "Running Trial 31...\n",
      "0.78 0.0447213595499958\n",
      "Running Trial 32...\n",
      "0.77 0.08660254037844387\n",
      "Running Trial 33...\n",
      "0.75 0.07681145747868608\n",
      "Running Trial 34...\n",
      "0.71 0.07141428428542852\n",
      "Running Trial 35...\n",
      "0.77 0.07681145747868608\n",
      "Running Trial 36...\n",
      "0.75 0.033166247903554026\n",
      "Running Trial 37...\n",
      "0.75 0.059160797830996134\n",
      "Running Trial 38...\n",
      "0.76 0.0848528137423857\n",
      "Running Trial 39...\n",
      "0.76 0.028284271247461926\n",
      "Running Trial 40...\n",
      "0.77 0.09110433579144296\n",
      "Running Trial 41...\n",
      "0.79 0.01732050807568879\n",
      "Running Trial 42...\n",
      "0.7300000000000001 0.051961524227066305\n",
      "Running Trial 43...\n",
      "0.75 0.07681145747868608\n",
      "Running Trial 44...\n",
      "0.7400000000000001 0.0447213595499958\n",
      "Running Trial 45...\n",
      "0.79 0.033166247903553984\n",
      "Running Trial 46...\n",
      "0.74 0.11489125293076054\n",
      "Running Trial 47...\n",
      "0.7300000000000001 0.051961524227066305\n",
      "Running Trial 48...\n",
      "0.68 0.03999999999999998\n",
      "Running Trial 49...\n",
      "0.77 0.033166247903554026\n",
      "Running Trial 50...\n",
      "0.7 0.04472135954999579\n",
      "Running Trial 51...\n",
      "0.79 0.033166247903553984\n",
      "Running Trial 52...\n",
      "0.79 0.08660254037844387\n",
      "Running Trial 53...\n",
      "0.76 0.07483314773547882\n",
      "Running Trial 54...\n",
      "0.76 0.06324555320336757\n",
      "Running Trial 55...\n",
      "0.7500000000000001 0.05916079783099614\n",
      "Running Trial 56...\n",
      "0.74 0.020000000000000018\n",
      "Running Trial 57...\n",
      "0.73 0.05916079783099617\n",
      "Running Trial 58...\n",
      "0.7600000000000001 0.04898979485566356\n",
      "Running Trial 59...\n",
      "0.7700000000000001 0.0714142842854285\n",
      "Running Trial 60...\n",
      "0.7400000000000001 0.034641016151377525\n",
      "Running Trial 61...\n",
      "0.8 0.09797958971132711\n",
      "Running Trial 62...\n",
      "0.7500000000000001 0.04358898943540673\n",
      "Running Trial 63...\n",
      "0.75 0.051961524227066326\n",
      "Running Trial 64...\n",
      "0.77 0.033166247903554026\n",
      "Running Trial 65...\n",
      "0.79 0.05916079783099617\n",
      "Running Trial 66...\n",
      "0.74 0.08717797887081347\n",
      "Running Trial 67...\n",
      "0.78 0.0447213595499958\n",
      "Running Trial 68...\n",
      "0.75 0.1244989959798873\n",
      "Running Trial 69...\n",
      "0.73 0.10723805294763607\n",
      "Running Trial 70...\n",
      "0.7600000000000001 0.09797958971132711\n",
      "Running Trial 71...\n",
      "0.75 0.059160797830996134\n",
      "Running Trial 72...\n",
      "0.8 0.0632455532033676\n",
      "Running Trial 73...\n",
      "0.74 0.06633249580710801\n",
      "Running Trial 74...\n",
      "0.81 0.043588989435406726\n",
      "Running Trial 75...\n",
      "0.77 0.11090536506409415\n",
      "Running Trial 76...\n",
      "0.7899999999999999 0.08660254037844385\n",
      "Running Trial 77...\n",
      "0.76 0.0692820323027551\n",
      "Running Trial 78...\n",
      "0.74 0.08246211251235319\n",
      "Running Trial 79...\n",
      "0.74 0.06633249580710796\n",
      "Running Trial 80...\n",
      "0.77 0.04358898943540673\n",
      "Running Trial 81...\n",
      "0.8300000000000001 0.06557438524302002\n",
      "Running Trial 82...\n",
      "0.74 0.07211102550927977\n",
      "Running Trial 83...\n",
      "0.7500000000000001 0.051961524227066326\n",
      "Running Trial 84...\n",
      "0.77 0.04358898943540673\n",
      "Running Trial 85...\n",
      "0.7400000000000001 0.08246211251235319\n",
      "Running Trial 86...\n",
      "0.73 0.08660254037844387\n",
      "Running Trial 87...\n",
      "0.81 0.05916079783099616\n",
      "Running Trial 88...\n",
      "0.76 0.028284271247461926\n",
      "Running Trial 89...\n",
      "0.76 0.028284271247461926\n",
      "Running Trial 90...\n",
      "0.8 0.08485281374238571\n",
      "Running Trial 91...\n",
      "0.79 0.05196152422706631\n",
      "Running Trial 92...\n",
      "0.8 0.03999999999999998\n",
      "Running Trial 93...\n",
      "0.78 0.09165151389911681\n",
      "Running Trial 94...\n",
      "0.72 0.1095445115010332\n",
      "Running Trial 95...\n",
      "0.78 0.07211102550927977\n",
      "Running Trial 96...\n",
      "0.79 0.05196152422706631\n",
      "Running Trial 97...\n",
      "0.78 0.07211102550927977\n",
      "Running Trial 98...\n",
      "0.7200000000000001 0.04898979485566356\n",
      "Running Trial 99...\n",
      "0.7500000000000001 0.05916079783099614\n",
      "Running Trial 100...\n",
      "0.73 0.07141428428542848\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 1, stop = 50, num = 10, dtype=int)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "parameters = {'estimator__n_estimators': n_estimators,\n",
    "               'estimator__max_features': max_features}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_nested = nested_cross_validation(rf, parameters, X, Y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Trial 1...\n",
      "0.8500000000000001 0.08185352771872453\n",
      "Running Trial 2...\n",
      "0.82 0.04472135954999579\n",
      "Running Trial 3...\n",
      "0.81 0.05916079783099617\n",
      "Running Trial 4...\n",
      "0.84 0.028284271247461888\n",
      "Running Trial 5...\n",
      "0.8500000000000001 0.06557438524301998\n",
      "Running Trial 6...\n",
      "0.8599999999999999 0.08246211251235319\n",
      "Running Trial 7...\n",
      "0.85 0.0768114574786861\n",
      "Running Trial 8...\n",
      "0.8600000000000001 0.060000000000000005\n",
      "Running Trial 9...\n",
      "0.88 0.028284271247461926\n",
      "Running Trial 10...\n",
      "0.86 0.060000000000000005\n",
      "Running Trial 11...\n",
      "0.8300000000000001 0.05916079783099616\n",
      "Running Trial 12...\n",
      "0.87 0.051961524227066326\n",
      "Running Trial 13...\n",
      "0.8699999999999999 0.091104335791443\n",
      "Running Trial 14...\n",
      "0.84 0.12328828005937952\n",
      "Running Trial 15...\n",
      "0.83 0.07141428428542852\n",
      "Running Trial 16...\n",
      "0.84 0.028284271247461888\n",
      "Running Trial 17...\n",
      "0.8400000000000001 0.028284271247461888\n",
      "Running Trial 18...\n",
      "0.84 0.04898979485566356\n",
      "Running Trial 19...\n",
      "0.85 0.033166247903553984\n",
      "Running Trial 20...\n",
      "0.8399999999999999 0.08485281374238571\n",
      "Running Trial 21...\n",
      "0.84 0.028284271247461888\n",
      "Running Trial 22...\n",
      "0.8699999999999999 0.05916079783099614\n",
      "Running Trial 23...\n",
      "0.8500000000000001 0.07681145747868606\n",
      "Running Trial 24...\n",
      "0.84 0.04898979485566356\n",
      "Running Trial 25...\n",
      "0.8300000000000001 0.01732050807568874\n",
      "Running Trial 26...\n",
      "0.8999999999999999 0.06633249580710801\n",
      "Running Trial 27...\n",
      "0.85 0.099498743710662\n",
      "Running Trial 28...\n",
      "0.84 0.028284271247461888\n",
      "Running Trial 29...\n",
      "0.8600000000000001 0.044721359549995794\n",
      "Running Trial 30...\n",
      "0.8300000000000001 0.08660254037844385\n",
      "Running Trial 31...\n",
      "0.8099999999999999 0.12449899597988734\n",
      "Running Trial 32...\n",
      "0.8500000000000001 0.07141428428542851\n",
      "Running Trial 33...\n",
      "0.85 0.07681145747868606\n",
      "Running Trial 34...\n",
      "0.88 0.04898979485566356\n",
      "Running Trial 35...\n",
      "0.89 0.033166247903554026\n",
      "Running Trial 36...\n",
      "0.8300000000000001 0.01732050807568874\n",
      "Running Trial 37...\n",
      "0.8200000000000001 0.07211102550927981\n",
      "Running Trial 38...\n",
      "0.85 0.01732050807568879\n",
      "Running Trial 39...\n",
      "0.85 0.01732050807568879\n",
      "Running Trial 40...\n",
      "0.86 0.044721359549995794\n",
      "Running Trial 41...\n",
      "0.86 0.020000000000000018\n",
      "Running Trial 42...\n",
      "0.8600000000000001 0.060000000000000005\n",
      "Running Trial 43...\n",
      "0.8 0.06324555320336758\n",
      "Running Trial 44...\n",
      "0.88 0.028284271247461926\n",
      "Running Trial 45...\n",
      "0.87 0.01732050807568879\n",
      "Running Trial 46...\n",
      "0.8300000000000001 0.05916079783099616\n",
      "Running Trial 47...\n",
      "0.88 0.09797958971132713\n",
      "Running Trial 48...\n",
      "0.87 0.06557438524302002\n",
      "Running Trial 49...\n",
      "0.8700000000000001 0.06557438524302002\n",
      "Running Trial 50...\n",
      "0.8400000000000001 0.08000000000000002\n",
      "Running Trial 51...\n",
      "0.84 0.05656854249492382\n",
      "Running Trial 52...\n",
      "0.85 0.04358898943540674\n",
      "Running Trial 53...\n",
      "0.86 0.05999999999999998\n",
      "Running Trial 54...\n",
      "0.8500000000000001 0.09110433579144299\n",
      "Running Trial 55...\n",
      "0.8400000000000001 0.05656854249492382\n",
      "Running Trial 56...\n",
      "0.88 0.07483314773547882\n",
      "Running Trial 57...\n",
      "0.88 0.04898979485566356\n",
      "Running Trial 58...\n",
      "0.8200000000000001 0.06633249580710801\n",
      "Running Trial 59...\n",
      "0.8200000000000001 0.10770329614269009\n",
      "Running Trial 60...\n",
      "0.82 0.03464101615137753\n",
      "Running Trial 61...\n",
      "0.84 0.04898979485566356\n",
      "Running Trial 62...\n",
      "0.82 0.060000000000000005\n",
      "Running Trial 63...\n",
      "0.87 0.059160797830996134\n",
      "Running Trial 64...\n",
      "0.87 0.033166247903554026\n",
      "Running Trial 65...\n",
      "0.91 0.01732050807568879\n",
      "Running Trial 66...\n",
      "0.83 0.15066519173319365\n",
      "Running Trial 67...\n",
      "0.88 0.0\n",
      "Running Trial 68...\n",
      "0.87 0.033166247903554026\n",
      "Running Trial 69...\n",
      "0.89 0.033166247903554026\n",
      "Running Trial 70...\n",
      "0.8200000000000001 0.08246211251235322\n",
      "Running Trial 71...\n",
      "0.85 0.033166247903553984\n",
      "Running Trial 72...\n",
      "0.8700000000000001 0.04358898943540673\n",
      "Running Trial 73...\n",
      "0.88 0.07483314773547882\n",
      "Running Trial 74...\n",
      "0.84 0.07483314773547885\n",
      "Running Trial 75...\n",
      "0.8400000000000001 0.03999999999999998\n",
      "Running Trial 76...\n",
      "0.8899999999999999 0.043588989435406726\n",
      "Running Trial 77...\n",
      "0.8200000000000001 0.04472135954999579\n",
      "Running Trial 78...\n",
      "0.86 0.09165151389911681\n",
      "Running Trial 79...\n",
      "0.8500000000000001 0.05916079783099617\n",
      "Running Trial 80...\n",
      "0.87 0.01732050807568879\n",
      "Running Trial 81...\n",
      "0.8500000000000001 0.051961524227066305\n",
      "Running Trial 82...\n",
      "0.87 0.033166247903554026\n",
      "Running Trial 83...\n",
      "0.88 0.04898979485566356\n",
      "Running Trial 84...\n",
      "0.84 0.03999999999999998\n",
      "Running Trial 85...\n",
      "0.8799999999999999 0.07483314773547882\n",
      "Running Trial 86...\n",
      "0.87 0.033166247903554026\n",
      "Running Trial 87...\n",
      "0.87 0.01732050807568879\n",
      "Running Trial 88...\n",
      "0.8500000000000001 0.051961524227066305\n",
      "Running Trial 89...\n",
      "0.8600000000000001 0.06\n",
      "Running Trial 90...\n",
      "0.8500000000000001 0.07141428428542851\n",
      "Running Trial 91...\n",
      "0.89 0.01732050807568879\n",
      "Running Trial 92...\n",
      "0.89 0.01732050807568879\n",
      "Running Trial 93...\n",
      "0.8499999999999999 0.08660254037844387\n",
      "Running Trial 94...\n",
      "0.85 0.05916079783099617\n",
      "Running Trial 95...\n",
      "0.87 0.043588989435406726\n",
      "Running Trial 96...\n",
      "0.87 0.059160797830996134\n",
      "Running Trial 97...\n",
      "0.85 0.033166247903553984\n",
      "Running Trial 98...\n",
      "0.8400000000000001 0.0632455532033676\n",
      "Running Trial 99...\n",
      "0.88 0.028284271247461926\n",
      "Running Trial 100...\n",
      "0.88 0.040000000000000036\n"
     ]
    }
   ],
   "source": [
    "parameters = {'estimator__solver': ['lbfgs'], \n",
    "              'estimator__max_iter': [500, 1000, 1500, 2000, 2500, 3000], \n",
    "              'estimator__hidden_layer_sizes':np.linspace(10, 200, 10, dtype=int)\n",
    "             }\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "mlp_nested = nested_cross_validation(mlp, parameters, X, Y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results in csv files\n",
    "\n",
    "# Naive Bayes\n",
    "result_list = []\n",
    "result_columns = [\"Model\", \"Trial\", \"Accuracy\", \"Std_dev\"]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    result_list.append([\"NB\", i, nb_nested[i][0], nb_nested[i][1]])\n",
    "    \n",
    "nb_df = pd.DataFrame(result_list,columns=result_columns)\n",
    "\n",
    "nb_df.to_csv(\"NB_results\")\n",
    "\n",
    "result_list = []\n",
    "result_columns = [\"Model\", \"Trial\", \"Accuracy\", \"Std_dev\"]\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "\n",
    "for i in range(100):\n",
    "    result_list.append([\"RF\", i, rf_nested[i][0], rf_nested[i][1]])\n",
    "    \n",
    "rf_df = pd.DataFrame(result_list,columns=result_columns)\n",
    "\n",
    "rf_df.to_csv(\"RF_results\")\n",
    "\n",
    "result_list = []\n",
    "result_columns = [\"Model\", \"Trial\", \"Accuracy\", \"Std_dev\"]\n",
    "\n",
    "# Multilayer Perceptron\n",
    "\n",
    "for i in range(100):\n",
    "    result_list.append([\"MLP\", i, mlp_nested[i][0], mlp_nested[i][1]])\n",
    "    \n",
    "mlp_df = pd.DataFrame(result_list,columns=result_columns)\n",
    "\n",
    "mlp_df.to_csv(\"MLP_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7614"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(np.array(rf_nested)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Visualise boxplot\n",
    "\n",
    "def read_results(csvfile):\n",
    "    results = []\n",
    "\n",
    "    with open(csvfile, \"r\") as csv_file:\n",
    "        next(csv_file)\n",
    "        for line in csv_file:\n",
    "            temp = line.strip()\n",
    "            temp = temp.split(\",\")\n",
    "            model = temp[1]\n",
    "            results.append(float(temp[-2]))\n",
    "        \n",
    "    return model, results\n",
    "\n",
    "mod1, res1 = read_results(\"NB_results\")\n",
    "mod2, res2 = read_results(\"RF_results\")\n",
    "mod3, res3 = read_results(\"MLP_results\")\n",
    "# res4 = all_scores\n",
    "\n",
    "plt.boxplot([res1, res2, res3], vert = 0, labels=[\"NB\", \"RF\", \"MLP\"])\n",
    "plt.title(\"Model Comparison\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.savefig(\"boxplot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\folke\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\folke\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\folke\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=True),\n",
       "                   error_score=nan,\n",
       "                   estimator=OneVsRestClassifier(estimator=MLPClassifier(activation='relu',\n",
       "                                                                         alpha=0.0001,\n",
       "                                                                         batch_size='auto',\n",
       "                                                                         beta_1=0.9,\n",
       "                                                                         beta_2=0.999,\n",
       "                                                                         early_stopping=False,\n",
       "                                                                         epsilon=1e-08,\n",
       "                                                                         hidden_layer_sizes=(100,),\n",
       "                                                                         learning_rate='constant',\n",
       "                                                                         learning_rate_init=0.001,\n",
       "                                                                         max_fun=15000,...\n",
       "                   param_distributions={'estimator__activation': ['identity',\n",
       "                                                                  'logistic',\n",
       "                                                                  'tanh',\n",
       "                                                                  'relu'],\n",
       "                                        'estimator__hidden_layer_sizes': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190, 200]),\n",
       "                                        'estimator__max_iter': [100, 250, 500,\n",
       "                                                                1000, 1500,\n",
       "                                                                2000, 2500,\n",
       "                                                                3000],\n",
       "                                        'estimator__solver': ['lbfgs', 'sgd',\n",
       "                                                              'adam']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Find best parameters across 10-folds and predict for validation data\n",
    "\n",
    "parameters_mlp = {'estimator__activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    "              'estimator__solver': ['lbfgs', 'sgd', 'adam'], \n",
    "              'estimator__max_iter': [100, 250, 500, 1000, 1500, 2000, 2500, 3000], \n",
    "              'estimator__hidden_layer_sizes':np.linspace(10, 200, 20, dtype=int)\n",
    "             }\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "onevsrest_mlp = OneVsRestClassifier(mlp)\n",
    "        \n",
    "model = RandomizedSearchCV(estimator=onevsrest_mlp, param_distributions=parameters_mlp, cv=folds, n_jobs=-1)\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation set and take features\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "with open(\"Validation_call.txt\", 'r') as temp:\n",
    "    for line in temp:\n",
    "        temp_list.append(line.split())\n",
    "\n",
    "columns_temp = temp_list[0]\n",
    "columns_temp = [x.replace(\"\\\"\", \"\") for x in columns_temp]\n",
    "\n",
    "df_test = pd.DataFrame(temp_list[1:], columns=columns_temp)\n",
    "test_set = df_test.drop(['Chromosome', 'Start','End', 'Nclone'], axis=1)\n",
    "test_set = test_set.transpose()\n",
    "\n",
    "for i, val in enumerate(p_val):\n",
    "    if val >= threshold and i not in important_genes:\n",
    "        test_set = test_set.drop([i], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = test_set.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds = []\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    if pred == 1:\n",
    "        output_preds.append([patient_ids[i],\"HER2+\"])\n",
    "    if pred == 2:\n",
    "        output_preds.append([patient_ids[i],\"HR+\"])\n",
    "    if pred == 3:\n",
    "        output_preds.append([patient_ids[i],\"Triple Neg\"])\n",
    "\n",
    "file1 = open(\"predictions.txt\",\"w\") \n",
    "        \n",
    "file1.write(\"\\\"Sample\\\" \\t \\\"Subgroup\\\"\\n\")\n",
    "for i, prediction in enumerate(predictions):\n",
    "    file1.write(\"\\\"{0}\\\" \\t \\\"{1}\\\"\\n\".format(output_preds[i][0], output_preds[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Array.1', 'HR+'], ['Array.61', 'HER2+'], ['Array.70', 'Triple Neg'], ['Array.14', 'HER2+'], ['Array.91', 'Triple Neg'], ['Array.58', 'Triple Neg'], ['Array.140', 'HER2+'], ['Array.20', 'HR+'], ['Array.133', 'Triple Neg'], ['Array.77', 'HER2+'], ['Array.131', 'HER2+'], ['Array.84', 'HR+'], ['Array.44', 'Triple Neg'], ['Array.41', 'HER2+'], ['Array.29', 'HR+'], ['Array.150', 'HER2+'], ['Array.151', 'HR+'], ['Array.132', 'HR+'], ['Array.32', 'HR+'], ['Array.11', 'HR+'], ['Array.156', 'HR+'], ['Array.80', 'HER2+'], ['Array.9', 'HER2+'], ['Array.3', 'HR+'], ['Array.136', 'HR+'], ['Array.46', 'HER2+'], ['Array.109', 'HER2+'], ['Array.103', 'Triple Neg'], ['Array.97', 'HR+'], ['Array.40', 'HR+'], ['Array.147', 'HER2+'], ['Array.161', 'Triple Neg'], ['Array.127', 'Triple Neg'], ['Array.119', 'Triple Neg'], ['Array.157', 'HER2+'], ['Array.54', 'HR+'], ['Array.115', 'HR+'], ['Array.121', 'HER2+'], ['Array.122', 'HER2+'], ['Array.158', 'Triple Neg'], ['Array.87', 'HER2+'], ['Array.28', 'HER2+'], ['Array.45', 'HR+'], ['Array.155', 'HR+'], ['Array.12', 'HR+'], ['Array.74', 'HER2+'], ['Array.26', 'HR+'], ['Array.120', 'HR+'], ['Array.108', 'HR+'], ['Array.81', 'HER2+'], ['Array.126', 'HR+'], ['Array.92', 'HR+'], ['Array.160', 'Triple Neg'], ['Array.66', 'HR+'], ['Array.83', 'Triple Neg'], ['Array.128', 'HER2+'], ['Array.63', 'HR+']]\n"
     ]
    }
   ],
   "source": [
    "print(output_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"predictions.txt\", output_frame.values, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_filename = \"cats_12_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
