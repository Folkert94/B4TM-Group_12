{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regions found in the literature were:  [2223, 1725, 2021, 2075, 2446, 2794, 1583, 361, 2328, 2733, 111, 937, 2210, 1136, 1965, 688, 1908, 1365, 361, 361, 1911, 1386, 1407, 1407, 664, 1575, 625, 479, 1296, 1866, 1735, 993]\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the significant regions based on literature\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "with open(\"train_call.txt\", 'r') as temp:\n",
    "    for line in temp:\n",
    "        temp_list.append(line.split())\n",
    "\n",
    "columns_temp = temp_list[0]\n",
    "columns_temp = [x.replace(\"\\\"\", \"\") for x in columns_temp]\n",
    "\n",
    "df_train = pd.DataFrame(temp_list[1:], columns=columns_temp)\n",
    "\n",
    "sig_reg_list = []\n",
    "\n",
    "with open(\"significant_regions.csv\", 'r') as sig_regs:\n",
    "    next(sig_regs)\n",
    "    for line in sig_regs:\n",
    "        line_temp = line.split(\",\")\n",
    "        if line_temp[1][1].isdigit():\n",
    "            chromosome = int(line_temp[1][0:2])\n",
    "        else:\n",
    "            chromosome = int(line_temp[1][0])\n",
    "        sig_reg_list.append([chromosome, int(line_temp[2].split()[0]), int(line_temp[2].split()[2])])\n",
    "        \n",
    "chromosomes = df_train[\"Chromosome\"].values.tolist()\n",
    "start_regs = df_train[\"Start\"].values.tolist()\n",
    "end_regs = df_train[\"End\"].values.tolist()\n",
    "\n",
    "chromosomes = [int(i) for i in chromosomes]\n",
    "start_regs = [int(i) for i in start_regs]\n",
    "end_regs = [int(i) for i in end_regs]\n",
    "\n",
    "sig_labels = []\n",
    "\n",
    "for region in sig_reg_list:\n",
    "    for i in range(len(start_regs)):\n",
    "        if region[0] == chromosomes[i] and region[1] > start_regs[i] and region[1] < end_regs[i]:\n",
    "#             print(\"Region = {0} - {1}\".format(start_regs[i], end_regs[i]))\n",
    "#             print(\"Significant region (from literature) = {0} - {1}\\n\".format(region[1], region[2]))\n",
    "            sig_labels.append(i)\n",
    "    \n",
    "print(\"The regions found in the literature were: \", sig_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Loading data\n",
    "df = pd.read_csv('Processed_data_2.csv')\n",
    "\n",
    "# X for features Y for breast cancer subtype where 1 = HER2+, 2 = HR+, 3 = Triple Neg\n",
    "X = df.drop(['Unnamed: 0', 'Sample','Subgroup'], axis=1)\n",
    "Y = df['Subgroup']\n",
    "\n",
    "patients = X.values.tolist()\n",
    "labels = Y.values.tolist()\n",
    "\n",
    "## FEATURE SELECTION\n",
    "\n",
    "# we need to shift the features by 1 since the chi2 function does not take non-negative values\n",
    "patients_shift = []\n",
    "\n",
    "for patient in patients:\n",
    "    x = []\n",
    "    for feature in patient:\n",
    "        x.append(feature + 1)\n",
    "    patients_shift.append(x)\n",
    "\n",
    "chi, p_val = chi2(patients_shift, Y)\n",
    "\n",
    "X_feature_selected = df\n",
    "\n",
    "p_value = 0.05\n",
    "for i, val in enumerate(p_val):\n",
    "    # this drops the p_values higher than 0.05 that are not in the significant genes list\n",
    "    if val >= p_value and i not in sig_labels:\n",
    "        X_feature_selected = X_feature_selected.drop([\"V{}\".format(i + 1)], axis=1)\n",
    "        \n",
    "X = X_feature_selected.drop(['Unnamed: 0', 'Sample','Subgroup'], axis=1)\n",
    "patients = X.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    V112  V193  V362  V480  V626  V665  V669  V670  V671  V672  ...  V2224  \\\n",
      "0     -1     1    -1     0     0     0     0     0     0     0  ...     -1   \n",
      "1      0    -1     0     0     0     0     0     0     0     0  ...      0   \n",
      "2      0     0     1     1     1     1     1     1     1     1  ...      0   \n",
      "3     -1    -1     0     1     0     0     0     0     0     0  ...      0   \n",
      "4      0    -1     0     0     0     0     0     0     0     0  ...      0   \n",
      "..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
      "95     1    -1     0     1     0     0     0     0     0     0  ...      0   \n",
      "96     0     2     0     0     0     0     0     0     0     0  ...      0   \n",
      "97     0     0     0     0     1     1     1     1     1     1  ...      0   \n",
      "98     0    -1     0     1     1     1     1     1     1     1  ...      0   \n",
      "99    -1    -1     0    -1     0     0     0     0     0     0  ...      0   \n",
      "\n",
      "    V2225  V2329  V2447  V2724  V2733  V2734  V2751  V2752  V2795  \n",
      "0      -1      1     -1     -1     -1     -1     -1     -1      1  \n",
      "1       0      0      0      0      0      0      0      0      1  \n",
      "2       0      0      1      0      0      0      0      0      1  \n",
      "3       0      0      0      0      0      0      0      0      1  \n",
      "4       0      0      0      0      0      0      0      0      1  \n",
      "..    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "95      0      0     -1      1      1      1      0      0      1  \n",
      "96      0      0      0      0      0      0      1      0      1  \n",
      "97      0      0      1      0      0      0      0      0      1  \n",
      "98      0      0      1     -1     -1     -1     -1     -1      1  \n",
      "99      0      0      0     -1     -1     -1      0      0      1  \n",
      "\n",
      "[100 rows x 163 columns]\n",
      "Number of features = 163\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(\"Number of features = {}\".format(len(patients[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    \"Scorer for the cross validation function\"\n",
    "    originalclass.extend(y_true)\n",
    "    predictedclass.extend(y_pred)\n",
    "    return accuracy_score(y_true, y_pred) \n",
    "\n",
    "def evaluate_model(model, features, labels):\n",
    "    \"Gets the cross validation score using a 5-fold (cv=5) cross validation\"\n",
    "    scores = cross_val_score(model, features, labels, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.88      0.85        32\n",
      "           2       0.74      0.72      0.73        36\n",
      "           3       0.68      0.66      0.67        32\n",
      "\n",
      "    accuracy                           0.75       100\n",
      "   macro avg       0.75      0.75      0.75       100\n",
      "weighted avg       0.75      0.75      0.75       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "temp = evaluate_model(random_forest, X, Y)\n",
    "print(classification_report(originalclass, predictedclass)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.78      0.88        32\n",
      "           2       0.76      0.81      0.78        36\n",
      "           3       0.68      0.78      0.72        32\n",
      "\n",
      "    accuracy                           0.79       100\n",
      "   macro avg       0.81      0.79      0.80       100\n",
      "weighted avg       0.81      0.79      0.79       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "gnb = GaussianNB()\n",
    "temp = evaluate_model(gnb, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.91      0.94        32\n",
      "           2       0.79      0.86      0.83        36\n",
      "           3       0.84      0.81      0.83        32\n",
      "\n",
      "    accuracy                           0.86       100\n",
      "   macro avg       0.87      0.86      0.86       100\n",
      "weighted avg       0.86      0.86      0.86       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural network with 1 hidden layer (the hidden layer is as big as the number of features)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation=\"relu\", alpha=1e-5,\n",
    "                    hidden_layer_sizes=(len(patients[0]),), max_iter=1000)\n",
    "\n",
    "temp = evaluate_model(mlp, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.94      0.92        32\n",
      "           2       0.81      0.83      0.82        36\n",
      "           3       0.87      0.81      0.84        32\n",
      "\n",
      "    accuracy                           0.86       100\n",
      "   macro avg       0.86      0.86      0.86       100\n",
      "weighted avg       0.86      0.86      0.86       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural network with 2 hidden layer (the hidden layer is as big as the number of features)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation=\"relu\", alpha=1e-5,\n",
    "                    hidden_layer_sizes=(len(patients[0]),len(patients[0])), max_iter=1000)\n",
    "\n",
    "temp = evaluate_model(mlp, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.94      0.94        32\n",
      "           2       0.79      0.83      0.81        36\n",
      "           3       0.80      0.75      0.77        32\n",
      "\n",
      "    accuracy                           0.84       100\n",
      "   macro avg       0.84      0.84      0.84       100\n",
      "weighted avg       0.84      0.84      0.84       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural network with 3 hidden layer (the hidden layer is as big as the number of features)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation=\"relu\", alpha=1e-5,\n",
    "                    hidden_layer_sizes=(len(patients[0]),len(patients[0]),len(patients[0])), max_iter=1000)\n",
    "\n",
    "temp = evaluate_model(mlp, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
