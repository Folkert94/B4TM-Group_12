{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0    1    2    3    4    5    6    7    8    9     ... 2824 2825  \\\n",
      "Array.129    0    0    0    0    0    0    0    0    0    0  ...    2    2   \n",
      "Array.34     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.67     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.24     0    0    0    0    0    0    0   -1    0    0  ...    0    0   \n",
      "Array.22     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "Array.10     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.123    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.100    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.134   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    1    1   \n",
      "Array.130    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "\n",
      "          2826 2827 2828 2829 2830 2831 2832 2833  \n",
      "Array.129    2    2    0    1    1    1    1    1  \n",
      "Array.34     1    1    1    1    1    1    1    1  \n",
      "Array.67     1    1    1    1    1    1    1    1  \n",
      "Array.24     0    0    0    0    0    0    0    0  \n",
      "Array.22     1    1    1    1    1    1    1    1  \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "Array.10     0    1    1    1    1    1    1    1  \n",
      "Array.123    1    1    1    1    1    1    1    1  \n",
      "Array.100    1    1    1    1    1    1    1    1  \n",
      "Array.134    1    1    1    1    1    1    1    1  \n",
      "Array.130    1    1    1    1    1    1    1    1  \n",
      "\n",
      "[100 rows x 2834 columns]\n",
      "[1, 2, 2, 3, 3, 2, 1, 1, 3, 1, 2, 3, 1, 1, 3, 3, 2, 1, 2, 2, 3, 1, 2, 1, 2, 1, 1, 3, 1, 2, 2, 1, 2, 1, 2, 2, 3, 3, 3, 1, 2, 3, 2, 3, 2, 3, 1, 1, 3, 3, 1, 2, 2, 3, 2, 3, 1, 1, 3, 2, 1, 2, 3, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 3, 1, 3, 2, 3, 3, 3, 3, 2, 1, 1, 2, 3, 3, 3, 3, 2, 3, 2, 3, 1, 2, 2, 2, 1]\n",
      "The regions found in the literature were:  [111, 157, 249, 65, 361, 360, 479, 576, 583, 688, 664, 625, 670, 772, 876, 877, 878, 937, 991, 992, 993, 966, 1136, 1137, 1092, 1207, 1234, 1370, 1371, 1387, 1296, 1310, 1583, 1407, 1575, 1513, 1589, 1611, 1697, 1645, 1657, 1725, 1734, 1735, 1865, 1904, 1911, 2017, 1965, 2015, 2016, 2207, 2074, 2075, 2306, 2184, 2135, 2136, 2200, 2201, 2071, 2160, 2161, 2446, 2681, 2682, 2683, 2684, 2685, 2732, 2744, 2794, 2822]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "with open(\"train_call.txt\", 'r') as temp:\n",
    "    for line in temp:\n",
    "        temp_list.append(line.split())\n",
    "\n",
    "columns_temp = temp_list[0]\n",
    "columns_temp = [x.replace(\"\\\"\", \"\") for x in columns_temp]\n",
    "\n",
    "df_train = pd.DataFrame(temp_list[1:], columns=columns_temp)\n",
    "X = df_train.drop(['Chromosome', 'Start','End', 'Nclone'], axis=1)\n",
    "X = X.transpose()\n",
    "\n",
    "labels = []\n",
    "\n",
    "# X for features Y for breast cancer subtype where 1 = HER2+, 2 = HR+, 3 = Triple Neg\n",
    "with open(\"Train_clinical.txt\", 'r') as temp_labels:\n",
    "    next(temp_labels)\n",
    "    for line in temp_labels:\n",
    "        temp = line.strip()\n",
    "        temp = temp.split()\n",
    "        if temp[1].strip(\"\\\"\") == \"HER2+\":\n",
    "            labels.append(1)\n",
    "        if temp[1].strip(\"\\\"\") == \"HR+\":\n",
    "            labels.append(2)\n",
    "        if temp[1].strip(\"\\\"\") == \"Triple\":\n",
    "            labels.append(3)\n",
    "\n",
    "Y = labels\n",
    "            \n",
    "important_genes = []\n",
    "\n",
    "with open(\"important_genes_2.csv\", 'r') as imp_genes:\n",
    "    for line in imp_genes:\n",
    "        temp = line.strip()\n",
    "        important_genes.append(temp.split(\",\"))\n",
    "        \n",
    "imp_genes = []\n",
    "\n",
    "for gene in important_genes[1:]:\n",
    "    imp_genes.append([gene[0], gene[1], gene[2], gene[3]])\n",
    "    \n",
    "important_genes = []\n",
    "\n",
    "for x in imp_genes:\n",
    "    for i, y in enumerate(df_train.values.tolist()):\n",
    "        if x[1] == y[0] and x[2] == y[1] and x[3] == y[2]:\n",
    "            important_genes.append(i)\n",
    "            \n",
    "print(X)\n",
    "print(Y)\n",
    "print(\"The regions found in the literature were: \", important_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Gene  Region number       P-value Yes/No\n",
      "0              DIRAS3            111  6.897062e-01     No\n",
      "1              PTPN22            157  7.287985e-01     No\n",
      "2                 AGT            249  9.791761e-01     No\n",
      "3               CLSPN             65  5.039604e-01     No\n",
      "4   BARD1/CASP8/CTLA4            361  8.022867e-01     No\n",
      "5               SF3B1            360  8.717109e-01     No\n",
      "6              PIK3CA            479  4.007464e-01     No\n",
      "7               NFKB1            576  8.076397e-01     No\n",
      "8                FGF2            583  8.076397e-01     No\n",
      "9               RAD50            688  1.138701e-01     No\n",
      "10             MAP3K1            664  1.569463e-01     No\n",
      "11               TERT            625  9.757757e-01     No\n",
      "12             PIK3R1            670  4.250528e-02    Yes\n",
      "13              CCND3            772  1.568220e-01     No\n",
      "14               ESR1            876  4.297669e-01     No\n",
      "15               ESR1            877  3.435048e-01     No\n",
      "16               ESR1            878  3.384654e-01     No\n",
      "17               EGFR            937  9.492498e-01     No\n",
      "18       KMT2C (MLL3)            991  8.738841e-01     No\n",
      "19       KMT2C (MLL3)            992  8.280285e-01     No\n",
      "20       KMT2C (MLL3)            993  8.014328e-01     No\n",
      "21          CAV1/CAV2            966  8.425206e-01     No\n",
      "22                NBN           1136  7.630498e-01     No\n",
      "23                NBN           1137  7.911207e-01     No\n",
      "24              IKBKB           1092  7.408158e-02     No\n",
      "25              PTPRD           1207  5.060686e-01     No\n",
      "26               MELK           1234  6.914782e-01     No\n",
      "27               PTEN           1370  9.529703e-01     No\n",
      "28               PTEN           1371  7.162040e-01     No\n",
      "29              FGFR2           1387  9.025203e-01     No\n",
      "30              GATA3           1296  6.855018e-01     No\n",
      "31              MASTL           1310  4.611954e-01     No\n",
      "32                ATM           1583  2.250590e-01     No\n",
      "33           H19/LSP1           1407  5.048502e-01     No\n",
      "34           MRE11(A)           1575  2.436539e-01     No\n",
      "35              CCND1           1513  6.078381e-01     No\n",
      "36              TIRAP           1589  1.729887e-01     No\n",
      "37             CDKN1B           1611  7.665508e-01     No\n",
      "38               TBX3           1697  7.967035e-01     No\n",
      "39               KRT5           1645  1.479597e-01     No\n",
      "40               IL22           1657  5.859564e-02     No\n",
      "41              BRCA2           1725  6.931973e-01     No\n",
      "42                RB1           1734  3.485173e-01     No\n",
      "43                RB1           1735  4.047287e-01     No\n",
      "44               AKT1           1865  3.883914e-01     No\n",
      "45              RAD51           1904  2.001524e-01     No\n",
      "46            CYP19A1           1911  2.163115e-01     No\n",
      "47               CDH1           2017  4.623894e-02    Yes\n",
      "48              PALB2           1965  5.683650e-01     No\n",
      "49               CBFB           2015  1.517658e-01     No\n",
      "50               CDH3           2016  1.160794e-01     No\n",
      "51              BRCA1           2207  3.346706e-03    Yes\n",
      "52               TP53           2074  3.249625e-02    Yes\n",
      "53               TP53           2075  3.249625e-02    Yes\n",
      "54              BRIP1           2306  6.918517e-01     No\n",
      "55       ERBB2 (HER2)           2184  8.326227e-14    Yes\n",
      "56                NF1           2135  2.972004e-01     No\n",
      "57                NF1           2136  6.509545e-01     No\n",
      "58              KRT14           2200  4.172152e-01     No\n",
      "59              KRT17           2201  6.104122e-01     No\n",
      "60             ALOX15           2071  9.275122e-02     No\n",
      "61               CCL5           2160  5.475658e-01     No\n",
      "62               CCL4           2161  6.103237e-01     No\n",
      "63         STK11/LKB1           2446  9.669922e-01     No\n",
      "64              RUNX1           2681  5.234851e-01     No\n",
      "65              RUNX1           2682  4.492747e-01     No\n",
      "66              RUNX1           2683  5.987332e-01     No\n",
      "67              RUNX1           2684  6.175287e-01     No\n",
      "68              RUNX1           2685  5.718320e-01     No\n",
      "69              CHEK2           2732  4.082143e-02    Yes\n",
      "70              PDGFB           2744  9.509540e-02     No\n",
      "71                 AR           2794  7.771286e-01     No\n",
      "72               AFF2           2822  9.299035e-01     No\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# #Loading data\n",
    "patients = X.values.tolist()\n",
    "\n",
    "## FEATURE SELECTION\n",
    "\n",
    "# we need to shift the features by 1 since the chi2 function does not take non-negative values\n",
    "patients_shift = []\n",
    "\n",
    "for patient in patients:\n",
    "    x = []\n",
    "    for feature in patient:\n",
    "        x.append(int(feature) + 1)\n",
    "    patients_shift.append(x)\n",
    "\n",
    "chi, p_val = chi2(patients_shift, Y)\n",
    "\n",
    "imp_genes_p_values = []\n",
    "\n",
    "for i, j in enumerate(important_genes):\n",
    "    if p_val[j] >= 0.05:\n",
    "        imp_genes_p_values.append([imp_genes[i][0], j, p_val[j], \"No\"])\n",
    "    else:\n",
    "        imp_genes_p_values.append([imp_genes[i][0], j, p_val[j], \"Yes\"])\n",
    "    \n",
    "\n",
    "important_genes_scores = pd.DataFrame(imp_genes_p_values, columns=[\"Gene\", \"Region number\", \"P-value\", \"Yes/No\"])\n",
    "pd.set_option('display.max_rows', 75)\n",
    "print(important_genes_scores)\n",
    "\n",
    "X_feature_selected = X\n",
    "\n",
    "threshold = 0.05\n",
    "for i, val in enumerate(p_val):\n",
    "    # this drops the p_values higher than 0.05 that are not in the significant genes list\n",
    "    if val >= threshold and i not in important_genes:\n",
    "        X_feature_selected = X_feature_selected.drop([i], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 204\n"
     ]
    }
   ],
   "source": [
    "X = X_feature_selected\n",
    "number_of_features = len(X.values.tolist()[0])\n",
    "print(\"Number of features = {}\".format(number_of_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array.129     2\n",
      "Array.34      0\n",
      "Array.67     -1\n",
      "Array.24      0\n",
      "Array.22      0\n",
      "             ..\n",
      "Array.10      2\n",
      "Array.123     0\n",
      "Array.100     0\n",
      "Array.134     1\n",
      "Array.130     2\n",
      "Name: 2184, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.iloc[:,170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    \"Scorer for the cross validation function\"\n",
    "    originalclass.extend(y_true)\n",
    "    predictedclass.extend(y_pred)\n",
    "    return accuracy_score(y_true, y_pred) \n",
    "\n",
    "def evaluate_model(model, features, labels):\n",
    "    \"Gets the cross validation score using a 5-fold (cv=5) cross validation\"\n",
    "    scores = cross_val_score(model, features, labels, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cross_validation(MODEL, PARAMS, X, Y, NUM_TRIALS):\n",
    "    model_scores = np.zeros(NUM_TRIALS)\n",
    "    model_params = {}\n",
    "    nested_scores = []\n",
    "    \n",
    "    for i in range(NUM_TRIALS):\n",
    "        print(\"Running Trial {}...\".format(i + 1))\n",
    "        inner_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "        outer_cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=i)\n",
    "        \n",
    "        model = GridSearchCV(estimator=MODEL, param_grid=PARAMS, cv=inner_cv, n_jobs=2)\n",
    "        model.fit(X, Y)\n",
    "        print(model.score(X, Y), model.best_params_)\n",
    "        model_scores[i] = model.score(X, Y)\n",
    "        model_params[i] = model.best_params_\n",
    "        \n",
    "        nested_score = cross_val_score(model, X=X, y=Y, cv=outer_cv)\n",
    "        nested_scores.append([nested_score.mean(), nested_score.std()])\n",
    "        print(nested_score.mean(), nested_score.std())\n",
    "        \n",
    "    return model_scores, model_params, nested_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Trial 1...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8300000000000001 0.11090536506409417\n",
      "Running Trial 2...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.87 0.033166247903554026\n",
      "Running Trial 3...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.88 0.040000000000000036\n",
      "Running Trial 4...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.8 0.028284271247461888\n",
      "Running Trial 5...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.8699999999999999 0.05916079783099614\n",
      "Running Trial 6...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8500000000000001 0.07141428428542851\n",
      "Running Trial 7...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.83 0.11090536506409417\n",
      "Running Trial 8...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8700000000000001 0.04358898943540673\n",
      "Running Trial 9...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8799999999999999 0.04898979485566356\n",
      "Running Trial 10...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8400000000000001 0.06324555320336758\n",
      "Running Trial 11...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8400000000000001 0.06928203230275506\n",
      "Running Trial 12...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.86 0.06633249580710801\n",
      "Running Trial 13...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.84 0.13266499161421597\n",
      "Running Trial 14...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.84 0.10198039027185567\n",
      "Running Trial 15...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8400000000000001 0.05656854249492382\n",
      "Running Trial 16...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8400000000000001 0.04898979485566356\n",
      "Running Trial 17...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.8400000000000001 0.028284271247461888\n",
      "Running Trial 18...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.86 0.044721359549995794\n",
      "Running Trial 19...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.83 0.051961524227066305\n",
      "Running Trial 20...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.81 0.12124355652982138\n",
      "Running Trial 21...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.87 0.043588989435406726\n",
      "Running Trial 22...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.87 0.051961524227066326\n",
      "Running Trial 23...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.8500000000000001 0.04358898943540674\n",
      "Running Trial 24...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8 0.028284271247461888\n",
      "Running Trial 25...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.81 0.05916079783099617\n",
      "Running Trial 26...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8699999999999999 0.09110433579144296\n",
      "Running Trial 27...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8600000000000001 0.08246211251235319\n",
      "Running Trial 28...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.85 0.033166247903553984\n",
      "Running Trial 29...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8600000000000001 0.060000000000000005\n",
      "Running Trial 30...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8400000000000001 0.06928203230275505\n",
      "Running Trial 31...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.84 0.09380831519646858\n",
      "Running Trial 32...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.8400000000000001 0.08485281374238572\n",
      "Running Trial 33...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.86 0.0447213595499958\n",
      "Running Trial 34...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.86 0.020000000000000018\n",
      "Running Trial 35...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.88 0.028284271247461926\n",
      "Running Trial 36...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.81 0.017320508075688742\n",
      "Running Trial 37...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.81 0.04358898943540673\n",
      "Running Trial 38...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8300000000000001 0.05916079783099616\n",
      "Running Trial 39...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.88 0.040000000000000036\n",
      "Running Trial 40...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.86 0.044721359549995794\n",
      "Running Trial 41...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.9 0.020000000000000018\n",
      "Running Trial 42...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.8800000000000001 0.04898979485566356\n",
      "Running Trial 43...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.81 0.07141428428542851\n",
      "Running Trial 44...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.83 0.043588989435406726\n",
      "Running Trial 45...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.86 0.020000000000000018\n",
      "Running Trial 46...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.85 0.04358898943540674\n",
      "Running Trial 47...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.86 0.0447213595499958\n",
      "Running Trial 48...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.85 0.05916079783099617\n",
      "Running Trial 49...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8500000000000001 0.05196152422706632\n",
      "Running Trial 50...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.8400000000000001 0.04898979485566356\n",
      "Running Trial 51...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.8300000000000001 0.0768114574786861\n",
      "Running Trial 52...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.85 0.04358898943540674\n",
      "Running Trial 53...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.8999999999999999 0.044721359549995794\n",
      "Running Trial 54...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8600000000000001 0.10392304845413264\n",
      "Running Trial 55...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8400000000000001 0.04898979485566356\n",
      "Running Trial 56...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8200000000000001 0.09165151389911678\n",
      "Running Trial 57...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.86 0.03464101615137758\n",
      "Running Trial 58...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8500000000000001 0.09110433579144298\n",
      "Running Trial 59...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.7900000000000001 0.099498743710662\n",
      "Running Trial 60...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8 0.03999999999999998\n",
      "Running Trial 61...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.86 0.060000000000000005\n",
      "Running Trial 62...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.86 0.03464101615137758\n",
      "Running Trial 63...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.86 0.05999999999999998\n",
      "Running Trial 64...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.84 0.028284271247461888\n",
      "Running Trial 65...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8600000000000001 0.060000000000000005\n",
      "Running Trial 66...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.85 0.10344080432788598\n",
      "Running Trial 67...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.87 0.04358898943540673\n",
      "Running Trial 68...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.86 0.03464101615137753\n",
      "Running Trial 69...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.86 0.0447213595499958\n",
      "Running Trial 70...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.86 0.03464101615137758\n",
      "Running Trial 71...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.87 0.033166247903554026\n",
      "Running Trial 72...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.8500000000000001 0.051961524227066305\n",
      "Running Trial 73...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.87 0.04358898943540673\n",
      "Running Trial 74...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.87 0.04358898943540673\n",
      "Running Trial 75...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8600000000000001 0.034641016151377525\n",
      "Running Trial 76...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8699999999999999 0.05916079783099614\n",
      "Running Trial 77...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8300000000000001 0.04358898943540673\n",
      "Running Trial 78...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.89 0.07681145747868608\n",
      "Running Trial 79...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.8300000000000001 0.07141428428542851\n",
      "Running Trial 80...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.8899999999999999 0.05916079783099614\n",
      "Running Trial 81...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8300000000000001 0.0768114574786861\n",
      "Running Trial 82...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.84 0.06928203230275512\n",
      "Running Trial 83...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.85 0.033166247903553984\n",
      "Running Trial 84...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.84 0.0632455532033676\n",
      "Running Trial 85...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8400000000000001 0.028284271247461888\n",
      "Running Trial 86...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.86 0.03464101615137753\n",
      "Running Trial 87...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.85 0.033166247903553984\n",
      "Running Trial 88...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8300000000000001 0.05196152422706631\n",
      "Running Trial 89...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8400000000000001 0.0632455532033676\n",
      "Running Trial 90...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.8300000000000001 0.05196152422706632\n",
      "Running Trial 91...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.8700000000000001 0.043588989435406726\n",
      "Running Trial 92...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 500, 'solver': 'lbfgs'}\n",
      "0.86 0.0447213595499958\n",
      "Running Trial 93...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.8699999999999999 0.07681145747868608\n",
      "Running Trial 94...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.83 0.043588989435406726\n",
      "Running Trial 95...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.8599999999999999 0.07211102550927977\n",
      "Running Trial 96...\n",
      "1.0 {'hidden_layer_sizes': 81, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.88 0.06324555320336757\n",
      "Running Trial 97...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.86 0.044721359549995794\n",
      "Running Trial 98...\n",
      "1.0 {'hidden_layer_sizes': 20, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
      "0.8799999999999999 0.04898979485566356\n",
      "Running Trial 99...\n",
      "1.0 {'hidden_layer_sizes': 142, 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "0.88 0.028284271247461926\n",
      "Running Trial 100...\n",
      "1.0 {'hidden_layer_sizes': 204, 'max_iter': 2000, 'solver': 'lbfgs'}\n",
      "0.8400000000000001 0.03999999999999998\n"
     ]
    }
   ],
   "source": [
    "parameters = {'solver': ['lbfgs'], \n",
    "              'max_iter': [500, 1000, 1500, 2000], \n",
    "              'hidden_layer_sizes':np.linspace(20, number_of_features, 4, dtype=int)\n",
    "             }\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "mlp_scores, mlp_params, mlp_nested = nested_cross_validation(mlp, parameters, X, Y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Trial 1...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.76 0.028284271247461926\n",
      "Running Trial 2...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 162}\n",
      "0.8200000000000001 0.06\n",
      "Running Trial 3...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.8300000000000001 0.05196152422706631\n",
      "Running Trial 4...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.7500000000000001 0.0714142842854285\n",
      "Running Trial 5...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.76 0.08485281374238571\n",
      "Running Trial 6...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 162}\n",
      "0.81 0.06557438524302002\n",
      "Running Trial 7...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.7999999999999999 0.09380831519646858\n",
      "Running Trial 8...\n",
      "0.99 {'max_features': 'auto', 'n_estimators': 50}\n",
      "0.82 0.09999999999999996\n",
      "Running Trial 9...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.76 0.040000000000000036\n",
      "Running Trial 10...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 275}\n",
      "0.81 0.11445523142259596\n",
      "Running Trial 11...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.8 0.08000000000000002\n",
      "Running Trial 12...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 387}\n",
      "0.79 0.08185352771872453\n",
      "Running Trial 13...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 275}\n",
      "0.76 0.08485281374238571\n",
      "Running Trial 14...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 500}\n",
      "0.79 0.11789826122551599\n",
      "Running Trial 15...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.79 0.033166247903553984\n",
      "Running Trial 16...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.78 0.08246211251235319\n",
      "Running Trial 17...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 50}\n",
      "0.7800000000000001 0.1\n",
      "Running Trial 18...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 50}\n",
      "0.74 0.10392304845413264\n",
      "Running Trial 19...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.74 0.12806248474865695\n",
      "Running Trial 20...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 162}\n",
      "0.75 0.091104335791443\n",
      "Running Trial 21...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.7899999999999999 0.09110433579144299\n",
      "Running Trial 22...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 387}\n",
      "0.78 0.07211102550927977\n",
      "Running Trial 23...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 50}\n",
      "0.8 0.028284271247461888\n",
      "Running Trial 24...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 50}\n",
      "0.76 0.04898979485566356\n",
      "Running Trial 25...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.7600000000000001 0.06324555320336757\n",
      "Running Trial 26...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.75 0.09949874371066199\n",
      "Running Trial 27...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 275}\n",
      "0.8 0.08944271909999159\n",
      "Running Trial 28...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 500}\n",
      "0.8099999999999999 0.07681145747868605\n",
      "Running Trial 29...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.7600000000000001 0.07483314773547882\n",
      "Running Trial 30...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.78 0.11489125293076059\n",
      "Running Trial 31...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 500}\n",
      "0.79 0.04358898943540674\n",
      "Running Trial 32...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.77 0.07681145747868608\n",
      "Running Trial 33...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.73 0.05916079783099617\n",
      "Running Trial 34...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 500}\n",
      "0.7300000000000001 0.033166247903553984\n",
      "Running Trial 35...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 387}\n",
      "0.77 0.043588989435406726\n",
      "Running Trial 36...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 387}\n",
      "0.75 0.05196152422706632\n",
      "Running Trial 37...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 162}\n",
      "0.8 0.05656854249492382\n",
      "Running Trial 38...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.76 0.09797958971132713\n",
      "Running Trial 39...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.77 0.06557438524302002\n",
      "Running Trial 40...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 162}\n",
      "0.7999999999999999 0.09380831519646858\n",
      "Running Trial 41...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 50}\n",
      "0.8 0.028284271247461888\n",
      "Running Trial 42...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 387}\n",
      "0.75 0.07681145747868608\n",
      "Running Trial 43...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.74 0.07211102550927977\n",
      "Running Trial 44...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 50}\n",
      "0.7500000000000001 0.05916079783099614\n",
      "Running Trial 45...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.76 0.08485281374238568\n",
      "Running Trial 46...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.7200000000000001 0.05656854249492382\n",
      "Running Trial 47...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.7 0.060000000000000005\n",
      "Running Trial 48...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 50}\n",
      "0.74 0.0447213595499958\n",
      "Running Trial 49...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.81 0.051961524227066305\n",
      "Running Trial 50...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 500}\n",
      "0.71 0.04358898943540673\n",
      "Running Trial 51...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.76 0.04898979485566356\n",
      "Running Trial 52...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.8200000000000001 0.07211102550927981\n",
      "Running Trial 53...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 50}\n",
      "0.78 0.05999999999999998\n",
      "Running Trial 54...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 500}\n",
      "0.77 0.10723805294763608\n",
      "Running Trial 55...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.74 0.03464101615137758\n",
      "Running Trial 56...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 275}\n",
      "0.81 0.06557438524302002\n",
      "Running Trial 57...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 162}\n",
      "0.75 0.059160797830996134\n",
      "Running Trial 58...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.77 0.04358898943540673\n",
      "Running Trial 59...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 387}\n",
      "0.8 0.04898979485566356\n",
      "Running Trial 60...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.73 0.033166247903553984\n",
      "Running Trial 61...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.7999999999999999 0.09380831519646858\n",
      "Running Trial 62...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.8 0.028284271247461888\n",
      "Running Trial 63...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.8200000000000001 0.07211102550927981\n",
      "Running Trial 64...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.8 0.08944271909999157\n",
      "Running Trial 65...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 275}\n",
      "0.77 0.051961524227066326\n",
      "Running Trial 66...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 162}\n",
      "0.75 0.06557438524302002\n",
      "Running Trial 67...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.78 0.0447213595499958\n",
      "Running Trial 68...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.79 0.11090536506409417\n",
      "Running Trial 69...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.77 0.059160797830996134\n",
      "Running Trial 70...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 275}\n",
      "0.8200000000000001 0.06633249580710801\n",
      "Running Trial 71...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.77 0.07141428428542848\n",
      "Running Trial 72...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 387}\n",
      "0.79 0.05916079783099617\n",
      "Running Trial 73...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 275}\n",
      "0.72 0.07483314773547886\n",
      "Running Trial 74...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 500}\n",
      "0.79 0.033166247903553984\n",
      "Running Trial 75...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.7500000000000001 0.1072380529476361\n",
      "Running Trial 76...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.77 0.05196152422706632\n",
      "Running Trial 77...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.7799999999999999 0.10392304845413264\n",
      "Running Trial 78...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.8 0.0632455532033676\n",
      "Running Trial 79...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 162}\n",
      "0.77 0.09110433579144299\n",
      "Running Trial 80...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 500}\n",
      "0.79 0.033166247903553984\n",
      "Running Trial 81...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.81 0.08660254037844385\n",
      "Running Trial 82...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.73 0.07681145747868606\n",
      "Running Trial 83...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.79 0.07141428428542851\n",
      "Running Trial 84...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.71 0.03316624790355398\n",
      "Running Trial 85...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.79 0.10344080432788601\n",
      "Running Trial 86...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.79 0.07141428428542848\n",
      "Running Trial 87...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 275}\n",
      "0.79 0.05196152422706631\n",
      "Running Trial 88...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.76 0.04898979485566356\n",
      "Running Trial 89...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 275}\n",
      "0.78 0.044721359549995794\n",
      "Running Trial 90...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.82 0.10770329614269007\n",
      "Running Trial 91...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 50}\n",
      "0.77 0.11445523142259599\n",
      "Running Trial 92...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 500}\n",
      "0.81 0.051961524227066305\n",
      "Running Trial 93...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 50}\n",
      "0.76 0.07999999999999996\n",
      "Running Trial 94...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 275}\n",
      "0.73 0.11090536506409417\n",
      "Running Trial 95...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 275}\n",
      "0.79 0.05196152422706631\n",
      "Running Trial 96...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 275}\n",
      "0.84 0.028284271247461888\n",
      "Running Trial 97...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.77 0.059160797830996134\n",
      "Running Trial 98...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 387}\n",
      "0.75 0.07681145747868608\n",
      "Running Trial 99...\n",
      "1.0 {'max_features': 'auto', 'n_estimators': 162}\n",
      "0.8200000000000001 0.04472135954999579\n",
      "Running Trial 100...\n",
      "1.0 {'max_features': 'sqrt', 'n_estimators': 162}\n",
      "0.76 0.08485281374238568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 500, num = 5, dtype=int)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Create the random grid\n",
    "parameters = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_scores, rf_params, rf_nested = nested_cross_validation(rf, parameters, X, Y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Trial 1...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.81 0.0768114574786861\n",
      "Running Trial 2...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8099999999999999 0.1072380529476361\n",
      "Running Trial 3...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8 0.0692820323027551\n",
      "Running Trial 4...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8 0.04898979485566356\n",
      "Running Trial 5...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.77 0.11445523142259599\n",
      "Running Trial 6...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.79 0.04358898943540674\n",
      "Running Trial 7...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.78 0.08717797887081347\n",
      "Running Trial 8...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.83 0.12449899597988731\n",
      "Running Trial 9...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.78 0.034641016151377525\n",
      "Running Trial 10...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.78 0.1\n",
      "Running Trial 11...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.81 0.11090536506409417\n",
      "Running Trial 12...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8199999999999998 0.10392304845413264\n",
      "Running Trial 13...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8300000000000001 0.08660254037844384\n",
      "Running Trial 14...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8200000000000001 0.11489125293076059\n",
      "Running Trial 15...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.78 0.06633249580710801\n",
      "Running Trial 16...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8400000000000001 0.06928203230275506\n",
      "Running Trial 17...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.81 0.05916079783099616\n",
      "Running Trial 18...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.78 0.08717797887081347\n",
      "Running Trial 19...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8200000000000001 0.060000000000000005\n",
      "Running Trial 20...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.7500000000000001 0.1396424004376894\n",
      "Running Trial 21...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8200000000000001 0.060000000000000005\n",
      "Running Trial 22...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8300000000000001 0.05916079783099616\n",
      "Running Trial 23...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.77 0.07681145747868608\n",
      "Running Trial 24...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8 0.06324555320336758\n",
      "Running Trial 25...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.79 0.033166247903553984\n",
      "Running Trial 26...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.73 0.10723805294763607\n",
      "Running Trial 27...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.84 0.05656854249492382\n",
      "Running Trial 28...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8 0.0748331477354788\n",
      "Running Trial 29...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.7500000000000001 0.14798648586948737\n",
      "Running Trial 30...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.79 0.05916079783099617\n",
      "Running Trial 31...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.79 0.11090536506409417\n",
      "Running Trial 32...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.77 0.07681145747868608\n",
      "Running Trial 33...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.79 0.033166247903553984\n",
      "Running Trial 34...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.84 0.028284271247461888\n",
      "Running Trial 35...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8300000000000001 0.09949874371066199\n",
      "Running Trial 36...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8 0.0748331477354788\n",
      "Running Trial 37...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8 0.11661903789690599\n",
      "Running Trial 38...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.78 0.1\n",
      "Running Trial 39...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.78 0.05999999999999998\n",
      "Running Trial 40...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8300000000000001 0.099498743710662\n",
      "Running Trial 41...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8300000000000001 0.01732050807568874\n",
      "Running Trial 42...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8400000000000001 0.028284271247461888\n",
      "Running Trial 43...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.77 0.07681145747868608\n",
      "Running Trial 44...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.81 0.03316624790355398\n",
      "Running Trial 45...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.77 0.033166247903554026\n",
      "Running Trial 46...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8 0.08944271909999159\n",
      "Running Trial 47...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8099999999999999 0.05196152422706632\n",
      "Running Trial 48...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8300000000000001 0.05196152422706631\n",
      "Running Trial 49...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.79 0.06557438524301998\n",
      "Running Trial 50...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.74 0.044721359549995794\n",
      "Running Trial 51...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.76 0.08485281374238571\n",
      "Running Trial 52...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8099999999999999 0.07681145747868605\n",
      "Running Trial 53...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8300000000000001 0.0768114574786861\n",
      "Running Trial 54...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.79 0.11445523142259598\n",
      "Running Trial 55...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.75 0.033166247903554026\n",
      "Running Trial 56...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8400000000000001 0.04898979485566356\n",
      "Running Trial 57...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8200000000000001 0.09999999999999996\n",
      "Running Trial 58...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8200000000000001 0.08717797887081347\n",
      "Running Trial 59...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8300000000000001 0.07141428428542851\n",
      "Running Trial 60...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.75 0.11090536506409417\n",
      "Running Trial 61...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.79 0.11789826122551599\n",
      "Running Trial 62...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.81 0.0768114574786861\n",
      "Running Trial 63...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.76 0.10198039027185568\n",
      "Running Trial 64...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.81 0.07681145747868605\n",
      "Running Trial 65...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.83 0.04358898943540673\n",
      "Running Trial 66...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.79 0.05196152422706631\n",
      "Running Trial 67...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8 0.04898979485566356\n",
      "Running Trial 68...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8 0.0632455532033676\n",
      "Running Trial 69...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.78 0.034641016151377525\n",
      "Running Trial 70...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.79 0.11445523142259598\n",
      "Running Trial 71...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8300000000000001 0.05196152422706631\n",
      "Running Trial 72...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.83 0.04358898943540673\n",
      "Running Trial 73...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.82 0.09165151389911678\n",
      "Running Trial 74...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.85 0.05916079783099617\n",
      "Running Trial 75...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.79 0.07681145747868606\n",
      "Running Trial 76...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8400000000000001 0.0748331477354788\n",
      "Running Trial 77...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.81 0.043588989435406726\n",
      "Running Trial 78...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.81 0.09539392014169455\n",
      "Running Trial 79...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.76 0.1296148139681572\n",
      "Running Trial 80...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.81 0.03316624790355398\n",
      "Running Trial 81...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.79 0.10723805294763605\n",
      "Running Trial 82...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8 0.10198039027185571\n",
      "Running Trial 83...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.7999999999999999 0.09380831519646858\n",
      "Running Trial 84...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.75 0.07141428428542847\n",
      "Running Trial 85...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.77 0.19467922333931784\n",
      "Running Trial 86...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.7899999999999999 0.08660254037844385\n",
      "Running Trial 87...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.8099999999999999 0.10344080432788601\n",
      "Running Trial 88...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8200000000000001 0.060000000000000005\n",
      "Running Trial 89...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.81 0.03316624790355398\n",
      "Running Trial 90...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.84 0.07483314773547886\n",
      "Running Trial 91...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.79 0.01732050807568879\n",
      "Running Trial 92...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8200000000000001 0.06\n",
      "Running Trial 93...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.79 0.09110433579144298\n",
      "Running Trial 94...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8 0.10198039027185571\n",
      "Running Trial 95...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.81 0.1072380529476361\n",
      "Running Trial 96...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.78 0.09165151389911678\n",
      "Running Trial 97...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.7899999999999999 0.09110433579144299\n",
      "Running Trial 98...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.8 0.04898979485566356\n",
      "Running Trial 99...\n",
      "0.89 {'var_smoothing': 1e-05}\n",
      "0.83 0.08660254037844385\n",
      "Running Trial 100...\n",
      "0.89 {'var_smoothing': 1e-09}\n",
      "0.77 0.07681145747868608\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "          \"var_smoothing\" : [1e-5, 1e-9]\n",
    "}\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb_scores, nb_params, nb_nested = nested_cross_validation(nb, params, X, Y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "result_columns = [\"Model\", \"Trial\", \"Parameters\", \"Accuracy\", \"Std_dev\"]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    result_list.append([\"NB\", i, nb_params[i], nb_nested[i][0], nb_nested[i][1]])\n",
    "    \n",
    "nb_df = pd.DataFrame(result_list,columns=result_columns)\n",
    "\n",
    "nb_df.to_csv(\"NB_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "result_columns = [\"Model\", \"Trial\", \"Parameters\", \"Accuracy\", \"Std_dev\"]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    result_list.append([\"MLP\", i, mlp_params[i], mlp_nested[i][0], mlp_nested[i][1]])\n",
    "    \n",
    "mlp_df = pd.DataFrame(result_list,columns=result_columns)\n",
    "\n",
    "mlp_df.to_csv(\"MLP_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "result_columns = [\"Model\", \"Trial\", \"Parameters\", \"Accuracy\", \"Std_dev\"]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    result_list.append([\"RF\", i, rf_params[i], rf_nested[i][0], rf_nested[i][1]])\n",
    "    \n",
    "rf_df = pd.DataFrame(result_list,columns=result_columns)\n",
    "\n",
    "rf_df.to_csv(\"RF_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp1 = np.array(mlp_nested)[:,0] \n",
    "temp2 = np.array(rf_nested)[:,0]\n",
    "temp3 = np.array(nb_nested)[:,0]\n",
    "\n",
    "# print(temp1)\n",
    "\n",
    "plt.boxplot([temp1, temp2, temp3], vert=0, labels=['MLP', 'RF', \"NB\"])\n",
    "plt.savefig(\"boxplot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 170 (0.113050)\n",
      "2. feature 201 (0.016140)\n",
      "3. feature 181 (0.015683)\n",
      "4. feature 26 (0.014354)\n",
      "5. feature 55 (0.014103)\n",
      "6. feature 3 (0.013284)\n",
      "7. feature 187 (0.013182)\n",
      "8. feature 17 (0.013129)\n",
      "9. feature 198 (0.013081)\n",
      "10. feature 123 (0.013056)\n",
      "11. feature 185 (0.012242)\n",
      "12. feature 188 (0.011577)\n",
      "13. feature 113 (0.011234)\n",
      "14. feature 41 (0.010344)\n",
      "15. feature 179 (0.010288)\n",
      "16. feature 122 (0.010015)\n",
      "17. feature 121 (0.009961)\n",
      "18. feature 136 (0.009958)\n",
      "19. feature 29 (0.009850)\n",
      "20. feature 18 (0.009226)\n",
      "21. feature 4 (0.009071)\n",
      "22. feature 186 (0.008986)\n",
      "23. feature 129 (0.008790)\n",
      "24. feature 199 (0.008763)\n",
      "25. feature 31 (0.008748)\n",
      "26. feature 54 (0.008368)\n",
      "27. feature 115 (0.007871)\n",
      "28. feature 174 (0.007802)\n",
      "29. feature 197 (0.007720)\n",
      "30. feature 140 (0.007683)\n",
      "31. feature 19 (0.007662)\n",
      "32. feature 138 (0.007483)\n",
      "33. feature 114 (0.007390)\n",
      "34. feature 200 (0.007148)\n",
      "35. feature 139 (0.007107)\n",
      "36. feature 33 (0.006964)\n",
      "37. feature 47 (0.006854)\n",
      "38. feature 182 (0.006840)\n",
      "39. feature 53 (0.006718)\n",
      "40. feature 75 (0.006668)\n",
      "41. feature 124 (0.006539)\n",
      "42. feature 27 (0.006456)\n",
      "43. feature 61 (0.006436)\n",
      "44. feature 102 (0.006384)\n",
      "45. feature 180 (0.006336)\n",
      "46. feature 120 (0.006319)\n",
      "47. feature 175 (0.006269)\n",
      "48. feature 178 (0.006261)\n",
      "49. feature 7 (0.006091)\n",
      "50. feature 16 (0.006072)\n",
      "51. feature 130 (0.005820)\n",
      "52. feature 51 (0.005795)\n",
      "53. feature 135 (0.005723)\n",
      "54. feature 40 (0.005693)\n",
      "55. feature 1 (0.005679)\n",
      "56. feature 49 (0.005666)\n",
      "57. feature 25 (0.005570)\n",
      "58. feature 64 (0.005513)\n",
      "59. feature 97 (0.005436)\n",
      "60. feature 183 (0.005428)\n",
      "61. feature 42 (0.005262)\n",
      "62. feature 35 (0.005193)\n",
      "63. feature 36 (0.005151)\n",
      "64. feature 149 (0.005143)\n",
      "65. feature 32 (0.005106)\n",
      "66. feature 56 (0.005103)\n",
      "67. feature 189 (0.004962)\n",
      "68. feature 74 (0.004946)\n",
      "69. feature 165 (0.004943)\n",
      "70. feature 22 (0.004894)\n",
      "71. feature 24 (0.004871)\n",
      "72. feature 50 (0.004863)\n",
      "73. feature 30 (0.004833)\n",
      "74. feature 0 (0.004815)\n",
      "75. feature 133 (0.004739)\n",
      "76. feature 119 (0.004571)\n",
      "77. feature 23 (0.004499)\n",
      "78. feature 101 (0.004497)\n",
      "79. feature 15 (0.004493)\n",
      "80. feature 52 (0.004430)\n",
      "81. feature 12 (0.004428)\n",
      "82. feature 79 (0.004398)\n",
      "83. feature 37 (0.004394)\n",
      "84. feature 60 (0.004348)\n",
      "85. feature 116 (0.004327)\n",
      "86. feature 137 (0.004313)\n",
      "87. feature 8 (0.004298)\n",
      "88. feature 152 (0.004296)\n",
      "89. feature 100 (0.004280)\n",
      "90. feature 98 (0.004257)\n",
      "91. feature 132 (0.004163)\n",
      "92. feature 28 (0.004150)\n",
      "93. feature 117 (0.004111)\n",
      "94. feature 126 (0.003844)\n",
      "95. feature 131 (0.003778)\n",
      "96. feature 48 (0.003684)\n",
      "97. feature 58 (0.003669)\n",
      "98. feature 111 (0.003650)\n",
      "99. feature 203 (0.003633)\n",
      "100. feature 103 (0.003614)\n",
      "101. feature 145 (0.003524)\n",
      "102. feature 155 (0.003467)\n",
      "103. feature 202 (0.003454)\n",
      "104. feature 68 (0.003449)\n",
      "105. feature 110 (0.003430)\n",
      "106. feature 151 (0.003372)\n",
      "107. feature 96 (0.003354)\n",
      "108. feature 141 (0.003316)\n",
      "109. feature 142 (0.003314)\n",
      "110. feature 10 (0.003311)\n",
      "111. feature 44 (0.003268)\n",
      "112. feature 76 (0.003175)\n",
      "113. feature 184 (0.003130)\n",
      "114. feature 14 (0.003038)\n",
      "115. feature 9 (0.003030)\n",
      "116. feature 134 (0.003008)\n",
      "117. feature 150 (0.002996)\n",
      "118. feature 99 (0.002974)\n",
      "119. feature 92 (0.002960)\n",
      "120. feature 106 (0.002881)\n",
      "121. feature 39 (0.002777)\n",
      "122. feature 86 (0.002697)\n",
      "123. feature 20 (0.002681)\n",
      "124. feature 46 (0.002665)\n",
      "125. feature 80 (0.002625)\n",
      "126. feature 144 (0.002606)\n",
      "127. feature 77 (0.002577)\n",
      "128. feature 57 (0.002567)\n",
      "129. feature 81 (0.002548)\n",
      "130. feature 62 (0.002529)\n",
      "131. feature 5 (0.002528)\n",
      "132. feature 73 (0.002499)\n",
      "133. feature 72 (0.002445)\n",
      "134. feature 66 (0.002381)\n",
      "135. feature 156 (0.002304)\n",
      "136. feature 177 (0.002275)\n",
      "137. feature 147 (0.002263)\n",
      "138. feature 172 (0.002254)\n",
      "139. feature 13 (0.002247)\n",
      "140. feature 128 (0.002242)\n",
      "141. feature 95 (0.002233)\n",
      "142. feature 65 (0.002231)\n",
      "143. feature 21 (0.002179)\n",
      "144. feature 43 (0.002163)\n",
      "145. feature 2 (0.002107)\n",
      "146. feature 70 (0.002088)\n",
      "147. feature 78 (0.002072)\n",
      "148. feature 125 (0.002064)\n",
      "149. feature 127 (0.002015)\n",
      "150. feature 11 (0.002014)\n",
      "151. feature 107 (0.001996)\n",
      "152. feature 148 (0.001973)\n",
      "153. feature 158 (0.001952)\n",
      "154. feature 166 (0.001929)\n",
      "155. feature 153 (0.001929)\n",
      "156. feature 162 (0.001922)\n",
      "157. feature 91 (0.001921)\n",
      "158. feature 105 (0.001876)\n",
      "159. feature 45 (0.001867)\n",
      "160. feature 118 (0.001856)\n",
      "161. feature 59 (0.001820)\n",
      "162. feature 173 (0.001767)\n",
      "163. feature 193 (0.001746)\n",
      "164. feature 93 (0.001702)\n",
      "165. feature 194 (0.001654)\n",
      "166. feature 89 (0.001598)\n",
      "167. feature 104 (0.001551)\n",
      "168. feature 108 (0.001521)\n",
      "169. feature 146 (0.001517)\n",
      "170. feature 6 (0.001474)\n",
      "171. feature 154 (0.001459)\n",
      "172. feature 94 (0.001444)\n",
      "173. feature 69 (0.001431)\n",
      "174. feature 168 (0.001425)\n",
      "175. feature 161 (0.001330)\n",
      "176. feature 112 (0.001310)\n",
      "177. feature 190 (0.001303)\n",
      "178. feature 157 (0.001302)\n",
      "179. feature 169 (0.001273)\n",
      "180. feature 109 (0.001195)\n",
      "181. feature 167 (0.001136)\n",
      "182. feature 85 (0.001121)\n",
      "183. feature 176 (0.001102)\n",
      "184. feature 34 (0.001071)\n",
      "185. feature 196 (0.001063)\n",
      "186. feature 63 (0.001021)\n",
      "187. feature 160 (0.000927)\n",
      "188. feature 191 (0.000912)\n",
      "189. feature 171 (0.000896)\n",
      "190. feature 71 (0.000896)\n",
      "191. feature 67 (0.000892)\n",
      "192. feature 82 (0.000872)\n",
      "193. feature 83 (0.000750)\n",
      "194. feature 159 (0.000729)\n",
      "195. feature 195 (0.000698)\n",
      "196. feature 88 (0.000669)\n",
      "197. feature 90 (0.000659)\n",
      "198. feature 84 (0.000658)\n",
      "199. feature 143 (0.000613)\n",
      "200. feature 38 (0.000551)\n",
      "201. feature 163 (0.000494)\n",
      "202. feature 192 (0.000424)\n",
      "203. feature 164 (0.000397)\n",
      "204. feature 87 (0.000254)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'pr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-9ca0e150b218>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginalclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0medictedclass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pr' is not defined"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "# temp = evaluate_model(random_forest, X, Y)\n",
    "\n",
    "forest.fit(X, Y)\n",
    "# print(random_forest.feature_importances_.max())\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n",
    "print(classification_report(originalclass, pr/edictedclass)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GaussianNB' object has no attribute 'coefs_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-5c1f70b8fbb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mgnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# temp = evaluate_model(gnb, X, Y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GaussianNB' object has no attribute 'coefs_'"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X, Y)\n",
    "print(gnb.coefs_)\n",
    "\n",
    "# temp = evaluate_model(gnb, X, Y)\n",
    "# print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-4baa6d5c274a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mimportances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m std = np.std([tree.feature_importances_ for tree in mlp.estimators_],\n\u001b[0;32m     13\u001b[0m              axis=0)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "# Neural network with 1 hidden layer (the hidden layer is as big as the number of features)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation=\"relu\", alpha=0.0001,\n",
    "                    hidden_layer_sizes=(142,), max_iter=1000)\n",
    "\n",
    "temp = evaluate_model(mlp, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network with 2 hidden layer (the hidden layer is as big as the number of features)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation=\"relu\", alpha=1e-5,\n",
    "                    hidden_layer_sizes=(number_of_features, number_of_features), max_iter=1000)\n",
    "\n",
    "temp = evaluate_model(mlp, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network with 3 hidden layer (the hidden layer is as big as the number of features)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation=\"relu\", alpha=1e-5,\n",
    "                    hidden_layer_sizes=(number_of_features, number_of_features, number_of_features,), max_iter=1000)\n",
    "\n",
    "temp = evaluate_model(mlp, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
