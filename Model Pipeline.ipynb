{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0    1    2    3    4    5    6    7    8    9     ... 2824 2825  \\\n",
      "Array.129    0    0    0    0    0    0    0    0    0    0  ...    2    2   \n",
      "Array.34     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.67     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.24     0    0    0    0    0    0    0   -1    0    0  ...    0    0   \n",
      "Array.22     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "Array.10     0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.123    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.100    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "Array.134   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1  ...    1    1   \n",
      "Array.130    0    0    0    0    0    0    0    0    0    0  ...    1    1   \n",
      "\n",
      "          2826 2827 2828 2829 2830 2831 2832 2833  \n",
      "Array.129    2    2    0    1    1    1    1    1  \n",
      "Array.34     1    1    1    1    1    1    1    1  \n",
      "Array.67     1    1    1    1    1    1    1    1  \n",
      "Array.24     0    0    0    0    0    0    0    0  \n",
      "Array.22     1    1    1    1    1    1    1    1  \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "Array.10     0    1    1    1    1    1    1    1  \n",
      "Array.123    1    1    1    1    1    1    1    1  \n",
      "Array.100    1    1    1    1    1    1    1    1  \n",
      "Array.134    1    1    1    1    1    1    1    1  \n",
      "Array.130    1    1    1    1    1    1    1    1  \n",
      "\n",
      "[100 rows x 2834 columns]\n",
      "[1, 2, 2, 3, 3, 2, 1, 1, 3, 1, 2, 3, 1, 1, 3, 3, 2, 1, 2, 2, 3, 1, 2, 1, 2, 1, 1, 3, 1, 2, 2, 1, 2, 1, 2, 2, 3, 3, 3, 1, 2, 3, 2, 3, 2, 3, 1, 1, 3, 3, 1, 2, 2, 3, 2, 3, 1, 1, 3, 2, 1, 2, 3, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 3, 1, 3, 2, 3, 3, 3, 3, 2, 1, 1, 2, 3, 3, 3, 3, 2, 3, 2, 3, 1, 2, 2, 2, 1]\n",
      "The regions found in the literature were:  [2822, 1866, 2794, 2795, 1583, 2223, 2224, 1725, 2328, 2329, 2330, 361, 2016, 772, 2021, 1611, 2733, 1911, 111, 937, 2210, 1386, 1296, 1407, 993, 664, 1575, 1136, 2159, 2160, 2161, 1965, 479, 670, 1365, 157, 1207, 1208, 688, 1908, 1734, 2680, 2681, 283, 2446, 1609, 1697, 625, 2075]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "with open(\"train_call.txt\", 'r') as temp:\n",
    "    for line in temp:\n",
    "        temp_list.append(line.split())\n",
    "\n",
    "columns_temp = temp_list[0]\n",
    "columns_temp = [x.replace(\"\\\"\", \"\") for x in columns_temp]\n",
    "\n",
    "df_train = pd.DataFrame(temp_list[1:], columns=columns_temp)\n",
    "X = df_train.drop(['Chromosome', 'Start','End', 'Nclone'], axis=1)\n",
    "X = X.transpose()\n",
    "\n",
    "labels = []\n",
    "\n",
    "# X for features Y for breast cancer subtype where 1 = HER2+, 2 = HR+, 3 = Triple Neg\n",
    "with open(\"Train_clinical.txt\", 'r') as temp_labels:\n",
    "    next(temp_labels)\n",
    "    for line in temp_labels:\n",
    "        temp = line.strip()\n",
    "        temp = temp.split()\n",
    "        if temp[1].strip(\"\\\"\") == \"HER2+\":\n",
    "            labels.append(1)\n",
    "        if temp[1].strip(\"\\\"\") == \"HR+\":\n",
    "            labels.append(2)\n",
    "        if temp[1].strip(\"\\\"\") == \"Triple\":\n",
    "            labels.append(3)\n",
    "\n",
    "Y = labels\n",
    "            \n",
    "important_genes = []\n",
    "\n",
    "with open(\"important_genes.csv\", 'r') as imp_genes:\n",
    "    for line in imp_genes:\n",
    "        temp = line.strip()\n",
    "        important_genes.append(temp.split(\",\"))\n",
    "        \n",
    "imp_genes = []\n",
    "\n",
    "for gene in important_genes[1:]:\n",
    "    imp_genes.append([gene[0], gene[1], gene[2], gene[3]])\n",
    "    \n",
    "important_genes = []\n",
    "\n",
    "for x in imp_genes:\n",
    "    for i, y in enumerate(df_train.values.tolist()):\n",
    "        if x[1] == y[0] and x[2] == y[1] and x[3] == y[2]:\n",
    "            important_genes.append(i)\n",
    "            \n",
    "print(X)\n",
    "print(Y)\n",
    "print(\"The regions found in the literature were: \", important_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Gene  Region number   P-value Yes/No\n",
      "0                AFF2           2822  0.929904     No\n",
      "1                AKT1           1866  0.553470     No\n",
      "2                  AR           2794  0.777129     No\n",
      "3                  AR           2795  0.918872     No\n",
      "4                 ATM           1583  0.225059     No\n",
      "5               BRCA1           2223  0.006155    Yes\n",
      "6               BRCA1           2224  0.010694    Yes\n",
      "7               BRCA2           1725  0.693197     No\n",
      "8               BRIP1           2328  0.554967     No\n",
      "9               BRIP1           2329  0.523246     No\n",
      "10              BRIP1           2330  0.819148     No\n",
      "11  CASP8/CTLA4/BARD1            361  0.802287     No\n",
      "12               CBFB           2016  0.116079     No\n",
      "13              CCND3            772  0.156822     No\n",
      "14               CDH1           2021  0.011081    Yes\n",
      "15             CDKN1B           1611  0.766551     No\n",
      "16              CHEK2           2733  0.075718     No\n",
      "17            CYP19A1           1911  0.216312     No\n",
      "18             DIRAS3            111  0.689706     No\n",
      "19               EGFR            937  0.949250     No\n",
      "20       ERBB2 (HER2)           2210  0.002198    Yes\n",
      "21              FGFR2           1386  0.985744     No\n",
      "22              GATA3           1296  0.685502     No\n",
      "23           H19/LSP1           1407  0.504850     No\n",
      "24       KMT2C (MLL3)            993  0.801433     No\n",
      "25             MAP3K1            664  0.156946     No\n",
      "26           MRE11(A)           1575  0.243654     No\n",
      "27                NBN           1136  0.763050     No\n",
      "28                NF1           2159  0.424373     No\n",
      "29                NF1           2160  0.547566     No\n",
      "30                NF1           2161  0.610324     No\n",
      "31              PALB2           1965  0.568365     No\n",
      "32             PIK3CA            479  0.400746     No\n",
      "33             PIK3R1            670  0.042505    Yes\n",
      "34               PTEN           1365  0.863243     No\n",
      "35             PTPN22            157  0.728798     No\n",
      "36              PTPRD           1207  0.506069     No\n",
      "37              PTPRD           1208  0.623615     No\n",
      "38              RAD50            688  0.113870     No\n",
      "39              RAD51           1908  0.138529     No\n",
      "40                RB1           1734  0.348517     No\n",
      "41              RUNX1           2680  0.482657     No\n",
      "42              RUNX1           2681  0.523485     No\n",
      "43              SF3B1            283  0.879354     No\n",
      "44       STK11 (LKB1)           2446  0.966992     No\n",
      "45               TBX3           1609  0.657058     No\n",
      "46               TBX3           1697  0.796703     No\n",
      "47               TERT            625  0.975776     No\n",
      "48               TP53           2075  0.032496    Yes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# #Loading data\n",
    "# df = pd.read_csv('Processed_data_2.csv')\n",
    "\n",
    "# # X for features Y for breast cancer subtype where 1 = HER2+, 2 = HR+, 3 = Triple Neg\n",
    "# X = df.drop(['Unnamed: 0', 'Sample','Subgroup'], axis=1)\n",
    "# Y = df['Subgroup']\n",
    "# print(X)\n",
    "patients = X.values.tolist()\n",
    "\n",
    "## FEATURE SELECTION\n",
    "\n",
    "# we need to shift the features by 1 since the chi2 function does not take non-negative values\n",
    "patients_shift = []\n",
    "\n",
    "for patient in patients:\n",
    "    x = []\n",
    "    for feature in patient:\n",
    "        x.append(int(feature) + 1)\n",
    "    patients_shift.append(x)\n",
    "\n",
    "chi, p_val = chi2(patients_shift, Y)\n",
    "\n",
    "imp_genes_p_values = []\n",
    "\n",
    "for i, j in enumerate(important_genes):\n",
    "    if p_val[j] >= 0.05:\n",
    "        imp_genes_p_values.append([imp_genes[i][0], j, p_val[j], \"No\"])\n",
    "    else:\n",
    "        imp_genes_p_values.append([imp_genes[i][0], j, p_val[j], \"Yes\"])\n",
    "    \n",
    "\n",
    "important_genes_scores = pd.DataFrame(imp_genes_p_values, columns=[\"Gene\", \"Region number\", \"P-value\", \"Yes/No\"])\n",
    "print(important_genes_scores)\n",
    "\n",
    "X_feature_selected = X\n",
    "\n",
    "threshold = 0.05\n",
    "for i, val in enumerate(p_val):\n",
    "    # this drops the p_values higher than 0.05 that are not in the significant genes list\n",
    "    if val >= threshold and i not in important_genes:\n",
    "        X_feature_selected = X_feature_selected.drop([i], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 181\n"
     ]
    }
   ],
   "source": [
    "X = X_feature_selected\n",
    "number_of_features = len(X.values.tolist()[0])\n",
    "print(\"Number of features = {}\".format(number_of_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    \"Scorer for the cross validation function\"\n",
    "    originalclass.extend(y_true)\n",
    "    predictedclass.extend(y_pred)\n",
    "    return accuracy_score(y_true, y_pred) \n",
    "\n",
    "def evaluate_model(model, features, labels):\n",
    "    \"Gets the cross validation score using a 5-fold (cv=5) cross validation\"\n",
    "    scores = cross_val_score(model, features, labels, cv=5, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.94      0.90        32\n",
      "           2       0.77      0.75      0.76        36\n",
      "           3       0.73      0.69      0.71        32\n",
      "\n",
      "    accuracy                           0.79       100\n",
      "   macro avg       0.79      0.79      0.79       100\n",
      "weighted avg       0.79      0.79      0.79       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "temp = evaluate_model(random_forest, X, Y)\n",
    "print(classification_report(originalclass, predictedclass)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.81      0.90        32\n",
      "           2       0.82      0.86      0.84        36\n",
      "           3       0.72      0.81      0.76        32\n",
      "\n",
      "    accuracy                           0.83       100\n",
      "   macro avg       0.85      0.83      0.83       100\n",
      "weighted avg       0.84      0.83      0.83       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "gnb = GaussianNB()\n",
    "temp = evaluate_model(gnb, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.91      0.92        32\n",
      "           2       0.83      0.83      0.83        36\n",
      "           3       0.79      0.81      0.80        32\n",
      "\n",
      "    accuracy                           0.85       100\n",
      "   macro avg       0.85      0.85      0.85       100\n",
      "weighted avg       0.85      0.85      0.85       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural network with 1 hidden layer (the hidden layer is as big as the number of features)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation=\"relu\", alpha=1e-5,\n",
    "                    hidden_layer_sizes=(number_of_features,), max_iter=1000)\n",
    "\n",
    "temp = evaluate_model(mlp, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.94      0.92        32\n",
      "           2       0.84      0.86      0.85        36\n",
      "           3       0.77      0.72      0.74        32\n",
      "\n",
      "    accuracy                           0.84       100\n",
      "   macro avg       0.84      0.84      0.84       100\n",
      "weighted avg       0.84      0.84      0.84       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural network with 2 hidden layer (the hidden layer is as big as the number of features)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation=\"relu\", alpha=1e-5,\n",
    "                    hidden_layer_sizes=(number_of_features, number_of_features), max_iter=1000)\n",
    "\n",
    "temp = evaluate_model(mlp, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.94      0.88        32\n",
      "           2       0.82      0.86      0.84        36\n",
      "           3       0.77      0.62      0.69        32\n",
      "\n",
      "    accuracy                           0.81       100\n",
      "   macro avg       0.81      0.81      0.80       100\n",
      "weighted avg       0.81      0.81      0.80       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural network with 3 hidden layer (the hidden layer is as big as the number of features)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation=\"relu\", alpha=1e-5,\n",
    "                    hidden_layer_sizes=(number_of_features, number_of_features, number_of_features,), max_iter=1000)\n",
    "\n",
    "temp = evaluate_model(mlp, X, Y)\n",
    "print(classification_report(originalclass, predictedclass))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
